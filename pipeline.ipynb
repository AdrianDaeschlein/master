{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "\n",
    "# Data Handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning & Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "import optuna\n",
    "\n",
    "# Model Saving & Experiment Tracking\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow ui --port 5000\n"
     ]
    }
   ],
   "source": [
    "print(\"mlflow ui --port 5000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACKING_URI = \"azureml://northeurope.api.azureml.ms/mlflow/v1.0/subscriptions/716d3e14-e009-4f92-89c9-01fa8347272a/resourceGroups/adda23ac-rg/providers/Microsoft.MachineLearningServices/workspaces/fall\"\n",
    "mlflow.set_tracking_uri(TRACKING_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    '''\n",
    "    Load data from a csv file into a pandas dataframe.\n",
    "    \n",
    "    Args:\n",
    "    file_name: The name of the csv file to load\n",
    "    \n",
    "    Returns:\n",
    "    df: A pandas dataframe containing the data from the csv file\n",
    "    '''\n",
    "    folder = \"datasets\"\n",
    "\n",
    "    df = pd.read_csv(f\"{folder}/{file_name}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratify Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_activity_split(df, target_column=\"fall_binary\", test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the dataset while ensuring 20% of each 'activity' is in the test set.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The full dataset containing 'activity' and the target variable.\n",
    "        target_column (str): The column representing the target labels.\n",
    "        test_size (float): The fraction of each activity to be in the test set.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        data_train (pd.DataFrame): Training set.\n",
    "        data_test (pd.DataFrame): Test set.\n",
    "    \"\"\"\n",
    "\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "\n",
    "    # ✅ Loop through each activity and apply train-test split\n",
    "    for activity, group in df.groupby(\"activity\"):\n",
    "        train, test = train_test_split(group, test_size=test_size, random_state=random_state, stratify=group[target_column])\n",
    "        train_list.append(train)\n",
    "        test_list.append(test)\n",
    "\n",
    "    # ✅ Concatenate results into train & test datasets\n",
    "    data_train = pd.concat(train_list).reset_index(drop=True)\n",
    "    data_test = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "    return data_train, data_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Per Activity / Distance Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_per_activity(model, test_X, test_y, feature_columns=None):\n",
    "    \"\"\"\n",
    "    Evaluates model performance per activity type and logs the results in MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model (LSTM or Tree-based).\n",
    "        test_X: Test feature data (DataFrame).\n",
    "        test_y: Test target labels (Series).\n",
    "        target_column: The name of the target column.\n",
    "        feature_columns: The feature columns used for training.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame containing classification results per activity.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ✅ Ensure X_test is a DataFrame\n",
    "    if not isinstance(test_X, pd.DataFrame):\n",
    "        test_X = pd.DataFrame(test_X, columns=feature_columns)\n",
    "\n",
    "    # ✅ Ensure y_test is a Series\n",
    "    if isinstance(test_y, pd.DataFrame):\n",
    "        test_y = test_y.squeeze()  # Convert to Series if needed\n",
    "\n",
    "    # ✅ Ensure 'activity' column exists\n",
    "    if \"activity\" not in test_X.columns:\n",
    "        raise ValueError(\"Dataset does not contain an 'activity' column.\")\n",
    "\n",
    "    is_lstm = isinstance(model, tf.keras.Model)\n",
    "    results = []\n",
    "\n",
    "    # ✅ Loop through each unique activity and evaluate model performance\n",
    "    for activity in test_X[\"activity\"].unique():\n",
    "        # Filter test data for the current activity\n",
    "        X_test_activity = test_X[test_X[\"activity\"] == activity].copy()\n",
    "\n",
    "        # Extract the actual labels\n",
    "        y_test_activity = test_y.loc[X_test_activity.index].values.flatten()  # Ensure correct shape\n",
    "\n",
    "        # ✅ Check for missing values\n",
    "        if np.isnan(y_test_activity).any():\n",
    "            print(f\"Warning: NaN values found in y_test_activity for activity {activity}!\")\n",
    "            y_test_activity = np.nan_to_num(y_test_activity, nan=0)  # Replace NaN with 0 (No Fall)\n",
    "\n",
    "        # ✅ Ensure y_test_activity is integer\n",
    "        try:\n",
    "            y_test_activity = y_test_activity.astype(int)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error converting y_test_activity to integer for activity {activity}: {e}\")\n",
    "            continue  # Skip this activity if conversion fails\n",
    "\n",
    "        # ✅ Select feature columns\n",
    "        if is_lstm:\n",
    "            feature_columns = [col for col in X_test_activity.columns if col.startswith(\"value\")]\n",
    "\n",
    "        X_test_activity = X_test_activity[feature_columns].values  # Extract feature values\n",
    "\n",
    "        print(f\"Activity: {activity}, X shape: {X_test_activity.shape}, y shape: {y_test_activity.shape}\")\n",
    "\n",
    "        # ✅ Reshape X for LSTM input\n",
    "        if is_lstm:\n",
    "            X_test_activity = X_test_activity.reshape(-1, 500, 1)\n",
    "\n",
    "        # ✅ Predict fall_binary values\n",
    "        y_pred = model.predict(X_test_activity).round().astype(int).flatten()\n",
    "\n",
    "        # ✅ Compute correct and incorrect counts\n",
    "        correct = np.sum(y_pred == y_test_activity)\n",
    "        incorrect = len(y_pred) - correct\n",
    "\n",
    "        # ✅ Determine if the first sample of the activity is a fall or not\n",
    "        actual_fall = \"Fall\" if y_test_activity[0] == 1 else \"No Fall\"\n",
    "\n",
    "        print(f\"Activity {activity}: {correct} correct, {incorrect} incorrect\")\n",
    "\n",
    "        # ✅ Store results\n",
    "        results.append({\n",
    "            \"activity\": activity,\n",
    "            \"Actual Fall\": actual_fall,  # ✅ Single column for actual fall status\n",
    "            \"correct\": correct,\n",
    "            \"incorrect\": incorrect,\n",
    "            \"total\": len(y_pred),\n",
    "            \"accuracy\": correct / len(y_pred) if len(y_pred) > 0 else 0\n",
    "        })\n",
    "\n",
    "    # ✅ Convert results into a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # ✅ Mapping dictionary from abbreviations to full names\n",
    "    activity_mapping = {\n",
    "        \"S\": \"Still\",\n",
    "        \"CD\": \"Close Door\",\n",
    "        \"KD\": \"Knock Door\",\n",
    "        \"MA\": \"Minor Ambience (Sitting and Eating)\",\n",
    "        \"FOB\": \"Fall of object (Backpack)\",\n",
    "        \"FOL\": \"Fall of object (FaszienRolle)\",\n",
    "        \"WBS\": \"Walk by Sensor\",\n",
    "        \"RBS\": \"Rush by Sensor\",\n",
    "        \"SC\": \"Sitting down on chair\",\n",
    "        \"LC\": \"Laying down on couch\",\n",
    "        \"STC\": \"Stand up from Chair\",\n",
    "        \"PUF\": \"Picking something up from floor\",\n",
    "        \"K\": \"Kneeling down then standing up\",\n",
    "        \"SLB\": \"Standing Lost Balance\",\n",
    "        \"TF\": \"Trip and Fall - Forwards\",\n",
    "        \"SFB\": \"Slip and Fall - Backwards\",\n",
    "        \"FCS\": \"Chair - Fall to side\",\n",
    "        \"FCF\": \"Chair - Fall to Front\",\n",
    "        \"LAF\": \"Lying - Awake Fall\",\n",
    "        \"LSF\": \"Lying - Asleep Fall\",\n",
    "        \"FR\": \"Fall Recovery\",\n",
    "        \"KID\": \"Kids Running\"\n",
    "    }\n",
    "\n",
    "    # ✅ Function to extract the relevant part before the first '_'\n",
    "    def get_activity_name(code):\n",
    "        key = code.split('_')[0]  # Extract first part of activity code\n",
    "        return activity_mapping.get(key, code)  # Replace with full name if exists\n",
    "\n",
    "    # ✅ Apply the mapping to the results dataframe\n",
    "    results_df[\"activity\"] = results_df[\"activity\"].apply(get_activity_name)\n",
    "\n",
    "    # ✅ Save the results as a CSV file\n",
    "    results_path = \"activity_results.csv\"\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "\n",
    "    # ✅ Log results in MLflow\n",
    "    mlflow.log_artifact(results_path)\n",
    "\n",
    "    print(\"\\n📊 Per-Activity Results:\")\n",
    "    print(results_df)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_per_distance(model, test_X, test_y, feature_columns=None):\n",
    "    \"\"\"\n",
    "    Evaluates model performance per distance type and logs the results in MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model (LSTM or Tree-based).\n",
    "        test_X: Test feature data (DataFrame).\n",
    "        test_y: Test target labels (Series).\n",
    "        feature_columns: The feature columns used for training.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame containing classification results per distance.\n",
    "    \"\"\"\n",
    "\n",
    "    X_test = test_X.copy()\n",
    "    y_test = test_y.copy()\n",
    "\n",
    "    # ✅ Ensure X_test is a DataFrame\n",
    "    if not isinstance(X_test, pd.DataFrame):\n",
    "        X_test = pd.DataFrame(X_test, columns=feature_columns)\n",
    "\n",
    "    # ✅ Ensure y_test is a Series\n",
    "    if isinstance(y_test, pd.DataFrame):\n",
    "        y_test = y_test.squeeze()  # Convert to Series if needed\n",
    "\n",
    "    is_lstm = isinstance(model, tf.keras.Model)\n",
    "\n",
    "    # ✅ Ensure 'distance_m' column exists\n",
    "    if \"distance_m\" not in X_test.columns:\n",
    "        raise ValueError(\"Dataset does not contain a 'distance_m' column.\")\n",
    "\n",
    "    # ✅ Get unique distances and setup subplots dynamically\n",
    "    unique_distances = sorted(X_test[\"distance_m\"].unique())\n",
    "    fig, axes = plt.subplots(len(unique_distances), 1, figsize=(6, 4 * len(unique_distances))) \n",
    "\n",
    "    results = []\n",
    "    confusion_matrices = {}\n",
    "\n",
    "    # ✅ Loop through each unique distance and evaluate model performance\n",
    "    for i, distance in enumerate(unique_distances):\n",
    "        X_test_distance = X_test[X_test[\"distance_m\"] == distance].copy()\n",
    "        y_test_distance = y_test.loc[X_test_distance.index].values.flatten()  # Ensure correct shape\n",
    "\n",
    "        # ✅ Select feature columns\n",
    "        if is_lstm:\n",
    "            feature_columns = [col for col in X_test_distance.columns if col.startswith(\"value\")]\n",
    "\n",
    "        X_test_distance = X_test_distance[feature_columns].values  # Extract feature values\n",
    "\n",
    "        print(f\"Distance: {distance}, X shape: {X_test_distance.shape}, y shape: {y_test_distance.shape}\")\n",
    "\n",
    "        # ✅ Reshape X for LSTM input\n",
    "        if is_lstm:\n",
    "            X_test_distance = X_test_distance.reshape(-1, 500, 1)\n",
    "\n",
    "        # ✅ Predict fall_binary values\n",
    "        y_pred = model.predict(X_test_distance).round().astype(int).flatten()\n",
    "\n",
    "        # ✅ Compute correct and incorrect counts\n",
    "        correct = np.sum(y_pred == y_test_distance)\n",
    "        incorrect = len(y_pred) - correct\n",
    "\n",
    "        # ✅ Compute confusion matrix, ensuring both classes appear\n",
    "        cm = confusion_matrix(y_test_distance, y_pred, labels=[1, 0])\n",
    "\n",
    "        # ✅ Ensure confusion matrix always has shape (2,2)\n",
    "        if cm.shape == (1, 1):  \n",
    "            cm_fixed = np.array([[cm[0, 0], 0], [0, 0]])  \n",
    "        elif cm.shape == (1, 2):  \n",
    "            cm_fixed = np.vstack([cm, [0, 0]])  \n",
    "        elif cm.shape == (2, 1):  \n",
    "            cm_fixed = np.hstack([cm, [[0], [0]]])  \n",
    "        else:\n",
    "            cm_fixed = cm  \n",
    "\n",
    "        # ✅ Correct confusion matrix order:\n",
    "        # TP | FN\n",
    "        # FP | TN\n",
    "        cm_corrected = np.array([\n",
    "            [cm_fixed[0, 0], cm_fixed[1, 0]],  # True Positives, False Negatives\n",
    "            [cm_fixed[0, 1], cm_fixed[1, 1]]   # False Positives, True Negatives\n",
    "        ])\n",
    "\n",
    "        confusion_matrices[distance] = cm_corrected\n",
    "\n",
    "        # ✅ Plot confusion matrix with **correct** labels\n",
    "        sns.heatmap(cm_corrected, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=[\"Actual Fall\", \"Actual No Fall\"], \n",
    "                    yticklabels=[\"Predicted Fall\", \"Predicted No Fall\"],\n",
    "                    ax=axes[i] if len(unique_distances) > 1 else axes)\n",
    "        axes[i].set_title(f\"Confusion Matrix - Distance {distance}\")\n",
    "        axes[i].set_xlabel(\" \")\n",
    "        axes[i].set_ylabel(\" \")\n",
    "\n",
    "        print(f\"Distance {distance}: {correct} correct, {incorrect} incorrect\")\n",
    "\n",
    "        # ✅ Store results\n",
    "        results.append({\n",
    "            \"distance\": distance,\n",
    "            \"correct\": correct,\n",
    "            \"incorrect\": incorrect,\n",
    "            \"total\": len(y_pred),\n",
    "            \"accuracy\": correct / len(y_pred) if len(y_pred) > 0 else 0\n",
    "        })\n",
    "\n",
    "    # ✅ Save and log confusion matrix plot\n",
    "    confusion_matrix_path = \"confusion_matrices_distance.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(confusion_matrix_path)\n",
    "    plt.close()\n",
    "\n",
    "    # ✅ Convert results into a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # ✅ Save results as CSV\n",
    "    results_path = \"distance_results.csv\"\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "\n",
    "    # ✅ Log results in MLflow\n",
    "    mlflow.log_artifact(results_path)\n",
    "    mlflow.log_artifact(confusion_matrix_path)\n",
    "\n",
    "    print(\"\\n📊 Per-Distance Results:\")\n",
    "    print(results_df)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classical Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, model_class, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Defines the Optuna optimization objective with K-Fold Cross-Validation.\n",
    "    \n",
    "    Args:\n",
    "        trial: Optuna trial object.\n",
    "        model_class: The model class (e.g., XGBClassifier, RandomForestClassifier, GradientBoostingClassifier, SVC).\n",
    "        X_train, y_train: Training data (without separate test split).\n",
    "\n",
    "    Returns:\n",
    "        The average F1-score across all folds.\n",
    "    \"\"\"\n",
    "\n",
    "    # Suggest hyperparameters based on model type\n",
    "    if model_class == XGBClassifier:\n",
    "        num_no_falls = sum(y_train == 0)\n",
    "        num_falls = sum(y_train == 1)\n",
    "        default_scale_pos_weight = num_no_falls / num_falls\n",
    "\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0, 10),\n",
    "            \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", default_scale_pos_weight * 0.5, default_scale_pos_weight * 1.5)\n",
    "        }\n",
    "        model = XGBClassifier(**params, objective=\"binary:logistic\", random_state=42)\n",
    "\n",
    "    elif model_class == RandomForestClassifier:\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        }\n",
    "        model = RandomForestClassifier(**params, random_state=42)\n",
    "\n",
    "    elif model_class == GradientBoostingClassifier:\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        }\n",
    "        model = GradientBoostingClassifier(**params, random_state=42)\n",
    "\n",
    "    elif model_class == SVC:\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.1, 100, log=True),\n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"]),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0.001, 10, log=True),\n",
    "        }\n",
    "        model = SVC(**params, probability=True, random_state=42)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model class: {model_class.__name__}\")\n",
    "\n",
    "    # K-Fold Cross-Validation (Stratified to preserve class balance)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    f1_scores = []\n",
    "\n",
    "    ## Loop through each fold\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]  \n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        ## Train and evaluate the model\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "        y_pred = model.predict(X_fold_val)\n",
    "        f1_scores.append(f1_score(y_fold_val, y_pred))\n",
    "\n",
    "    ## Return average F1-score across folds\n",
    "    return np.mean(f1_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_log_classical_model(\n",
    "    model, \n",
    "    X_train, X_test, y_train, y_test, X_test_full,\n",
    "    save_name=\"classification_model\", \n",
    "    experiment_name=\"classical_models_experiment\",\n",
    "    target_column=\"fall_binary\",\n",
    "    feature_columns=None,\n",
    "    if_optuna=True,\n",
    "    n_trials=250,  # Number of hyperparameter tuning trials\n",
    "    dataset_name = \"fall_data.csv\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains a classical ML model (RandomForest, XGBoost, GradientBoosting, or SVM) with optional hyperparameter tuning\n",
    "    and logs everything to MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: A classical ML model (RandomForest, XGBoost, GradientBoosting, or SVM).\n",
    "        X_train, X_test, y_train, y_test: Pre-split training and testing datasets.\n",
    "        save_name: Name to save the trained model.\n",
    "        experiment_name: Name of the MLflow experiment.\n",
    "        n_trials: Number of hyperparameter tuning trials.\n",
    "\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Start MLflow experiment\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        # Identify model class\n",
    "        model_class = type(model)\n",
    "\n",
    "        if if_optuna:\n",
    "            # ✅ Perform hyperparameter optimization\n",
    "            study = optuna.create_study(direction=\"maximize\")\n",
    "            study.optimize(lambda trial: objective(trial, model_class, X_train, y_train), n_trials=n_trials)\n",
    "        \n",
    "            best_params = study.best_params\n",
    "            print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "            # ✅ Train final model with best params\n",
    "            if model_class == XGBClassifier:\n",
    "                best_model = XGBClassifier(**best_params, objective=\"binary:logistic\", use_label_encoder=False)\n",
    "            elif model_class.__name__ == \"GradientBoostingClassifier\":\n",
    "                best_model = model_class(**best_params, random_state=42)\n",
    "            elif model_class.__name__ == \"RandomForestClassifier\":\n",
    "                best_model = model_class(**best_params, random_state=42)\n",
    "            elif model_class == SVC:\n",
    "                best_model = SVC(**best_params, probability=True, random_state=42)  # ✅ Enable probability for ROC AUC\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported model class: {model_class.__name__}\")\n",
    "        else:\n",
    "            best_model = model\n",
    "\n",
    "        best_model.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "        # SVM needs probability predictions for AUC\n",
    "        if hasattr(best_model, \"predict_proba\"):\n",
    "            roc_auc = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "        # ✅ Log model parameters\n",
    "        mlflow.log_param(\"model_type\", best_model.__class__.__name__)\n",
    "        if if_optuna:\n",
    "            for param, value in best_params.items():\n",
    "                mlflow.log_param(param, value)\n",
    "        mlflow.log_param(\"num_features\", X_train.shape[1])\n",
    "\n",
    "        # Log features used for training as list\n",
    "        if feature_columns is not None:\n",
    "            mlflow.log_param(\"features\", feature_columns)\n",
    "        \n",
    "        # Log target column\n",
    "        mlflow.log_param(\"target_column\", target_column)\n",
    "        \n",
    "        mlflow.log_param(\"dataset\", dataset_name)\n",
    "            \n",
    "        # ✅ Log metrics\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "        # ✅ Save best model\n",
    "        models_folder = \"models\"\n",
    "        if not os.path.exists(models_folder):\n",
    "            os.makedirs(models_folder)\n",
    "        save_path = os.path.join(models_folder, f\"{save_name}.pkl\")\n",
    "        joblib.dump(best_model, save_path)\n",
    "        mlflow.log_artifact(save_path)\n",
    "\n",
    "        # Generate and save confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        conf_matrix = np.array([\n",
    "            [conf_matrix[0, 0], conf_matrix[1, 0]],  # True Positives, False Positives\n",
    "            [conf_matrix[0, 1], conf_matrix[1, 1]]   # False Negatives, True Negatives\n",
    "        ])\n",
    "\n",
    "        # Flip the order of labels for visualization\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(\n",
    "            conf_matrix[::-1, ::-1],  # Reverse rows and keep columns the same\n",
    "            annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Actual Fall\", \"Actual No Fall\"], \n",
    "            yticklabels=[\"Predicted Fall\", \"Predicted No Fall\"],\n",
    "        )\n",
    "        plt.xlabel(\" \")\n",
    "        plt.ylabel(\" \")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        conf_matrix_path = \"confusion_matrix.png\"\n",
    "        plt.savefig(conf_matrix_path)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(conf_matrix_path)\n",
    "\n",
    "        print(f\"Model trained with accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "        # ✅ After training and evaluation, call the per-activity evaluation\n",
    "        evaluate_per_activity(best_model, X_test_full, y_test, feature_columns)\n",
    "\n",
    "        # ✅ After training and evaluation, call the per-distance evaluation\n",
    "        evaluate_per_distance(best_model, X_test_full, y_test, feature_columns)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipe(\n",
    "    model, \n",
    "    dataset_name, \n",
    "    save_name=\"fall_model\", \n",
    "    feature_columns=None, \n",
    "    target_column=\"fall_binary\", \n",
    "    experiment_name=\"default_experiment\",\n",
    "    use_early_stopping=True,\n",
    "    if_optuna=True,\n",
    "    n_trials=250\n",
    "):\n",
    "    \"\"\"\n",
    "    General training pipeline for both classical models (XGBoost, RF, SVM) and deep learning models.\n",
    "\n",
    "    Args:\n",
    "        model: The initialized model (LSTM, RNN, RF, XGB, etc.).\n",
    "        dataset_name: The dataset CSV file.\n",
    "        save_name: Name to save the trained model.\n",
    "        feature_columns: List of feature column names.\n",
    "        target_column: The name of the target column.\n",
    "        experiment_name: MLflow experiment name.\n",
    "        use_early_stopping: Whether to use early stopping (for neural networks).\n",
    "        if_optuna: Whether to perform hyperparameter tuning (for tree-based models).\n",
    "\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    # ✅ Prevent overwriting existing models unless explicitly handled\n",
    "    if os.path.exists(f\"models/{save_name}.pkl\") or os.path.exists(f\"models/{save_name}.keras\"):\n",
    "        raise ValueError(f\"Model name '{save_name}' already exists. Choose a new name or delete the existing model.\")\n",
    "\n",
    "    # ✅ Load dataset\n",
    "    df = load_data(dataset_name)\n",
    "\n",
    "    # ✅ Auto-detect feature columns if not explicitly provided\n",
    "    value_columns = [col for col in df.columns if col.startswith(\"value\")]\n",
    "    if value_columns:\n",
    "        feature_columns = value_columns  \n",
    "    elif feature_columns is None:\n",
    "        raise ValueError(\"Feature columns must be specified.\")\n",
    "\n",
    "    # ✅ Ensure target column exists\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' not found in dataset.\")\n",
    "\n",
    "    data_train, data_test = stratified_activity_split(df, target_column=target_column, test_size=0.2, random_state=42)\n",
    "    print(f\"Train shape: {data_train.shape}, Test shape: {data_test.shape}\")\n",
    "\n",
    "    # ✅ Keep full test data (including metadata like 'activity' or 'distance_m')\n",
    "    X_test_full = data_test.copy()  \n",
    "\n",
    "    # ✅ Keep `X_train`, `X_test` as DataFrames & `y_train`, `y_test` as Series\n",
    "    X_train = data_train[feature_columns]  \n",
    "    X_test = data_test[feature_columns]    \n",
    "    y_train = data_train[target_column]  \n",
    "    y_test = data_test[target_column]    \n",
    "\n",
    "    # ✅ Check model type\n",
    "    is_tree = isinstance(model, (XGBClassifier, RandomForestClassifier, GradientBoostingClassifier))\n",
    "    is_svm = isinstance(model, SVC)\n",
    "\n",
    "    if is_svm:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        X_test_full[feature_columns] = scaler.transform(X_test_full[feature_columns])\n",
    "\n",
    "        # ✅ Convert X_train back to DataFrame\n",
    "        X_train = pd.DataFrame(X_train, columns=feature_columns, index=data_train.index)\n",
    "        X_test = pd.DataFrame(X_test, columns=feature_columns, index=data_test.index)\n",
    "        X_test_full[feature_columns] = pd.DataFrame(X_test_full[feature_columns], columns=feature_columns, index=data_test.index)\n",
    "\n",
    "    # ✅ Train tree-based models with optional Optuna hyperparameter tuning\n",
    "    if is_tree or is_svm:\n",
    "        model = train_and_log_classical_model(\n",
    "            model, X_train, X_test, y_train, y_test, X_test_full,\n",
    "            save_name=save_name,\n",
    "            experiment_name=experiment_name,\n",
    "            target_column=target_column,\n",
    "            feature_columns=feature_columns,\n",
    "            if_optuna=if_optuna,\n",
    "            n_trials=n_trials,\n",
    "            dataset_name=dataset_name\n",
    "        )\n",
    "    \n",
    "    # Delete the files activity_results.csv and distance_results.csv\n",
    "    os.remove(\"activity_results.csv\")\n",
    "    os.remove(\"distance_results.csv\")\n",
    "    os.remove(\"confusion_matrices_distance.png\")\n",
    "    os.remove(\"confusion_matrix.png\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mlflow.tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "def train_model(\n",
    "    model, \n",
    "    dataset_name, \n",
    "    save_name=\"lstm_fall_model\", \n",
    "    feature_columns=None, \n",
    "    target_column=\"fall_binary\", \n",
    "    experiment_name=\"default_experiment\",\n",
    "    use_early_stopping=True  # ✅ Option to enable/disable early stopping\n",
    "):\n",
    "    \"\"\"\n",
    "    Loads the dataset, reshapes it for RNN, trains the model, and logs everything to MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: The RNN model (already defined).\n",
    "        dataset_name: The name of the dataset CSV file.\n",
    "        save_name: Name to save the trained model.\n",
    "        feature_columns: List of feature column names (overwritten if 'value' columns exist).\n",
    "        target_column: The name of the target column.\n",
    "        experiment_name: Name of the MLflow experiment.\n",
    "        use_early_stopping: Whether to enable early stopping based on validation loss.\n",
    "\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load dataset\n",
    "    df = load_data(dataset_name)\n",
    "\n",
    "    # Auto-detect feature columns if they start with \"value\"\n",
    "    value_columns = [col for col in df.columns if col.startswith(\"value\")]\n",
    "    if value_columns:\n",
    "        feature_columns = value_columns  # Override feature selection\n",
    "    elif feature_columns is None:\n",
    "        raise ValueError(\"Feature columns must be specified if no 'value' columns exist.\")\n",
    "\n",
    "    # Ensure target column exists\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' not found in dataset.\")\n",
    "\n",
    "    # Train-test split but keep the full dataset for evaluation\n",
    "    data_train, data_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    print(f\"Train shape: {data_train.shape}, Test shape: {data_test.shape}\")\n",
    "\n",
    "    X_train = data_train[feature_columns].values\n",
    "    X_test = data_test[feature_columns].values\n",
    "\n",
    "    y_train = data_train[target_column].values\n",
    "    y_test = data_test[target_column].values\n",
    "    \n",
    "    X_test_full = X_test.copy()  # Keep a copy of the test data for evaluation\n",
    "    y_test_full = y_test.copy()\n",
    "\n",
    "    X_train = X_train[feature_columns].values\n",
    "    X_test = X_test[feature_columns].values\n",
    "\n",
    "    # Reshape X: (num_samples, timesteps=500, num_features)\n",
    "    if value_columns:\n",
    "        num_features = len(feature_columns) // 500  # Calculate how many features per timestep\n",
    "        X_test = X_test.reshape(-1, 500, num_features)\n",
    "        X_train = X_train.reshape(-1, 500, num_features)\n",
    "    else:\n",
    "        num_features = len(feature_columns)\n",
    "\n",
    "    # Print shapes\n",
    "    print(f\"X_test_full shape: {X_test_full.shape}\")\n",
    "    print(f\"y_test_full shape: {y_test_full.shape}\")\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "    is_lstm = isinstance(model, tf.keras.Model)\n",
    "\n",
    "    if is_lstm:\n",
    "        # ✅ Set up Early Stopping (if enabled)\n",
    "        callbacks = []\n",
    "        if use_early_stopping:\n",
    "            early_stopping = EarlyStopping(\n",
    "                monitor=\"val_loss\", patience=3, restore_best_weights=True, verbose=1\n",
    "            )\n",
    "            callbacks.append(early_stopping)\n",
    "\n",
    "    # Start MLflow experiment\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        print(f\"X_train shape: {X_train.shape}\")  # Should be (num_samples, timesteps, num_features)\n",
    "        print(f\"y_train shape: {y_train.shape}\")  # Should be (num_samples,)\n",
    "\n",
    "        # ✅ Log dataset name\n",
    "        mlflow.log_param(\"dataset_name\", dataset_name)  \n",
    "\n",
    "        if is_lstm:\n",
    "            # Train the model and log history\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                validation_data=(X_test, y_test),\n",
    "                callbacks=callbacks  # ✅ Apply Early Stopping if enabled\n",
    "            )\n",
    "        else:\n",
    "            model.fit(X_train, y_train)  # No need for epochs, batch size, or callbacks\n",
    "            \n",
    "        if is_lstm:\n",
    "            # Evaluate model\n",
    "            loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        else:\n",
    "            y_pred = model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # ✅ After training and evaluation, call the per-activity evaluation\n",
    "        results_df = evaluate_per_activity(model, X_test_full, y_test_full, target_column, feature_columns)\n",
    "        \n",
    "        # ✅ After training and evaluation, call the per-distance evaluation\n",
    "        evaluate_per_distance(model, X_test_full, y_test_full, target_column, feature_columns)\n",
    "\n",
    "        # ✅ Log per-activity accuracy in MLflow\n",
    "        mlflow.log_artifact(\"activity_results.csv\")\n",
    "\n",
    "        # ✅ Log model parameters\n",
    "        mlflow.log_param(\"num_features_used\", len(feature_columns))\n",
    "        mlflow.log_param(\"model_type\", model.__class__.__name__)\n",
    "\n",
    "        if is_lstm:\n",
    "            mlflow.log_param(\"epochs\", EPOCHS)\n",
    "            mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "            mlflow.log_param(\"optimizer\", model.optimizer.__class__.__name__)\n",
    "            mlflow.log_param(\"loss_function\", model.loss)\n",
    "            mlflow.log_param(\"early_stopping\", use_early_stopping)  # ✅ Log whether early stopping was used\n",
    "            mlflow.log_metric(\"final_loss\", loss)\n",
    "\n",
    "        # ✅ Log metrics\n",
    "        mlflow.log_metric(\"final_accuracy\", accuracy)\n",
    "\n",
    "        if is_lstm:\n",
    "            # ✅ Log accuracy and loss per epoch\n",
    "            for epoch, (train_acc, val_acc, train_loss, val_loss) in enumerate(zip(history.history['accuracy'], history.history['val_accuracy'], history.history['loss'], history.history['val_loss'])):\n",
    "                mlflow.log_metric(\"train_accuracy_epoch\", train_acc, step=epoch)\n",
    "                mlflow.log_metric(\"val_accuracy_epoch\", val_acc, step=epoch)\n",
    "                mlflow.log_metric(\"train_loss_epoch\", train_loss, step=epoch)\n",
    "                mlflow.log_metric(\"val_loss_epoch\", val_loss, step=epoch)\n",
    "\n",
    "        # ✅ Ensure models folder exists\n",
    "        models_folder = \"models\"\n",
    "        if not os.path.exists(models_folder):\n",
    "            os.makedirs(models_folder)\n",
    "\n",
    "        save_path = os.path.join(models_folder, save_name)\n",
    "\n",
    "        if is_lstm:\n",
    "            model.save(save_path + \".keras\")  # ✅ Save Keras model\n",
    "            mlflow.log_artifact(save_path + \".keras\")\n",
    "        else:\n",
    "            import joblib\n",
    "            joblib.dump(model, save_path + \".pkl\")  # ✅ Save tree-based model\n",
    "            mlflow.log_artifact(save_path + \".pkl\")\n",
    "\n",
    "        # ✅ Log the saved model file as an artifact in MLflow\n",
    "        mlflow.log_artifact(save_path + \".pkl\")\n",
    "\n",
    "        # ✅ Save confusion matrix\n",
    "        y_pred = model.predict(X_test).round()\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # Compute additional metrics\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "\n",
    "        # Log additional metrics\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "        # ✅ Save and log confusion matrix\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"No Fall\", \"Fall\"], yticklabels=[\"No Fall\", \"Fall\"])\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        conf_matrix_path = \"confusion_matrix.png\"\n",
    "        plt.savefig(conf_matrix_path)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(conf_matrix_path)\n",
    "\n",
    "        print(f\"Model trained with accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "        # Delete the files activity_results.csv and distance_results.csv\n",
    "        os.remove(\"activity_results.csv\")\n",
    "        os.remove(\"distance_results.csv\")\n",
    "        os.remove(\"confusion_matrices_distance.png\")\n",
    "        os.remove(\"confusion_matrix.png\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# XGBoost Model\n",
    "# ==========================\n",
    "\n",
    "def build_xgboost_model():\n",
    "    \"\"\"\n",
    "    Builds an XGBoost model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A compiled XGBoost model.\n",
    "    \"\"\"\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.11,\n",
    "        objective=\"binary:logistic\",\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ==========================\n",
    "# Random Forest Model\n",
    "# ==========================\n",
    "\n",
    "def build_random_forest_model():\n",
    "    \"\"\"\n",
    "    Builds a Random Forest model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Random Forest model.\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ==========================\n",
    "# GBM Model\n",
    "# ==========================\n",
    "def build_gradient_boosting_model():\n",
    "    \"\"\"\n",
    "    Builds a Gradient Boosting (GBM) model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Gradient Boosting model.\n",
    "    \"\"\"\n",
    "    return GradientBoostingClassifier(\n",
    "        n_estimators=200,  # Number of boosting stages\n",
    "        learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n",
    "        max_depth=5,  # Maximum depth of the trees\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "# ==========================\n",
    "# SVM Model\n",
    "# ==========================\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def build_svm_model():\n",
    "    \"\"\"\n",
    "    Builds an SVM model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A configured SVM model.\n",
    "    \"\"\"\n",
    "    model = SVC(\n",
    "        kernel=\"rbf\",  # Radial Basis Function (RBF) kernel (default)\n",
    "        C=1.0,         # Regularization parameter\n",
    "        gamma=\"scale\",  # Kernel coefficient\n",
    "        probability=True,  # Enable probability estimates (needed for ROC AUC)\n",
    "        random_state=42\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# RNN Model\n",
    "# ==========================\n",
    "def build_rnn_model():\n",
    "    \"\"\"\n",
    "    Builds a simple RNN model using Keras.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        SimpleRNN(RNN_UNITS, input_shape=INPUT_SHAPE, return_sequences=True),\n",
    "        SimpleRNN(RNN_UNITS),\n",
    "        Dense(DENSE_UNITS, activation=\"relu\"),\n",
    "        Dropout(DROPOUT_RATE),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNCTION, metrics=METRICS)\n",
    "    return model\n",
    "\n",
    "# ==========================\n",
    "# LSTM Model\n",
    "# ==========================\n",
    "def build_lstm_model(l2_lambda=0.001, dropout_rate=0.2, clipnorm=1.0):\n",
    "    \"\"\"\n",
    "    Builds an LSTM-based model with L2 regularization, dropout, and gradient clipping.\n",
    "\n",
    "    Args:\n",
    "        l2_lambda: Strength of L2 regularization (default: 0.001).\n",
    "        dropout_rate: Dropout rate to reduce overfitting (default: 0.2).\n",
    "        clipnorm: Gradient clipping norm (default: 1.0).\n",
    "\n",
    "    Returns:\n",
    "        A compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(RNN_UNITS, input_shape=INPUT_SHAPE, return_sequences=True, \n",
    "             kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),  # Dropout after first LSTM layer\n",
    "        LSTM(RNN_UNITS, kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),  # Dropout after second LSTM layer\n",
    "        Dense(DENSE_UNITS, activation=\"relu\", kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),  # Dropout before final layer\n",
    "        Dense(1, activation=\"sigmoid\")  # Output layer for binary classification\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(clipnorm=clipnorm)\n",
    "    model.compile(optimizer=optimizer, loss=LOSS_FUNCTION, metrics=METRICS)\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Bidirectional LSTM Model (Optional)\n",
    "# ==========================\n",
    "def build_bidirectional_lstm():\n",
    "    \"\"\"\n",
    "    Builds a Bidirectional LSTM model for improved sequence learning.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(RNN_UNITS, return_sequences=True), input_shape=INPUT_SHAPE),\n",
    "        Bidirectional(LSTM(RNN_UNITS)),\n",
    "        Dense(DENSE_UNITS, activation=\"relu\"),\n",
    "        Dropout(DROPOUT_RATE),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNCTION, metrics=METRICS)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# CONFIGURABLE VARIABLES\n",
    "# ==========================\n",
    "RNN_UNITS = 128           # Number of RNN/LSTM units\n",
    "DENSE_UNITS = 64         # Number of neurons in the dense layer\n",
    "DROPOUT_RATE = 0.1      # Dropout rate for regularization\n",
    "OPTIMIZER = \"adam\"       # Optimizer: \"adam\", \"sgd\", \"rmsprop\", etc.\n",
    "LOSS_FUNCTION = \"binary_crossentropy\"  # \"binary_crossentropy\" for classification\n",
    "METRICS = [\"accuracy\"]   # Metrics to monitor\n",
    "EPOCHS = 10              # Number of training epochs\n",
    "BATCH_SIZE = 16          # Batch size for training\n",
    "INPUT_SHAPE = (500, 1)   # (Time steps, Features) - Adjust based on your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.11, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=400, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Initialize the Model\n",
    "# ==========================\n",
    "model = build_xgboost_model()  # Change this to your desired model\n",
    "# print(model.summary())  # Print model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1016, 19), Test shape: (254, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/15 18:48:45 INFO mlflow.tracking.fluent: Experiment with name 'Classic Models MPU' does not exist. Creating a new experiment.\n",
      "[I 2025-03-15 18:48:48,065] A new study created in memory with name: no-name-72b037bb-0a80-4438-a848-fdaac2505e9a\n",
      "[I 2025-03-15 18:48:48,862] Trial 0 finished with value: 0.8833248895967355 and parameters: {'n_estimators': 350, 'max_depth': 13, 'learning_rate': 0.01326633577756169, 'subsample': 0.7402009890563781, 'colsample_bytree': 0.7827856259087405, 'gamma': 6.8351545549475485, 'scale_pos_weight': 2.6894351601492072}. Best is trial 0 with value: 0.8833248895967355.\n",
      "[I 2025-03-15 18:48:49,081] Trial 1 finished with value: 0.9125735330613379 and parameters: {'n_estimators': 50, 'max_depth': 7, 'learning_rate': 0.2674892882190184, 'subsample': 0.6074459880668076, 'colsample_bytree': 0.6852310291618152, 'gamma': 0.060700675155999084, 'scale_pos_weight': 1.2034497555015975}. Best is trial 1 with value: 0.9125735330613379.\n",
      "[I 2025-03-15 18:48:50,317] Trial 2 finished with value: 0.9036172070051061 and parameters: {'n_estimators': 400, 'max_depth': 12, 'learning_rate': 0.01030758812221279, 'subsample': 0.8704878216398738, 'colsample_bytree': 0.9344772908146818, 'gamma': 4.125230531307816, 'scale_pos_weight': 2.680322760735257}. Best is trial 1 with value: 0.9125735330613379.\n",
      "[I 2025-03-15 18:48:50,459] Trial 3 finished with value: 0.9020163516613945 and parameters: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.10543660047635313, 'subsample': 0.8569951799309455, 'colsample_bytree': 0.9734586559468429, 'gamma': 3.576025632042179, 'scale_pos_weight': 2.3408461664375015}. Best is trial 1 with value: 0.9125735330613379.\n",
      "[I 2025-03-15 18:48:50,690] Trial 4 finished with value: 0.8858355976187665 and parameters: {'n_estimators': 150, 'max_depth': 14, 'learning_rate': 0.08228452043497148, 'subsample': 0.7540436640611287, 'colsample_bytree': 0.7965365281290219, 'gamma': 6.753624068792372, 'scale_pos_weight': 2.853009935549322}. Best is trial 1 with value: 0.9125735330613379.\n",
      "[I 2025-03-15 18:48:51,834] Trial 5 finished with value: 0.9023079091262008 and parameters: {'n_estimators': 500, 'max_depth': 16, 'learning_rate': 0.017497883101065995, 'subsample': 0.6980065744590557, 'colsample_bytree': 0.7987888479470348, 'gamma': 2.7955787667809586, 'scale_pos_weight': 2.4100922435260257}. Best is trial 1 with value: 0.9125735330613379.\n",
      "[I 2025-03-15 18:48:52,307] Trial 6 finished with value: 0.8978822216070755 and parameters: {'n_estimators': 450, 'max_depth': 13, 'learning_rate': 0.19298228828182218, 'subsample': 0.6895450256395299, 'colsample_bytree': 0.8663382606855365, 'gamma': 3.84791351662387, 'scale_pos_weight': 2.399581429304426}. Best is trial 1 with value: 0.9125735330613379.\n",
      "[I 2025-03-15 18:48:52,437] Trial 7 finished with value: 0.8945312900815294 and parameters: {'n_estimators': 100, 'max_depth': 18, 'learning_rate': 0.2009144413618847, 'subsample': 0.9234449409397683, 'colsample_bytree': 0.8203857236121366, 'gamma': 6.252918897310549, 'scale_pos_weight': 1.1708226505629293}. Best is trial 1 with value: 0.9125735330613379.\n",
      "[I 2025-03-15 18:48:53,228] Trial 8 finished with value: 0.9062456907451502 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.0369109994401821, 'subsample': 0.8803277754303306, 'colsample_bytree': 0.7611597076868537, 'gamma': 3.1293813680381657, 'scale_pos_weight': 2.110018506277392}. Best is trial 1 with value: 0.9125735330613379.\n",
      "[I 2025-03-15 18:48:53,382] Trial 9 finished with value: 0.8591245496190382 and parameters: {'n_estimators': 50, 'max_depth': 18, 'learning_rate': 0.011640520631203348, 'subsample': 0.6125601673532314, 'colsample_bytree': 0.771049923030485, 'gamma': 9.711601628949893, 'scale_pos_weight': 2.3433394509639793}. Best is trial 1 with value: 0.9125735330613379.\n",
      "[I 2025-03-15 18:48:54,151] Trial 10 finished with value: 0.9098914629659074 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.03662345166985819, 'subsample': 0.6234372798362369, 'colsample_bytree': 0.6115147166247946, 'gamma': 0.14743813397451336, 'scale_pos_weight': 1.2472736808898137}. Best is trial 1 with value: 0.9125735330613379.\n",
      "[I 2025-03-15 18:48:54,887] Trial 11 finished with value: 0.9067168597913042 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.03958990777934838, 'subsample': 0.6055816703422752, 'colsample_bytree': 0.6227602487570817, 'gamma': 0.2518031686576319, 'scale_pos_weight': 1.2149677211830616}. Best is trial 1 with value: 0.9125735330613379.\n",
      "[I 2025-03-15 18:48:55,978] Trial 12 finished with value: 0.9101176691420594 and parameters: {'n_estimators': 250, 'max_depth': 7, 'learning_rate': 0.02512968769050711, 'subsample': 0.997712381785315, 'colsample_bytree': 0.6044648649559349, 'gamma': 0.218120688372495, 'scale_pos_weight': 1.5914437153245373}. Best is trial 1 with value: 0.9125735330613379.\n",
      "[I 2025-03-15 18:48:56,336] Trial 13 finished with value: 0.908458839363489 and parameters: {'n_estimators': 300, 'max_depth': 9, 'learning_rate': 0.27921719417528795, 'subsample': 0.7985311110400943, 'colsample_bytree': 0.6941415339295283, 'gamma': 1.7413015733729353, 'scale_pos_weight': 1.6497775185978452}. Best is trial 1 with value: 0.9125735330613379.\n",
      "[I 2025-03-15 18:48:56,857] Trial 14 finished with value: 0.8935654038316345 and parameters: {'n_estimators': 250, 'max_depth': 3, 'learning_rate': 0.023454344459355455, 'subsample': 0.963845537407019, 'colsample_bytree': 0.6818013162982935, 'gamma': 1.4958968579122045, 'scale_pos_weight': 1.674281168326511}. Best is trial 1 with value: 0.9125735330613379.\n",
      "[I 2025-03-15 18:48:57,182] Trial 15 finished with value: 0.9098657763350829 and parameters: {'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.07424016831180508, 'subsample': 0.99985387334289, 'colsample_bytree': 0.681356015588361, 'gamma': 1.548609521846807, 'scale_pos_weight': 1.6037764774623309}. Best is trial 1 with value: 0.9125735330613379.\n",
      "[I 2025-03-15 18:48:58,544] Trial 16 finished with value: 0.9130762606113505 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.023834275390112836, 'subsample': 0.7877862983022043, 'colsample_bytree': 0.6470643697975472, 'gamma': 0.27461775848927256, 'scale_pos_weight': 1.4130494878847788}. Best is trial 16 with value: 0.9130762606113505.\n",
      "[I 2025-03-15 18:48:58,884] Trial 17 finished with value: 0.8878187613843351 and parameters: {'n_estimators': 350, 'max_depth': 9, 'learning_rate': 0.12553465230852873, 'subsample': 0.8160079847909545, 'colsample_bytree': 0.7145914489594448, 'gamma': 9.98112020456614, 'scale_pos_weight': 1.4084713953626078}. Best is trial 16 with value: 0.9130762606113505.\n",
      "[I 2025-03-15 18:48:59,267] Trial 18 finished with value: 0.8920579799429692 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.051436653737520426, 'subsample': 0.6712031048470916, 'colsample_bytree': 0.6490879429766417, 'gamma': 5.199763587115745, 'scale_pos_weight': 1.961782893526201}. Best is trial 16 with value: 0.9130762606113505.\n",
      "[I 2025-03-15 18:48:59,730] Trial 19 finished with value: 0.8949969397827612 and parameters: {'n_estimators': 150, 'max_depth': 8, 'learning_rate': 0.023168617596070487, 'subsample': 0.7536617375633564, 'colsample_bytree': 0.733135331385022, 'gamma': 2.281554239448024, 'scale_pos_weight': 1.068597040151676}. Best is trial 16 with value: 0.9130762606113505.\n",
      "[I 2025-03-15 18:49:00,249] Trial 20 finished with value: 0.901832303126595 and parameters: {'n_estimators': 350, 'max_depth': 10, 'learning_rate': 0.29738019148013556, 'subsample': 0.6459485593280588, 'colsample_bytree': 0.6619925477234442, 'gamma': 1.0929894725817466, 'scale_pos_weight': 1.9874780636984342}. Best is trial 16 with value: 0.9130762606113505.\n",
      "[I 2025-03-15 18:49:01,316] Trial 21 finished with value: 0.9144325196533931 and parameters: {'n_estimators': 250, 'max_depth': 7, 'learning_rate': 0.02582322758877673, 'subsample': 0.9162495818817692, 'colsample_bytree': 0.6190035212235673, 'gamma': 0.023434321772999714, 'scale_pos_weight': 1.4212362893600254}. Best is trial 21 with value: 0.9144325196533931.\n",
      "[I 2025-03-15 18:49:01,963] Trial 22 finished with value: 0.9053384214458842 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.019320718648189406, 'subsample': 0.9387562180772887, 'colsample_bytree': 0.6534922937929606, 'gamma': 0.8299609984514873, 'scale_pos_weight': 1.4163120912748726}. Best is trial 21 with value: 0.9144325196533931.\n",
      "[I 2025-03-15 18:49:02,264] Trial 23 finished with value: 0.9026301198355295 and parameters: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.05385884587376067, 'subsample': 0.8106646086749068, 'colsample_bytree': 0.7299243012121368, 'gamma': 2.336917287666318, 'scale_pos_weight': 1.4104814323008499}. Best is trial 21 with value: 0.9144325196533931.\n",
      "[I 2025-03-15 18:49:03,542] Trial 24 finished with value: 0.9150837831189632 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.027078019250244716, 'subsample': 0.9005145390101286, 'colsample_bytree': 0.6386074852385396, 'gamma': 0.0035661351394171703, 'scale_pos_weight': 1.8094376117138238}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:03,957] Trial 25 finished with value: 0.8819971545529969 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.03180506141987791, 'subsample': 0.9053264838323666, 'colsample_bytree': 0.6003689849168277, 'gamma': 8.2637374808044, 'scale_pos_weight': 1.8864555129206515}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:04,980] Trial 26 finished with value: 0.9122023573376381 and parameters: {'n_estimators': 250, 'max_depth': 7, 'learning_rate': 0.015482492927104716, 'subsample': 0.8536280208841032, 'colsample_bytree': 0.6401841652287505, 'gamma': 0.9989639433149444, 'scale_pos_weight': 1.8053441021761691}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:05,661] Trial 27 finished with value: 0.8973373936419848 and parameters: {'n_estimators': 400, 'max_depth': 11, 'learning_rate': 0.02760882238543707, 'subsample': 0.8343144243249729, 'colsample_bytree': 0.860958341458433, 'gamma': 4.981517785203205, 'scale_pos_weight': 3.1263639768384532}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:06,175] Trial 28 finished with value: 0.9060159919331332 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.045859624004618196, 'subsample': 0.8983203759603696, 'colsample_bytree': 0.6292724703631424, 'gamma': 2.344651846332462, 'scale_pos_weight': 1.4533165711175404}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:07,276] Trial 29 finished with value: 0.9111272918258212 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.015175295610744703, 'subsample': 0.9458947080335518, 'colsample_bytree': 0.7150446129273789, 'gamma': 0.7328969121101261, 'scale_pos_weight': 1.755430919809228}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:08,442] Trial 30 finished with value: 0.9105113916475609 and parameters: {'n_estimators': 400, 'max_depth': 15, 'learning_rate': 0.019765183444729953, 'subsample': 0.7782271503405754, 'colsample_bytree': 0.7463989654940096, 'gamma': 1.6829080865883363, 'scale_pos_weight': 2.140971024783793}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:09,492] Trial 31 finished with value: 0.9127744898668082 and parameters: {'n_estimators': 250, 'max_depth': 7, 'learning_rate': 0.030438847098322175, 'subsample': 0.7144996761897712, 'colsample_bytree': 0.6709648657893676, 'gamma': 0.034910195906632906, 'scale_pos_weight': 1.2755591662877674}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:10,551] Trial 32 finished with value: 0.9130762606113505 and parameters: {'n_estimators': 250, 'max_depth': 7, 'learning_rate': 0.031611992405541564, 'subsample': 0.7810414363445776, 'colsample_bytree': 0.6655816124444605, 'gamma': 0.006914585221809717, 'scale_pos_weight': 1.5156285211456433}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:11,313] Trial 33 finished with value: 0.9010151337366004 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.0126464791269272, 'subsample': 0.7840594244407183, 'colsample_bytree': 0.634295486413358, 'gamma': 0.7012247653193899, 'scale_pos_weight': 1.511997380504451}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:11,876] Trial 34 finished with value: 0.9115234458171934 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.06946026101622722, 'subsample': 0.8320024098801396, 'colsample_bytree': 0.7003850403841456, 'gamma': 1.261370745688565, 'scale_pos_weight': 1.7727140079580543}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:13,216] Trial 35 finished with value: 0.9081207757046433 and parameters: {'n_estimators': 250, 'max_depth': 11, 'learning_rate': 0.02222842963852797, 'subsample': 0.7324607488027943, 'colsample_bytree': 0.659306340372682, 'gamma': 0.00251413018388566, 'scale_pos_weight': 1.3338549970219562}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:13,757] Trial 36 finished with value: 0.9043654126407542 and parameters: {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.031124646681964456, 'subsample': 0.7724429397911696, 'colsample_bytree': 0.9902017903868203, 'gamma': 0.6129717095366483, 'scale_pos_weight': 1.0671752174365954}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:14,370] Trial 37 finished with value: 0.9095185541128608 and parameters: {'n_estimators': 350, 'max_depth': 10, 'learning_rate': 0.04411946206493166, 'subsample': 0.8707393741426926, 'colsample_bytree': 0.6263270711746836, 'gamma': 1.949275734563365, 'scale_pos_weight': 1.555737666036845}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:15,228] Trial 38 finished with value: 0.9016307773028194 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.016297125368716758, 'subsample': 0.9708030401179282, 'colsample_bytree': 0.7011338160578934, 'gamma': 2.8445848475727336, 'scale_pos_weight': 1.731708366724143}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:15,593] Trial 39 finished with value: 0.8943665548754611 and parameters: {'n_estimators': 250, 'max_depth': 6, 'learning_rate': 0.05977279192615397, 'subsample': 0.8957659354256137, 'colsample_bytree': 0.9381277213052964, 'gamma': 4.346404925436892, 'scale_pos_weight': 1.88782033684266}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:16,342] Trial 40 finished with value: 0.9003060261419057 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.019620021023552824, 'subsample': 0.8478942038494878, 'colsample_bytree': 0.670918330184824, 'gamma': 3.447316390373037, 'scale_pos_weight': 2.2251643345218235}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:17,663] Trial 41 finished with value: 0.911279603950207 and parameters: {'n_estimators': 250, 'max_depth': 20, 'learning_rate': 0.02952678710188355, 'subsample': 0.7183298070692973, 'colsample_bytree': 0.6684456011017158, 'gamma': 0.029424628152549863, 'scale_pos_weight': 1.305965709308245}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:18,591] Trial 42 finished with value: 0.9065285175994854 and parameters: {'n_estimators': 250, 'max_depth': 7, 'learning_rate': 0.03411012905732601, 'subsample': 0.7177649786815556, 'colsample_bytree': 0.6413064587071929, 'gamma': 0.5380359419259909, 'scale_pos_weight': 1.3171925714970931}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:19,408] Trial 43 finished with value: 0.9127972445464984 and parameters: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.02692424042078238, 'subsample': 0.7545132150380944, 'colsample_bytree': 0.6144740101094395, 'gamma': 0.5293720164753206, 'scale_pos_weight': 1.148067007163915}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:20,228] Trial 44 finished with value: 0.8926458304645287 and parameters: {'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.010168816534452386, 'subsample': 0.7500624264618487, 'colsample_bytree': 0.6159299491023736, 'gamma': 1.1392298704885184, 'scale_pos_weight': 1.146288573035731}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:20,968] Trial 45 finished with value: 0.9148531547411858 and parameters: {'n_estimators': 150, 'max_depth': 13, 'learning_rate': 0.03967394448442817, 'subsample': 0.787649472667581, 'colsample_bytree': 0.6167521746135183, 'gamma': 0.4924382082300972, 'scale_pos_weight': 1.4940666276082144}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:21,188] Trial 46 finished with value: 0.8958611292760533 and parameters: {'n_estimators': 100, 'max_depth': 14, 'learning_rate': 0.03856870199539964, 'subsample': 0.793648212376318, 'colsample_bytree': 0.6476000444382403, 'gamma': 7.45540866140501, 'scale_pos_weight': 1.5010696155034162}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:21,701] Trial 47 finished with value: 0.9080969887955181 and parameters: {'n_estimators': 150, 'max_depth': 13, 'learning_rate': 0.10894789389123961, 'subsample': 0.8137654744914697, 'colsample_bytree': 0.6011251647085603, 'gamma': 0.42316094017525524, 'scale_pos_weight': 1.6355340857277412}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:22,563] Trial 48 finished with value: 0.9092451110523593 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.04165399949468376, 'subsample': 0.7722552659480179, 'colsample_bytree': 0.7823881049044042, 'gamma': 2.0645335478488573, 'scale_pos_weight': 2.5065388112192424}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:23,377] Trial 49 finished with value: 0.9122481186723725 and parameters: {'n_estimators': 400, 'max_depth': 15, 'learning_rate': 0.04777384016973497, 'subsample': 0.8776166237410328, 'colsample_bytree': 0.8546763570952708, 'gamma': 0.955378189852689, 'scale_pos_weight': 1.5567185058114221}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:23,631] Trial 50 finished with value: 0.8896942467297457 and parameters: {'n_estimators': 50, 'max_depth': 17, 'learning_rate': 0.021534655966271406, 'subsample': 0.9172004359513785, 'colsample_bytree': 0.8213805464076832, 'gamma': 1.5568217639704853, 'scale_pos_weight': 1.67582893002928}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:24,231] Trial 51 finished with value: 0.9022684632440731 and parameters: {'n_estimators': 150, 'max_depth': 7, 'learning_rate': 0.025038602684079904, 'subsample': 0.7627175354259897, 'colsample_bytree': 0.6174553325136767, 'gamma': 0.5817013164097609, 'scale_pos_weight': 1.207462230347537}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:24,979] Trial 52 finished with value: 0.9133725271618403 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.026944309693621157, 'subsample': 0.7362961187741324, 'colsample_bytree': 0.6171188715554672, 'gamma': 0.37726549870455217, 'scale_pos_weight': 1.3804873666536757}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:25,266] Trial 53 finished with value: 0.9038957846962523 and parameters: {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.03622388000266314, 'subsample': 0.7356467962631864, 'colsample_bytree': 0.6317327087052915, 'gamma': 0.3481861323068464, 'scale_pos_weight': 1.4629462655641337}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:25,805] Trial 54 finished with value: 0.897841211812725 and parameters: {'n_estimators': 150, 'max_depth': 6, 'learning_rate': 0.025665468432475403, 'subsample': 0.6804190005633339, 'colsample_bytree': 0.6893755358164683, 'gamma': 1.2170324655740727, 'scale_pos_weight': 1.3589167347646847}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:26,950] Trial 55 finished with value: 0.9128214949966615 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.017586387636303442, 'subsample': 0.795165344862199, 'colsample_bytree': 0.6484365658794933, 'gamma': 1.2882444778492417, 'scale_pos_weight': 1.8395845808208606}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:27,937] Trial 56 finished with value: 0.908975873380409 and parameters: {'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.06275487626965771, 'subsample': 0.8296007317619459, 'colsample_bytree': 0.6797249846484467, 'gamma': 0.004408596023194391, 'scale_pos_weight': 1.394561512122407}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:28,549] Trial 57 finished with value: 0.9115793174217088 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.03440816276140978, 'subsample': 0.6985205836312118, 'colsample_bytree': 0.6151158135264202, 'gamma': 2.619131916206858, 'scale_pos_weight': 2.007881682224481}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:29,473] Trial 58 finished with value: 0.9117555501974868 and parameters: {'n_estimators': 250, 'max_depth': 13, 'learning_rate': 0.028105313580116875, 'subsample': 0.9768153325533773, 'colsample_bytree': 0.6552163303920636, 'gamma': 0.8787706365837861, 'scale_pos_weight': 1.6994401882428238}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:30,327] Trial 59 finished with value: 0.9067328506525962 and parameters: {'n_estimators': 150, 'max_depth': 11, 'learning_rate': 0.022391533416079638, 'subsample': 0.9311933632460563, 'colsample_bytree': 0.6004377064475498, 'gamma': 0.3083813332478602, 'scale_pos_weight': 1.5913744893993678}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:30,865] Trial 60 finished with value: 0.89767753197263 and parameters: {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.017702780564595844, 'subsample': 0.7397879775453938, 'colsample_bytree': 0.6303395542595152, 'gamma': 1.783879620178105, 'scale_pos_weight': 1.52710685059995}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:32,000] Trial 61 finished with value: 0.9114885848094193 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.0176021224941237, 'subsample': 0.7954391810059138, 'colsample_bytree': 0.6440781104854774, 'gamma': 1.2509696942288997, 'scale_pos_weight': 1.8499470844347041}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:32,953] Trial 62 finished with value: 0.9084711781061745 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.014101125539524513, 'subsample': 0.8089056627364714, 'colsample_bytree': 0.6570083800922419, 'gamma': 0.3221604898403491, 'scale_pos_weight': 1.4710005414383935}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:33,945] Trial 63 finished with value: 0.9097638004074696 and parameters: {'n_estimators': 250, 'max_depth': 8, 'learning_rate': 0.019125716203799447, 'subsample': 0.8221796167298824, 'colsample_bytree': 0.6409166271862813, 'gamma': 1.3421418183308667, 'scale_pos_weight': 2.0315645312426582}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:35,050] Trial 64 finished with value: 0.9144988924597888 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.024561137058011908, 'subsample': 0.7858982042088392, 'colsample_bytree': 0.6230444928055954, 'gamma': 0.7563829841856163, 'scale_pos_weight': 1.2248068639165703}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:36,057] Trial 65 finished with value: 0.9145925322095956 and parameters: {'n_estimators': 350, 'max_depth': 10, 'learning_rate': 0.03305595105875327, 'subsample': 0.7841572105198423, 'colsample_bytree': 0.6241204512226103, 'gamma': 0.8187938004451363, 'scale_pos_weight': 1.2146310673516352}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:36,624] Trial 66 finished with value: 0.900818617027376 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.23855324021771154, 'subsample': 0.7688935797202157, 'colsample_bytree': 0.6240135958897006, 'gamma': 0.8543079806785027, 'scale_pos_weight': 1.239903259455587}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:37,087] Trial 67 finished with value: 0.8879923997892163 and parameters: {'n_estimators': 350, 'max_depth': 12, 'learning_rate': 0.02461728875449771, 'subsample': 0.9521211655009343, 'colsample_bytree': 0.6070887125321395, 'gamma': 9.053878572771684, 'scale_pos_weight': 1.1966280876986448}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:37,516] Trial 68 finished with value: 0.8947061620263386 and parameters: {'n_estimators': 350, 'max_depth': 10, 'learning_rate': 0.0404806972541447, 'subsample': 0.8443698904346338, 'colsample_bytree': 0.6210743383638976, 'gamma': 5.845081137967777, 'scale_pos_weight': 1.0818824883279514}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:38,472] Trial 69 finished with value: 0.9149659195572483 and parameters: {'n_estimators': 350, 'max_depth': 11, 'learning_rate': 0.032934954785221696, 'subsample': 0.8623932825805893, 'colsample_bytree': 0.8986598947958789, 'gamma': 0.8573131278481302, 'scale_pos_weight': 1.2751235894332553}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:39,060] Trial 70 finished with value: 0.9106613327278111 and parameters: {'n_estimators': 400, 'max_depth': 14, 'learning_rate': 0.04796602848943567, 'subsample': 0.8828679587277031, 'colsample_bytree': 0.9020934482655901, 'gamma': 2.138957442060314, 'scale_pos_weight': 1.2724423885657596}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:40,000] Trial 71 finished with value: 0.9133201234928474 and parameters: {'n_estimators': 350, 'max_depth': 12, 'learning_rate': 0.03318316329495169, 'subsample': 0.9136739491521116, 'colsample_bytree': 0.8858508460584008, 'gamma': 0.796061425336966, 'scale_pos_weight': 1.3824010587565017}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:41,033] Trial 72 finished with value: 0.9101574202880693 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.03419326496765438, 'subsample': 0.9149533588563872, 'colsample_bytree': 0.891132524346155, 'gamma': 0.7784204152256973, 'scale_pos_weight': 1.3550471974499383}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:41,848] Trial 73 finished with value: 0.910365986856528 and parameters: {'n_estimators': 350, 'max_depth': 11, 'learning_rate': 0.028053812962605063, 'subsample': 0.8903531601158605, 'colsample_bytree': 0.8858401489239086, 'gamma': 1.5190460918389705, 'scale_pos_weight': 1.2668381015330372}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:42,734] Trial 74 finished with value: 0.9134929036842324 and parameters: {'n_estimators': 350, 'max_depth': 12, 'learning_rate': 0.032096063442725725, 'subsample': 0.9059809873990197, 'colsample_bytree': 0.9432469087242112, 'gamma': 1.0094369596964794, 'scale_pos_weight': 1.3775830738493213}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:44,064] Trial 75 finished with value: 0.9101377062900134 and parameters: {'n_estimators': 350, 'max_depth': 11, 'learning_rate': 0.03740999945403607, 'subsample': 0.8610797778670636, 'colsample_bytree': 0.6310465299288771, 'gamma': 0.30328692844633176, 'scale_pos_weight': 1.1097533153241324}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:44,962] Trial 76 finished with value: 0.90660305424068 and parameters: {'n_estimators': 400, 'max_depth': 15, 'learning_rate': 0.021439788669994818, 'subsample': 0.9338610503457061, 'colsample_bytree': 0.941124547539556, 'gamma': 1.7615290356835929, 'scale_pos_weight': 1.1999381396382498}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:45,729] Trial 77 finished with value: 0.9119124844427444 and parameters: {'n_estimators': 300, 'max_depth': 14, 'learning_rate': 0.04168305712548696, 'subsample': 0.858980864653217, 'colsample_bytree': 0.9571490066674297, 'gamma': 0.9567127536162153, 'scale_pos_weight': 1.4442222712783612}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:46,890] Trial 78 finished with value: 0.9131911414045174 and parameters: {'n_estimators': 350, 'max_depth': 9, 'learning_rate': 0.028795060810384465, 'subsample': 0.9077241223527022, 'colsample_bytree': 0.9209611577345458, 'gamma': 0.5516268102938493, 'scale_pos_weight': 1.3091737861714237}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:47,287] Trial 79 finished with value: 0.902011654558008 and parameters: {'n_estimators': 300, 'max_depth': 13, 'learning_rate': 0.05099791256496384, 'subsample': 0.9259725738963324, 'colsample_bytree': 0.8285837323768105, 'gamma': 4.3488582931035795, 'scale_pos_weight': 1.1546831277270715}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:48,270] Trial 80 finished with value: 0.9128357847563713 and parameters: {'n_estimators': 350, 'max_depth': 10, 'learning_rate': 0.03048830589939113, 'subsample': 0.9543072891484432, 'colsample_bytree': 0.9746422280897411, 'gamma': 1.0320300477832947, 'scale_pos_weight': 2.801801366303681}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:49,262] Trial 81 finished with value: 0.9131911414045174 and parameters: {'n_estimators': 350, 'max_depth': 13, 'learning_rate': 0.032709623254925844, 'subsample': 0.8979574453063289, 'colsample_bytree': 0.9116445279725891, 'gamma': 0.7544216413421863, 'scale_pos_weight': 1.4043142724420385}. Best is trial 24 with value: 0.9150837831189632.\n",
      "[I 2025-03-15 18:49:50,865] Trial 82 finished with value: 0.9152736831517366 and parameters: {'n_estimators': 350, 'max_depth': 12, 'learning_rate': 0.026882032644332237, 'subsample': 0.9097260546902618, 'colsample_bytree': 0.8432633247656723, 'gamma': 0.2547481609874034, 'scale_pos_weight': 1.3577396893797729}. Best is trial 82 with value: 0.9152736831517366.\n",
      "[I 2025-03-15 18:49:52,619] Trial 83 finished with value: 0.9149124256903785 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.026641803815028446, 'subsample': 0.8733498817758364, 'colsample_bytree': 0.852355045843122, 'gamma': 0.3051606710065307, 'scale_pos_weight': 1.2520560061758466}. Best is trial 82 with value: 0.9152736831517366.\n",
      "[I 2025-03-15 18:49:54,788] Trial 84 finished with value: 0.9194868538868539 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.023811880556235933, 'subsample': 0.8680893681065185, 'colsample_bytree': 0.8419155626320302, 'gamma': 0.1700828562917005, 'scale_pos_weight': 1.256624090851487}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:49:56,722] Trial 85 finished with value: 0.9159538277731827 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.024315526459406003, 'subsample': 0.8734192700200998, 'colsample_bytree': 0.8336545680403971, 'gamma': 0.24125343467004298, 'scale_pos_weight': 1.1147772813459844}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:49:58,821] Trial 86 finished with value: 0.9178090249057991 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.020641790529004205, 'subsample': 0.8399412625758153, 'colsample_bytree': 0.8348522246237667, 'gamma': 0.25163219173996587, 'scale_pos_weight': 1.1211105084442023}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:00,861] Trial 87 finished with value: 0.9160312471280212 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.020633662478293978, 'subsample': 0.8733386573354084, 'colsample_bytree': 0.839729470169003, 'gamma': 0.2626685871952058, 'scale_pos_weight': 1.1240484880512378}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:02,911] Trial 88 finished with value: 0.917450601966731 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.020271530446843627, 'subsample': 0.8668364524770139, 'colsample_bytree': 0.8384070355494421, 'gamma': 0.2655253842431462, 'scale_pos_weight': 1.113897548094192}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:05,106] Trial 89 finished with value: 0.917734472934473 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.020413613786969625, 'subsample': 0.8700078886588636, 'colsample_bytree': 0.8437743823527861, 'gamma': 0.18849401425163942, 'scale_pos_weight': 1.1294599382669128}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:07,295] Trial 90 finished with value: 0.917450601966731 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.020785636071235094, 'subsample': 0.8657055135213815, 'colsample_bytree': 0.838225112747775, 'gamma': 0.1673931119241196, 'scale_pos_weight': 1.0499308052647824}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:09,448] Trial 91 finished with value: 0.917450601966731 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.02040997446618588, 'subsample': 0.865927440539974, 'colsample_bytree': 0.8371868981276076, 'gamma': 0.1950962386349625, 'scale_pos_weight': 1.0529578378028197}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:11,794] Trial 92 finished with value: 0.9129724769342975 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.012885236339898916, 'subsample': 0.8429199433758846, 'colsample_bytree': 0.8360689004419248, 'gamma': 0.13831072789550275, 'scale_pos_weight': 1.0993024671631115}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:14,058] Trial 93 finished with value: 0.9160054406764084 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.02063153044090169, 'subsample': 0.8831350217063051, 'colsample_bytree': 0.8003699650299667, 'gamma': 0.1473637820887153, 'scale_pos_weight': 1.127883960140344}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:16,206] Trial 94 finished with value: 0.9178090249057991 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.01998638457177295, 'subsample': 0.8810969914314033, 'colsample_bytree': 0.8053913644319503, 'gamma': 0.2086212687243521, 'scale_pos_weight': 1.0516016135837776}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:18,736] Trial 95 finished with value: 0.9157196814317192 and parameters: {'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.01575578654646978, 'subsample': 0.8841649305029868, 'colsample_bytree': 0.806340479124761, 'gamma': 0.17266692780987614, 'scale_pos_weight': 1.0543820620884767}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:20,808] Trial 96 finished with value: 0.9129569950630539 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.011235151380306676, 'subsample': 0.8690976202089025, 'colsample_bytree': 0.8099394963690235, 'gamma': 0.5876172091408485, 'scale_pos_weight': 1.1322019948738014}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:22,432] Trial 97 finished with value: 0.912884740994891 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.020440887907238386, 'subsample': 0.8493445441255661, 'colsample_bytree': 0.8720969101118825, 'gamma': 0.5074793520979609, 'scale_pos_weight': 1.0593200918004482}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:24,983] Trial 98 finished with value: 0.9161918159348806 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.014503590681840458, 'subsample': 0.8897550156863978, 'colsample_bytree': 0.7820890621044527, 'gamma': 0.17312993067136273, 'scale_pos_weight': 1.1720504683020483}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:27,500] Trial 99 finished with value: 0.9144325196533931 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.014260600065512968, 'subsample': 0.8873488785561384, 'colsample_bytree': 0.7914445205385183, 'gamma': 0.0056236092748226385, 'scale_pos_weight': 1.1739592160070995}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:28,667] Trial 100 finished with value: 0.9066321022085212 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.018616537967504843, 'subsample': 0.8387431905862295, 'colsample_bytree': 0.7644133656091968, 'gamma': 1.3730143507226553, 'scale_pos_weight': 1.0507135483301988}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:30,594] Trial 101 finished with value: 0.9164091998839268 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.01628546389235088, 'subsample': 0.8682686827947289, 'colsample_bytree': 0.8160403188168334, 'gamma': 0.43697993525963696, 'scale_pos_weight': 1.1230230987030236}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:32,569] Trial 102 finished with value: 0.914678279348915 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.01643524118582177, 'subsample': 0.863569910099812, 'colsample_bytree': 0.8158944351844666, 'gamma': 0.41361371055434415, 'scale_pos_weight': 1.1465961707837513}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:34,949] Trial 103 finished with value: 0.9194861229608499 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.020518605646606125, 'subsample': 0.8508916215233733, 'colsample_bytree': 0.7853696402784146, 'gamma': 0.18699285698927742, 'scale_pos_weight': 1.1715326722046677}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:37,086] Trial 104 finished with value: 0.91450541040182 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.01192431610459554, 'subsample': 0.8546296583653, 'colsample_bytree': 0.7804843360954332, 'gamma': 0.5954574931355777, 'scale_pos_weight': 1.1769849265826036}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:38,510] Trial 105 finished with value: 0.9114816072122564 and parameters: {'n_estimators': 450, 'max_depth': 13, 'learning_rate': 0.014526299525058012, 'subsample': 0.8245044763138883, 'colsample_bytree': 0.8699105330902045, 'gamma': 1.0869207600434163, 'scale_pos_weight': 1.098781193363346}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:40,650] Trial 106 finished with value: 0.9164091998839268 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.016467282339046277, 'subsample': 0.8527461590887702, 'colsample_bytree': 0.8452759609587303, 'gamma': 0.393809840107524, 'scale_pos_weight': 1.1639057305327718}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:42,445] Trial 107 finished with value: 0.9131911414045174 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.018508854428934348, 'subsample': 0.8927982009021846, 'colsample_bytree': 0.8507621221297118, 'gamma': 0.49787048957540125, 'scale_pos_weight': 1.1802976371524159}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:44,230] Trial 108 finished with value: 0.9131911414045174 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.016309645608880333, 'subsample': 0.8347985769888036, 'colsample_bytree': 0.8205422819043419, 'gamma': 0.6202283475292276, 'scale_pos_weight': 1.0848230780433414}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:45,397] Trial 109 finished with value: 0.9131911414045174 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.02289229583613544, 'subsample': 0.8495209792056788, 'colsample_bytree': 0.8292303925155651, 'gamma': 1.1475469532669376, 'scale_pos_weight': 1.2313626394604096}. Best is trial 84 with value: 0.9194868538868539.\n",
      "[I 2025-03-15 18:50:47,989] Trial 110 finished with value: 0.920920352877158 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.015088186394593861, 'subsample': 0.8656190745853759, 'colsample_bytree': 0.8639967071761631, 'gamma': 0.12944910863441217, 'scale_pos_weight': 1.31683466568333}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:50:50,639] Trial 111 finished with value: 0.9163336756432896 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.013242014200899661, 'subsample': 0.8680018839266073, 'colsample_bytree': 0.8607425221195907, 'gamma': 0.012817989498831783, 'scale_pos_weight': 1.299051247653407}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:50:53,011] Trial 112 finished with value: 0.9128118502464642 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.013497445021272798, 'subsample': 0.8514482300957593, 'colsample_bytree': 0.8630907158452159, 'gamma': 0.00681744154332109, 'scale_pos_weight': 1.0536304331604451}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:50:54,997] Trial 113 finished with value: 0.9164253265930096 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.016793100196866983, 'subsample': 0.8652893391024994, 'colsample_bytree': 0.8447414680104098, 'gamma': 0.41588258477164197, 'scale_pos_weight': 1.3220814860461152}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:50:56,922] Trial 114 finished with value: 0.914678279348915 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.016886168735534026, 'subsample': 0.8783705356371657, 'colsample_bytree': 0.8457054207533875, 'gamma': 0.4010469425150617, 'scale_pos_weight': 1.2344489594213355}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:50:58,588] Trial 115 finished with value: 0.9164626937507967 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.015361020240889282, 'subsample': 0.8388645216497407, 'colsample_bytree': 0.8252801325748622, 'gamma': 0.675521193489472, 'scale_pos_weight': 1.3286976923304656}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:00,150] Trial 116 finished with value: 0.9133201234928474 and parameters: {'n_estimators': 400, 'max_depth': 11, 'learning_rate': 0.018213322542067232, 'subsample': 0.806863472672127, 'colsample_bytree': 0.825733323430332, 'gamma': 0.6889699746306146, 'scale_pos_weight': 1.330917799263453}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:01,654] Trial 117 finished with value: 0.9133201234928474 and parameters: {'n_estimators': 400, 'max_depth': 12, 'learning_rate': 0.019538826191771212, 'subsample': 0.8230240192410135, 'colsample_bytree': 0.8772841210550963, 'gamma': 0.6665022410425787, 'scale_pos_weight': 1.2782423160501046}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:02,489] Trial 118 finished with value: 0.8890247583897566 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.015203413498712362, 'subsample': 0.8378946843038716, 'colsample_bytree': 0.8058761403006873, 'gamma': 6.430355387140877, 'scale_pos_weight': 2.5373166894031316}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:03,649] Trial 119 finished with value: 0.9095474474818473 and parameters: {'n_estimators': 400, 'max_depth': 11, 'learning_rate': 0.021920518725534938, 'subsample': 0.8633674513618939, 'colsample_bytree': 0.7917979534160848, 'gamma': 0.9561122844845972, 'scale_pos_weight': 1.0877047187160178}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:05,739] Trial 120 finished with value: 0.9114621091464528 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.012165553380001961, 'subsample': 0.8433778055301578, 'colsample_bytree': 0.8154708667593663, 'gamma': 0.4689961005217558, 'scale_pos_weight': 1.2085013297306078}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:07,923] Trial 121 finished with value: 0.9093945241783918 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.0109567053338421, 'subsample': 0.830091792987272, 'colsample_bytree': 0.8558995989146677, 'gamma': 0.4025523457873906, 'scale_pos_weight': 1.141998984664553}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:10,384] Trial 122 finished with value: 0.9175003265930096 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.016735694008709237, 'subsample': 0.8569482284627342, 'colsample_bytree': 0.8419067938037013, 'gamma': 0.19513566613091593, 'scale_pos_weight': 1.1742049718510363}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:12,686] Trial 123 finished with value: 0.9175003265930096 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.017251461552403063, 'subsample': 0.8588239264147378, 'colsample_bytree': 0.8363566185460704, 'gamma': 0.1723974389022731, 'scale_pos_weight': 1.1036968161180811}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:15,170] Trial 124 finished with value: 0.9194868538868539 and parameters: {'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.01970701620587969, 'subsample': 0.8561520353898721, 'colsample_bytree': 0.8361507181047875, 'gamma': 0.16150811026852202, 'scale_pos_weight': 1.2475869516081628}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:17,416] Trial 125 finished with value: 0.9180138380138381 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.023080965463492732, 'subsample': 0.8787993134082698, 'colsample_bytree': 0.8332133465266455, 'gamma': 0.20139828008517485, 'scale_pos_weight': 1.2064811447638182}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:19,744] Trial 126 finished with value: 0.917734472934473 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.023283822931420502, 'subsample': 0.8792507557520688, 'colsample_bytree': 0.835219633392812, 'gamma': 0.17172034230529853, 'scale_pos_weight': 1.2465614873111674}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:21,941] Trial 127 finished with value: 0.9160054406764084 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.02322370844420007, 'subsample': 0.8995542082536123, 'colsample_bytree': 0.8577245096861158, 'gamma': 0.20508692041913887, 'scale_pos_weight': 1.2468042549944807}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:24,678] Trial 128 finished with value: 0.9158190845828544 and parameters: {'n_estimators': 500, 'max_depth': 13, 'learning_rate': 0.01907206921717813, 'subsample': 0.8784336738540804, 'colsample_bytree': 0.8783285125219215, 'gamma': 0.15655100901904795, 'scale_pos_weight': 3.0717272597527954}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:27,227] Trial 129 finished with value: 0.9194868538868539 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.023825018532047958, 'subsample': 0.8535460051811674, 'colsample_bytree': 0.8333519737371344, 'gamma': 0.00339520486037298, 'scale_pos_weight': 1.2028384787245041}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:27,836] Trial 130 finished with value: 0.8996952077336736 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.022740668831094296, 'subsample': 0.8542603524319564, 'colsample_bytree': 0.8322049857359106, 'gamma': 8.180867294366593, 'scale_pos_weight': 1.2109405428141915}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:30,242] Trial 131 finished with value: 0.9117976036495776 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.021298039722239894, 'subsample': 0.8581333142589822, 'colsample_bytree': 0.7509387014441329, 'gamma': 0.16658257259401857, 'scale_pos_weight': 1.186193055076248}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:32,930] Trial 132 finished with value: 0.9112721380827878 and parameters: {'n_estimators': 500, 'max_depth': 13, 'learning_rate': 0.017909972922503254, 'subsample': 0.8727246655618939, 'colsample_bytree': 0.7982251611064287, 'gamma': 0.018953034253553547, 'scale_pos_weight': 1.2760138637705098}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:34,213] Trial 133 finished with value: 0.9115453453401166 and parameters: {'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.023726450711950144, 'subsample': 0.8581513987924244, 'colsample_bytree': 0.8393808251291764, 'gamma': 0.8235995823293334, 'scale_pos_weight': 1.1041672887118346}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:36,349] Trial 134 finished with value: 0.9164091998839268 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.02041875092773994, 'subsample': 0.8804374398439445, 'colsample_bytree': 0.8515186181743913, 'gamma': 0.28372488434875465, 'scale_pos_weight': 1.2297675089086835}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:37,895] Trial 135 finished with value: 0.9115453453401166 and parameters: {'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.019227391242583675, 'subsample': 0.8912503176940381, 'colsample_bytree': 0.8650275706921937, 'gamma': 0.6629943386125033, 'scale_pos_weight': 1.1496212594804005}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:39,903] Trial 136 finished with value: 0.917734472934473 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.02505951683420627, 'subsample': 0.8487146712939267, 'colsample_bytree': 0.8225617510304813, 'gamma': 0.27063774645189415, 'scale_pos_weight': 1.1918332619278857}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:40,582] Trial 137 finished with value: 0.9004292702189589 and parameters: {'n_estimators': 500, 'max_depth': 13, 'learning_rate': 0.025257129465723355, 'subsample': 0.8448181583201685, 'colsample_bytree': 0.8111354142242083, 'gamma': 5.002264719561994, 'scale_pos_weight': 1.2847635411931917}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:43,113] Trial 138 finished with value: 0.9176941287825009 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.025343145401194495, 'subsample': 0.8212947570364997, 'colsample_bytree': 0.8229916892397295, 'gamma': 0.021499726640118816, 'scale_pos_weight': 1.1993114274225392}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:44,810] Trial 139 finished with value: 0.9114035758496037 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.023912894942888622, 'subsample': 0.8219824604323398, 'colsample_bytree': 0.7734902805025405, 'gamma': 0.4766081394280891, 'scale_pos_weight': 1.1974685577419142}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:46,131] Trial 140 finished with value: 0.9115453453401166 and parameters: {'n_estimators': 500, 'max_depth': 13, 'learning_rate': 0.022267379425239184, 'subsample': 0.8303575307714866, 'colsample_bytree': 0.8247611221196404, 'gamma': 0.9765819451259561, 'scale_pos_weight': 1.2528770625569925}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:47,657] Trial 141 finished with value: 0.9048438311125704 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.1570732950503075, 'subsample': 0.851825297710063, 'colsample_bytree': 0.8292389697566092, 'gamma': 0.038855722107345496, 'scale_pos_weight': 1.135312558025529}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:49,723] Trial 142 finished with value: 0.9163122507122508 and parameters: {'n_estimators': 500, 'max_depth': 14, 'learning_rate': 0.025864754819422933, 'subsample': 0.8170515475771815, 'colsample_bytree': 0.8203292214450933, 'gamma': 0.2919287275490159, 'scale_pos_weight': 1.1773871081974356}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:50,683] Trial 143 finished with value: 0.9064106434238486 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.017747284736899523, 'subsample': 0.843943152501634, 'colsample_bytree': 0.8476432586954705, 'gamma': 3.8694462724279646, 'scale_pos_weight': 2.2476839891658065}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:52,479] Trial 144 finished with value: 0.911334472934473 and parameters: {'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.028727814541279945, 'subsample': 0.8731755467892651, 'colsample_bytree': 0.8006787916272499, 'gamma': 0.2896503789452937, 'scale_pos_weight': 1.1077613008661575}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:54,887] Trial 145 finished with value: 0.9194868538868539 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.021744148334460242, 'subsample': 0.8589539995729109, 'colsample_bytree': 0.8349675970909257, 'gamma': 0.003918088952755545, 'scale_pos_weight': 1.2228784037364833}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:57,644] Trial 146 finished with value: 0.9114898931341624 and parameters: {'n_estimators': 500, 'max_depth': 13, 'learning_rate': 0.022095995700363608, 'subsample': 0.857872964751041, 'colsample_bytree': 0.7894385729580562, 'gamma': 0.010160356667578342, 'scale_pos_weight': 1.2230570147802067}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:58,439] Trial 147 finished with value: 0.911419650893672 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.08240623061965151, 'subsample': 0.8841507871506401, 'colsample_bytree': 0.8325446667484608, 'gamma': 0.547388634685916, 'scale_pos_weight': 1.2870795926229879}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:51:59,887] Trial 148 finished with value: 0.9135941548639261 and parameters: {'n_estimators': 500, 'max_depth': 13, 'learning_rate': 0.024873814753298883, 'subsample': 0.802629588736364, 'colsample_bytree': 0.8123287819726386, 'gamma': 0.7618296733421901, 'scale_pos_weight': 1.345553072312373}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:02,463] Trial 149 finished with value: 0.9142482940726844 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.01947439798703503, 'subsample': 0.8372255701967659, 'colsample_bytree': 0.8210451612933715, 'gamma': 0.021802607418350127, 'scale_pos_weight': 1.1767619179871023}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:03,933] Trial 150 finished with value: 0.9167129668013427 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.022856983097049678, 'subsample': 0.8786889782741197, 'colsample_bytree': 0.8049919937212768, 'gamma': 0.5847570337374204, 'scale_pos_weight': 1.2604244192126182}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:05,834] Trial 151 finished with value: 0.9194766702375665 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.02102725360486542, 'subsample': 0.8490336657626038, 'colsample_bytree': 0.8393040038475864, 'gamma': 0.3307844819841359, 'scale_pos_weight': 1.0956386398380944}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:07,755] Trial 152 finished with value: 0.9164091998839268 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.021596560004560762, 'subsample': 0.8472766419396683, 'colsample_bytree': 0.8533475787656976, 'gamma': 0.31555320791502706, 'scale_pos_weight': 1.1485163823289064}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:09,704] Trial 153 finished with value: 0.9146344217311959 and parameters: {'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.018700152549073142, 'subsample': 0.8586161765903032, 'colsample_bytree': 0.8401335195735797, 'gamma': 0.42676881095032354, 'scale_pos_weight': 1.2059783783298965}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:11,806] Trial 154 finished with value: 0.917734472934473 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.024326316154515214, 'subsample': 0.832162263944368, 'colsample_bytree': 0.83093213608085, 'gamma': 0.189595122622475, 'scale_pos_weight': 1.0864614024972783}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:12,443] Trial 155 finished with value: 0.8970348376357331 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.026145532132561263, 'subsample': 0.8271487635495262, 'colsample_bytree': 0.846519524005957, 'gamma': 5.5700917385924775, 'scale_pos_weight': 1.1656925968095881}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:14,693] Trial 156 finished with value: 0.917734472934473 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.029100758830761013, 'subsample': 0.8481532950653677, 'colsample_bytree': 0.8301935910381131, 'gamma': 0.00783777202907629, 'scale_pos_weight': 1.235462544933055}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:16,935] Trial 157 finished with value: 0.9145758531278025 and parameters: {'n_estimators': 450, 'max_depth': 13, 'learning_rate': 0.02811467517322023, 'subsample': 0.8167830973666732, 'colsample_bytree': 0.8269506738877664, 'gamma': 0.011184862887540895, 'scale_pos_weight': 1.32162194447674}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:18,283] Trial 158 finished with value: 0.9150453214695753 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.029858742331281798, 'subsample': 0.8342483483028723, 'colsample_bytree': 0.8177862543194392, 'gamma': 0.5621682839682156, 'scale_pos_weight': 1.2335754067340776}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:19,930] Trial 159 finished with value: 0.911334472934473 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.023815444782556653, 'subsample': 0.843876859563754, 'colsample_bytree': 0.8608735947522621, 'gamma': 0.41697869109798635, 'scale_pos_weight': 1.085872397882722}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:21,207] Trial 160 finished with value: 0.9134929036842324 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.0253467988857911, 'subsample': 0.8119520479009565, 'colsample_bytree': 0.8115057826801443, 'gamma': 0.857255360173147, 'scale_pos_weight': 1.3010981738341445}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:23,360] Trial 161 finished with value: 0.9134126412922929 and parameters: {'n_estimators': 500, 'max_depth': 20, 'learning_rate': 0.02160617978834452, 'subsample': 0.6312299009540738, 'colsample_bytree': 0.8307810521632442, 'gamma': 0.2607221149293884, 'scale_pos_weight': 1.209319289408464}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:25,773] Trial 162 finished with value: 0.9160054406764084 and parameters: {'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.020476941842394337, 'subsample': 0.850282403783181, 'colsample_bytree': 0.8420869108076756, 'gamma': 0.18417067038285737, 'scale_pos_weight': 1.1467634746684048}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:28,357] Trial 163 finished with value: 0.9160054406764084 and parameters: {'n_estimators': 500, 'max_depth': 13, 'learning_rate': 0.02372973063535461, 'subsample': 0.8704738817123647, 'colsample_bytree': 0.8502356685607964, 'gamma': 0.0013563039872774851, 'scale_pos_weight': 1.2630153951793617}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:29,935] Trial 164 finished with value: 0.9131376475376476 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.02672313585534027, 'subsample': 0.8522132739260259, 'colsample_bytree': 0.8239559746676638, 'gamma': 0.34791911903325645, 'scale_pos_weight': 1.1810756985227284}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:31,364] Trial 165 finished with value: 0.9097203214695753 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.02255386169840192, 'subsample': 0.8371153847960191, 'colsample_bytree': 0.8341305018616533, 'gamma': 0.6438860375730717, 'scale_pos_weight': 1.0946473627084823}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:33,766] Trial 166 finished with value: 0.9159538277731827 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.0199873908790632, 'subsample': 0.864885792551431, 'colsample_bytree': 0.873819690793225, 'gamma': 0.18565380436077866, 'scale_pos_weight': 1.1284779990259612}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:35,418] Trial 167 finished with value: 0.9128312471280212 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.024038135492388386, 'subsample': 0.8280847579152713, 'colsample_bytree': 0.854943686820553, 'gamma': 0.41696835597725124, 'scale_pos_weight': 1.0489596745541367}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:38,076] Trial 168 finished with value: 0.9146148852423289 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.018108427047176266, 'subsample': 0.8769893989140911, 'colsample_bytree': 0.867946767791486, 'gamma': 0.00045033003720115284, 'scale_pos_weight': 1.244552796008631}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:38,851] Trial 169 finished with value: 0.8954276215045628 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.021324184618009615, 'subsample': 0.8417566581228813, 'colsample_bytree': 0.8417746698680528, 'gamma': 3.2059352581751233, 'scale_pos_weight': 1.2051239930869049}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:40,117] Trial 170 finished with value: 0.9133201234928474 and parameters: {'n_estimators': 500, 'max_depth': 13, 'learning_rate': 0.026856602066244146, 'subsample': 0.8877257720893907, 'colsample_bytree': 0.8186093229169904, 'gamma': 0.7064842795671308, 'scale_pos_weight': 1.1538781419577095}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:42,414] Trial 171 finished with value: 0.9157196814317192 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.016822541813011696, 'subsample': 0.8576206051053579, 'colsample_bytree': 0.8373841285623294, 'gamma': 0.2172989511095998, 'scale_pos_weight': 1.0964321350758732}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:44,593] Trial 172 finished with value: 0.917450601966731 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.018885346708957286, 'subsample': 0.8618976796110862, 'colsample_bytree': 0.8315350020706886, 'gamma': 0.23602435423619852, 'scale_pos_weight': 1.1092379523775673}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:46,277] Trial 173 finished with value: 0.9165800710221459 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.01969479791159969, 'subsample': 0.8515342527836146, 'colsample_bytree': 0.8464431570713851, 'gamma': 0.5130618519355539, 'scale_pos_weight': 1.1798598252097245}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:48,644] Trial 174 finished with value: 0.919167971924777 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.015335021228060018, 'subsample': 0.8693817407404665, 'colsample_bytree': 0.8046224759800031, 'gamma': 0.17879198535855273, 'scale_pos_weight': 1.240909081362153}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:50,934] Trial 175 finished with value: 0.9145711465279517 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.015100852110171105, 'subsample': 0.8961838877444673, 'colsample_bytree': 0.7966033745464968, 'gamma': 0.3785306404772094, 'scale_pos_weight': 1.2874418378760404}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:53,084] Trial 176 finished with value: 0.9194868538868539 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.02529000781851321, 'subsample': 0.8726601444605968, 'colsample_bytree': 0.8066722448051441, 'gamma': 0.16285455242174052, 'scale_pos_weight': 1.2453458687466408}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:55,222] Trial 177 finished with value: 0.9177578216287893 and parameters: {'n_estimators': 400, 'max_depth': 12, 'learning_rate': 0.02509689368949542, 'subsample': 0.8702581400502997, 'colsample_bytree': 0.8073312040837937, 'gamma': 0.013238859130531681, 'scale_pos_weight': 1.3855686833381178}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:56,501] Trial 178 finished with value: 0.9151070551491302 and parameters: {'n_estimators': 400, 'max_depth': 13, 'learning_rate': 0.029713444247629506, 'subsample': 0.8711278029041749, 'colsample_bytree': 0.8040752869136091, 'gamma': 0.5512906389778922, 'scale_pos_weight': 1.3730250677773899}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:52:58,513] Trial 179 finished with value: 0.9134696316540655 and parameters: {'n_estimators': 400, 'max_depth': 12, 'learning_rate': 0.0220075480578306, 'subsample': 0.881984416943617, 'colsample_bytree': 0.7928559474241418, 'gamma': 0.20273199570679787, 'scale_pos_weight': 1.315397580096079}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:00,285] Trial 180 finished with value: 0.918309589570576 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.02364490574002089, 'subsample': 0.8682563835507673, 'colsample_bytree': 0.7775724670338906, 'gamma': 0.40159451410380936, 'scale_pos_weight': 1.4390937574111904}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:02,119] Trial 181 finished with value: 0.9151864570614571 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.02342287005816434, 'subsample': 0.8727462722148492, 'colsample_bytree': 0.8102556355709586, 'gamma': 0.34509006567043, 'scale_pos_weight': 1.4323469751999365}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:04,396] Trial 182 finished with value: 0.9134182730565066 and parameters: {'n_estimators': 450, 'max_depth': 13, 'learning_rate': 0.024944382743135728, 'subsample': 0.8661186779824721, 'colsample_bytree': 0.7837954063094384, 'gamma': 0.15472628270460392, 'scale_pos_weight': 1.4112702919385829}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:06,755] Trial 183 finished with value: 0.914804062839243 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.027228433142077187, 'subsample': 0.8875362576296262, 'colsample_bytree': 0.7653071419344216, 'gamma': 0.0005743169907322342, 'scale_pos_weight': 1.3429829734089944}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:08,359] Trial 184 finished with value: 0.9196975146226233 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.022991903659238956, 'subsample': 0.8753359967711559, 'colsample_bytree': 0.7860958944614831, 'gamma': 0.4810275856090478, 'scale_pos_weight': 1.2498388317576006}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:09,804] Trial 185 finished with value: 0.9182633254021745 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.021052103659012566, 'subsample': 0.8776738654396387, 'colsample_bytree': 0.7752947706115998, 'gamma': 0.729740106609384, 'scale_pos_weight': 1.3695873199430033}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:11,252] Trial 186 finished with value: 0.9168754003501274 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.021004798320902497, 'subsample': 0.8781217562489231, 'colsample_bytree': 0.7546224630733456, 'gamma': 0.7665328773417849, 'scale_pos_weight': 1.4655004605470896}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:12,845] Trial 187 finished with value: 0.916688920163647 and parameters: {'n_estimators': 450, 'max_depth': 19, 'learning_rate': 0.022757247889508024, 'subsample': 0.9016845740996071, 'colsample_bytree': 0.7788519622139847, 'gamma': 0.4989863088284343, 'scale_pos_weight': 1.3742089247751288}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:14,110] Trial 188 finished with value: 0.9117583756969424 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.02066462059705827, 'subsample': 0.8875068116576749, 'colsample_bytree': 0.7878086772992924, 'gamma': 1.0029544235439605, 'scale_pos_weight': 1.3097967931700105}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:15,622] Trial 189 finished with value: 0.9168754003501274 and parameters: {'n_estimators': 400, 'max_depth': 13, 'learning_rate': 0.01941098859975734, 'subsample': 0.8741791374761778, 'colsample_bytree': 0.7711242961640365, 'gamma': 0.6657532238986987, 'scale_pos_weight': 1.4108711024027885}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:17,396] Trial 190 finished with value: 0.918309589570576 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.02200457482347696, 'subsample': 0.8637297866436577, 'colsample_bytree': 0.7414439899742108, 'gamma': 0.40958093290191694, 'scale_pos_weight': 1.266390808176635}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:19,214] Trial 191 finished with value: 0.9180768452156943 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.021457450704259053, 'subsample': 0.8652517779870939, 'colsample_bytree': 0.7581850552301096, 'gamma': 0.39875897978589014, 'scale_pos_weight': 1.264112748134998}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:20,962] Trial 192 finished with value: 0.918309589570576 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.022372239880126918, 'subsample': 0.8653853821145714, 'colsample_bytree': 0.731809652216958, 'gamma': 0.4101658749726008, 'scale_pos_weight': 1.2853037278736572}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:22,678] Trial 193 finished with value: 0.9149131589731077 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.02109045689216262, 'subsample': 0.8647312604860066, 'colsample_bytree': 0.7283458947406405, 'gamma': 0.47834153114697264, 'scale_pos_weight': 1.3458460249149031}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:23,269] Trial 194 finished with value: 0.8952312902971699 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.02225592464927512, 'subsample': 0.8678593075695061, 'colsample_bytree': 0.760748849789453, 'gamma': 7.389303305782713, 'scale_pos_weight': 1.2922633771291805}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:24,625] Trial 195 finished with value: 0.9132551498904906 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.019732771977958523, 'subsample': 0.8925498912577886, 'colsample_bytree': 0.7386363903156319, 'gamma': 0.8750138357123243, 'scale_pos_weight': 1.2677611239180415}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:26,420] Trial 196 finished with value: 0.916688920163647 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.022021985299779417, 'subsample': 0.8617366009635788, 'colsample_bytree': 0.7225441026899124, 'gamma': 0.4143041321855279, 'scale_pos_weight': 1.3554509310562377}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:28,033] Trial 197 finished with value: 0.9180768452156943 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.020692985007855748, 'subsample': 0.8749621333893103, 'colsample_bytree': 0.7408424383194547, 'gamma': 0.7064119139080907, 'scale_pos_weight': 1.2575571053483423}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:29,627] Trial 198 finished with value: 0.9182633254021745 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.018058856583029546, 'subsample': 0.8826567439506066, 'colsample_bytree': 0.7069644695750471, 'gamma': 0.683415439730392, 'scale_pos_weight': 1.3109369207841095}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:30,880] Trial 199 finished with value: 0.908835541051273 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.0178673683867632, 'subsample': 0.882887284243086, 'colsample_bytree': 0.7047744495891624, 'gamma': 1.2973024745540669, 'scale_pos_weight': 1.3080280885612068}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:32,169] Trial 200 finished with value: 0.9133776215909976 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.0178981822258535, 'subsample': 0.879405081574794, 'colsample_bytree': 0.7378119105145505, 'gamma': 1.1294607955203246, 'scale_pos_weight': 1.254664830339778}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:33,805] Trial 201 finished with value: 0.9182633254021745 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.018758394583864864, 'subsample': 0.8723843181004594, 'colsample_bytree': 0.7497687930403417, 'gamma': 0.644809626447947, 'scale_pos_weight': 1.383052109773063}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:35,254] Trial 202 finished with value: 0.9165324048671627 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.019141217442340493, 'subsample': 0.8593582844285209, 'colsample_bytree': 0.7467654960334881, 'gamma': 0.822264085059369, 'scale_pos_weight': 1.3295222269039553}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:37,033] Trial 203 finished with value: 0.9131383808203768 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.015755719500556205, 'subsample': 0.8940553721842005, 'colsample_bytree': 0.751191847355373, 'gamma': 0.598199091590738, 'scale_pos_weight': 1.2942885095249352}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:38,876] Trial 204 finished with value: 0.9132551498904906 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.013809055359398303, 'subsample': 0.8757717741379069, 'colsample_bytree': 0.7186349120852051, 'gamma': 0.6713288508383157, 'scale_pos_weight': 1.2361223312826473}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:40,213] Trial 205 finished with value: 0.9182633254021745 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.021106932711143785, 'subsample': 0.8848508656021138, 'colsample_bytree': 0.7624864885123033, 'gamma': 0.9203438065475434, 'scale_pos_weight': 1.4427511553165675}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:41,618] Trial 206 finished with value: 0.9168754003501274 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.021071339226108297, 'subsample': 0.8644830760817648, 'colsample_bytree': 0.7592984050191874, 'gamma': 0.887841605323855, 'scale_pos_weight': 1.4516545370539722}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:42,956] Trial 207 finished with value: 0.915426431114807 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.018456025366371975, 'subsample': 0.8732063962268629, 'colsample_bytree': 0.7656234649651079, 'gamma': 1.109717363337351, 'scale_pos_weight': 1.4078018069105942}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:44,342] Trial 208 finished with value: 0.9172553935955889 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.02299747475764748, 'subsample': 0.9051490541796516, 'colsample_bytree': 0.7758326874377334, 'gamma': 0.7517222142855434, 'scale_pos_weight': 1.5287108517877392}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:46,021] Trial 209 finished with value: 0.9180768452156943 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.02004152220890537, 'subsample': 0.885663718503785, 'colsample_bytree': 0.739360736070657, 'gamma': 0.49188836132628744, 'scale_pos_weight': 1.3635892795239366}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:47,676] Trial 210 finished with value: 0.9163459246806825 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.019449410524928316, 'subsample': 0.8967233509992056, 'colsample_bytree': 0.735846705435995, 'gamma': 0.5325133733018446, 'scale_pos_weight': 1.3780237024114226}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:49,505] Trial 211 finished with value: 0.9196975146226233 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.021135706606900027, 'subsample': 0.8816725216927683, 'colsample_bytree': 0.7408317306402599, 'gamma': 0.37180599973841433, 'scale_pos_weight': 1.3437137953818252}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:51,240] Trial 212 finished with value: 0.918309589570576 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.021932480495957023, 'subsample': 0.8786598469671674, 'colsample_bytree': 0.7430640807795394, 'gamma': 0.41683322294076974, 'scale_pos_weight': 1.3560292818696498}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:52,509] Trial 213 finished with value: 0.9135331538496733 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.02143551662612629, 'subsample': 0.8862190801565245, 'colsample_bytree': 0.7419605421201312, 'gamma': 0.9911099894877001, 'scale_pos_weight': 1.425271833231998}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:54,256] Trial 214 finished with value: 0.9145711465279517 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.02023588077349347, 'subsample': 0.8881494760937738, 'colsample_bytree': 0.7294913550653656, 'gamma': 0.4256380248160095, 'scale_pos_weight': 1.3556223964790721}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:55,900] Trial 215 finished with value: 0.9168754003501274 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.017211552672786797, 'subsample': 0.8707820083735244, 'colsample_bytree': 0.7106248278305445, 'gamma': 0.7192499701046139, 'scale_pos_weight': 1.4628787142405557}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:57,527] Trial 216 finished with value: 0.9165786690355644 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.02189385494734184, 'subsample': 0.8590385182519206, 'colsample_bytree': 0.7485701370333162, 'gamma': 0.5427408075137906, 'scale_pos_weight': 1.484599183735016}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:53:59,435] Trial 217 finished with value: 0.9179227364698923 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.01896205400971889, 'subsample': 0.8817702213447358, 'colsample_bytree': 0.7556885606564022, 'gamma': 0.3887533339929128, 'scale_pos_weight': 1.3138318698025666}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:00,819] Trial 218 finished with value: 0.9196975146226233 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.023557627373605606, 'subsample': 0.8661116629757637, 'colsample_bytree': 0.7416336237886592, 'gamma': 0.7300636072025155, 'scale_pos_weight': 1.3544501977692616}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:01,824] Trial 219 finished with value: 0.9088055351468226 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.02363301048442511, 'subsample': 0.8629707929931688, 'colsample_bytree': 0.7453687930058678, 'gamma': 1.4758102129130064, 'scale_pos_weight': 1.267898587046511}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:03,106] Trial 220 finished with value: 0.9151473053145711 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.022548961725021167, 'subsample': 0.8544026137021699, 'colsample_bytree': 0.7277443059815983, 'gamma': 0.9122506676100829, 'scale_pos_weight': 1.3473510489355096}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:04,624] Trial 221 finished with value: 0.9168754003501274 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.020554733366925815, 'subsample': 0.8742323906445372, 'colsample_bytree': 0.7409182173983795, 'gamma': 0.6376045576922256, 'scale_pos_weight': 1.3903835836396878}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:06,397] Trial 222 finished with value: 0.9166440795081195 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.021426074704806057, 'subsample': 0.8681241935613134, 'colsample_bytree': 0.7646975149053735, 'gamma': 0.40853923160456623, 'scale_pos_weight': 1.3354574314261072}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:07,723] Trial 223 finished with value: 0.9182633254021745 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.023687938094230424, 'subsample': 0.8861357602474079, 'colsample_bytree': 0.7542836401585448, 'gamma': 0.7038556235123414, 'scale_pos_weight': 1.2938303717648185}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:09,007] Trial 224 finished with value: 0.9148693013553885 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.024093699838145886, 'subsample': 0.8752614242599077, 'colsample_bytree': 0.7558132394988792, 'gamma': 0.782710496639922, 'scale_pos_weight': 1.286488295247981}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:10,065] Trial 225 finished with value: 0.9119046057179816 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.025491606423445543, 'subsample': 0.892243396477082, 'colsample_bytree': 0.7672861841074785, 'gamma': 1.1774072373461313, 'scale_pos_weight': 1.2622361229280528}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:11,423] Trial 226 finished with value: 0.9182633254021745 and parameters: {'n_estimators': 400, 'max_depth': 11, 'learning_rate': 0.022952151419510514, 'subsample': 0.8655539910021708, 'colsample_bytree': 0.7705417151702847, 'gamma': 0.6818842653644841, 'scale_pos_weight': 1.2978867279390545}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:13,156] Trial 227 finished with value: 0.918309589570576 and parameters: {'n_estimators': 400, 'max_depth': 11, 'learning_rate': 0.023413163257526976, 'subsample': 0.8556857189297703, 'colsample_bytree': 0.7774460480922258, 'gamma': 0.3464221424087668, 'scale_pos_weight': 1.3143765695381593}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:13,791] Trial 228 finished with value: 0.8919788373308123 and parameters: {'n_estimators': 400, 'max_depth': 11, 'learning_rate': 0.024124941640660747, 'subsample': 0.855980403530686, 'colsample_bytree': 0.7749439339151342, 'gamma': 4.457866489934327, 'scale_pos_weight': 1.4245095259909564}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:15,659] Trial 229 finished with value: 0.9150837831189632 and parameters: {'n_estimators': 400, 'max_depth': 11, 'learning_rate': 0.02322144727003785, 'subsample': 0.8538834387031247, 'colsample_bytree': 0.7836589752099608, 'gamma': 0.276765594331534, 'scale_pos_weight': 1.387637324832277}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:16,383] Trial 230 finished with value: 0.9019274729766448 and parameters: {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.02689402832975641, 'subsample': 0.8677556996820506, 'colsample_bytree': 0.7703582308082547, 'gamma': 2.5736879109054214, 'scale_pos_weight': 1.3208561171183062}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:18,246] Trial 231 finished with value: 0.916298948755844 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.02245945107191757, 'subsample': 0.8631258996907786, 'colsample_bytree': 0.7583435394695768, 'gamma': 0.34207573361632054, 'scale_pos_weight': 1.3101603614902315}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:19,818] Trial 232 finished with value: 0.914027863629346 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.024648033517761698, 'subsample': 0.86370467516539, 'colsample_bytree': 0.7772390317064078, 'gamma': 0.5729665312537419, 'scale_pos_weight': 1.926151621005372}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:21,647] Trial 233 finished with value: 0.9179665940876115 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.021918964209659563, 'subsample': 0.8814486912541348, 'colsample_bytree': 0.7520948687725373, 'gamma': 0.3599499690323962, 'scale_pos_weight': 1.2927937965355387}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:23,124] Trial 234 finished with value: 0.9180768452156943 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.023327829013002465, 'subsample': 0.8696625195352384, 'colsample_bytree': 0.7862995434803192, 'gamma': 0.5765500435669925, 'scale_pos_weight': 1.2419326002757956}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:25,055] Trial 235 finished with value: 0.916298948755844 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.021630133924985015, 'subsample': 0.8561124160834722, 'colsample_bytree': 0.6935301504966669, 'gamma': 0.3358612997462187, 'scale_pos_weight': 1.3503008103952046}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:26,544] Trial 236 finished with value: 0.9148743957845458 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.018701691405512245, 'subsample': 0.8458944245555715, 'colsample_bytree': 0.7702117771544127, 'gamma': 0.805060066297791, 'scale_pos_weight': 1.2918279886680413}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:27,603] Trial 237 finished with value: 0.909807817917968 and parameters: {'n_estimators': 400, 'max_depth': 11, 'learning_rate': 0.02609493370744605, 'subsample': 0.8776428720419887, 'colsample_bytree': 0.7316412844487146, 'gamma': 0.9806580402511713, 'scale_pos_weight': 1.2239868546837087}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:28,158] Trial 238 finished with value: 0.8941632946303841 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.02271565275644075, 'subsample': 0.861121952109671, 'colsample_bytree': 0.7454919978052214, 'gamma': 9.320552325915605, 'scale_pos_weight': 1.3489582127538522}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:30,472] Trial 239 finished with value: 0.9134182730565066 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.024336145038779948, 'subsample': 0.8682862949813661, 'colsample_bytree': 0.7638934271877582, 'gamma': 0.1953854966862883, 'scale_pos_weight': 1.3981848847980665}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:32,595] Trial 240 finished with value: 0.9182633254021745 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.020632584400572095, 'subsample': 0.8504285833035722, 'colsample_bytree': 0.7931510616158455, 'gamma': 0.5049133404283794, 'scale_pos_weight': 1.2643790405946684}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:34,762] Trial 241 finished with value: 0.9196975146226233 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.020221994921038378, 'subsample': 0.85045185565848, 'colsample_bytree': 0.7955054012397913, 'gamma': 0.5104434922503454, 'scale_pos_weight': 1.2824419333341586}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:36,798] Trial 242 finished with value: 0.9165324048671627 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.0198265264617775, 'subsample': 0.8512826338847518, 'colsample_bytree': 0.7943464082424804, 'gamma': 0.6194081898936563, 'scale_pos_weight': 1.3153592290456642}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:38,996] Trial 243 finished with value: 0.9161195618667177 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.018185015773010692, 'subsample': 0.8476739111879201, 'colsample_bytree': 0.7780536315527945, 'gamma': 0.5301983124997696, 'scale_pos_weight': 1.2248895726308335}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:41,736] Trial 244 finished with value: 0.914804062839243 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.020501865232942586, 'subsample': 0.8580231126940707, 'colsample_bytree': 0.7929972298398504, 'gamma': 0.1846821585536662, 'scale_pos_weight': 1.2798475501925073}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:43,814] Trial 245 finished with value: 0.9180298692908557 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.02268523025313057, 'subsample': 0.881629134117327, 'colsample_bytree': 0.7826112598795837, 'gamma': 0.3629022797023081, 'scale_pos_weight': 1.3419214691279944}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:45,505] Trial 246 finished with value: 0.9182633254021745 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.021145286802526832, 'subsample': 0.8515741928502216, 'colsample_bytree': 0.7983555171797997, 'gamma': 0.7820599180013409, 'scale_pos_weight': 1.271449414186654}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:47,463] Trial 247 finished with value: 0.9196975146226233 and parameters: {'n_estimators': 400, 'max_depth': 11, 'learning_rate': 0.019701862117193644, 'subsample': 0.8740336205918238, 'colsample_bytree': 0.7916639110568678, 'gamma': 0.5488787470885341, 'scale_pos_weight': 1.2236169976991618}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:50,555] Trial 248 finished with value: 0.9112099548740769 and parameters: {'n_estimators': 400, 'max_depth': 12, 'learning_rate': 0.014935440105727622, 'subsample': 0.8902753446933104, 'colsample_bytree': 0.7824424074997157, 'gamma': 0.16764874350104372, 'scale_pos_weight': 1.2249100526066785}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:52,617] Trial 249 finished with value: 0.9168754003501274 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.01734258052033011, 'subsample': 0.8744735420283406, 'colsample_bytree': 0.7243838109362298, 'gamma': 0.6869074878706958, 'scale_pos_weight': 1.4370937802190955}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:54,258] Trial 250 finished with value: 0.9150299280432218 and parameters: {'n_estimators': 400, 'max_depth': 11, 'learning_rate': 0.019061223743050415, 'subsample': 0.8848734938527846, 'colsample_bytree': 0.7715008802529382, 'gamma': 0.9237108711715646, 'scale_pos_weight': 1.382179094773023}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:56,936] Trial 251 finished with value: 0.9131383808203768 and parameters: {'n_estimators': 400, 'max_depth': 12, 'learning_rate': 0.016116930910625982, 'subsample': 0.872929763783201, 'colsample_bytree': 0.6807025403474558, 'gamma': 0.3680790783051324, 'scale_pos_weight': 1.3061034166697836}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:54:59,258] Trial 252 finished with value: 0.9117976036495776 and parameters: {'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.02537497678859889, 'subsample': 0.9014716305742939, 'colsample_bytree': 0.7497397071546194, 'gamma': 0.006527072431060377, 'scale_pos_weight': 1.2227631468510431}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:00,958] Trial 253 finished with value: 0.9166440795081193 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.023261687537681434, 'subsample': 0.8662303089571565, 'colsample_bytree': 0.7868359929443914, 'gamma': 0.6209323036103315, 'scale_pos_weight': 1.3273388343888166}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:03,462] Trial 254 finished with value: 0.9130292846865119 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.01954712916874749, 'subsample': 0.8791828675008018, 'colsample_bytree': 0.7158726758652755, 'gamma': 0.27658900858326785, 'scale_pos_weight': 1.369835683937852}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:05,503] Trial 255 finished with value: 0.9180833631577257 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.02181178225055449, 'subsample': 0.8609362942907843, 'colsample_bytree': 0.7759549633594273, 'gamma': 0.4028571042067862, 'scale_pos_weight': 1.20027593660359}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:07,900] Trial 256 finished with value: 0.9112099548740769 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.018237110655411684, 'subsample': 0.8704200415975338, 'colsample_bytree': 0.7354820291609419, 'gamma': 0.1607102881310865, 'scale_pos_weight': 1.2920966350535168}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:09,233] Trial 257 finished with value: 0.9093051589259773 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.024137384681252295, 'subsample': 0.894920997674732, 'colsample_bytree': 0.7584673327406197, 'gamma': 1.0514187119486897, 'scale_pos_weight': 1.49921684097303}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:10,016] Trial 258 finished with value: 0.9104591825677844 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.08945159977407356, 'subsample': 0.8837992101031803, 'colsample_bytree': 0.8000166028403797, 'gamma': 0.8020133029067626, 'scale_pos_weight': 1.2532027884008827}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:12,077] Trial 259 finished with value: 0.9165786690355644 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.01973014206874848, 'subsample': 0.8617042184287664, 'colsample_bytree': 0.7485286585660028, 'gamma': 0.5208019389431544, 'scale_pos_weight': 1.3323293592595078}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:14,713] Trial 260 finished with value: 0.9100404570458535 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.022068774417102668, 'subsample': 0.8750874352103348, 'colsample_bytree': 0.7876768985216641, 'gamma': 0.1630184106964485, 'scale_pos_weight': 1.4056773104414595}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:16,174] Trial 261 finished with value: 0.9165800710221459 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.027008925355956448, 'subsample': 0.8571309173001928, 'colsample_bytree': 0.7697734171866517, 'gamma': 0.6445795416294416, 'scale_pos_weight': 1.2274040020040868}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:18,605] Trial 262 finished with value: 0.9165719739426592 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.021045101829888852, 'subsample': 0.8417337657585928, 'colsample_bytree': 0.7623460135390445, 'gamma': 0.3258363735830605, 'scale_pos_weight': 1.1881219689763778}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:20,360] Trial 263 finished with value: 0.9196975146226233 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.02385825998383097, 'subsample': 0.8676750936031736, 'colsample_bytree': 0.7091435609951685, 'gamma': 0.4863144978493718, 'scale_pos_weight': 1.2943065968549348}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:22,786] Trial 264 finished with value: 0.9147576267144318 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.012722141403584674, 'subsample': 0.8886451709186143, 'colsample_bytree': 0.7042369812929908, 'gamma': 0.4724415658171786, 'scale_pos_weight': 1.2605485433147081}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:25,012] Trial 265 finished with value: 0.910780069603599 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.0247610913195971, 'subsample': 0.6638848608076098, 'colsample_bytree': 0.6971872431598467, 'gamma': 0.15950369690105443, 'scale_pos_weight': 1.361813656206391}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:27,297] Trial 266 finished with value: 0.9148647595353954 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.017402517051837988, 'subsample': 0.8761917795946778, 'colsample_bytree': 0.711006873705, 'gamma': 0.34940135960590846, 'scale_pos_weight': 1.4569558012161161}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:29,804] Trial 267 finished with value: 0.9150937554151047 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.02616367498224146, 'subsample': 0.8674453849201064, 'colsample_bytree': 0.7218551872745583, 'gamma': 0.034673828856006006, 'scale_pos_weight': 2.1040200016174864}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:31,723] Trial 268 finished with value: 0.9196975146226233 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.019754567849890412, 'subsample': 0.8816449432204042, 'colsample_bytree': 0.7322194107323473, 'gamma': 0.5024610671023151, 'scale_pos_weight': 1.322092289160054}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:34,434] Trial 269 finished with value: 0.913326636515239 and parameters: {'n_estimators': 500, 'max_depth': 17, 'learning_rate': 0.018708306613607287, 'subsample': 0.8579752760422497, 'colsample_bytree': 0.7135335260713145, 'gamma': 0.30714706687479193, 'scale_pos_weight': 1.5720822651222113}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:36,552] Trial 270 finished with value: 0.918309589570576 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.019942004410108308, 'subsample': 0.8750253177574492, 'colsample_bytree': 0.7402652747150545, 'gamma': 0.4444867877587396, 'scale_pos_weight': 1.4189106332297305}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:38,901] Trial 271 finished with value: 0.9111877937576971 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.01614264464172717, 'subsample': 0.8730199645622925, 'colsample_bytree': 0.7365193893848011, 'gamma': 0.4922132515198204, 'scale_pos_weight': 2.620732940344129}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:40,690] Trial 272 finished with value: 0.9122348626211222 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.0586538626823409, 'subsample': 0.8464629346779841, 'colsample_bytree': 0.7320572441008907, 'gamma': 0.13696414735681128, 'scale_pos_weight': 2.050807809785719}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:42,982] Trial 273 finished with value: 0.9126608096307127 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.019671174482378165, 'subsample': 0.8673011361730075, 'colsample_bytree': 0.7243256254785664, 'gamma': 0.2893034634806706, 'scale_pos_weight': 2.340569489190814}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:45,521] Trial 274 finished with value: 0.9095958034091792 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.014130062239236407, 'subsample': 0.854103994204129, 'colsample_bytree': 0.7436798334790913, 'gamma': 0.0076902995231623306, 'scale_pos_weight': 1.3317673456812482}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:47,415] Trial 275 finished with value: 0.9151006221973963 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.017274114738508647, 'subsample': 0.8792286418110626, 'colsample_bytree': 0.6884343695201061, 'gamma': 0.48978159394055903, 'scale_pos_weight': 1.391922451436509}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:49,706] Trial 276 finished with value: 0.9129569950630539 and parameters: {'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.018580969226430672, 'subsample': 0.8603725661330685, 'colsample_bytree': 0.7314230129699416, 'gamma': 0.2772458825344351, 'scale_pos_weight': 1.1840671267388188}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:52,060] Trial 277 finished with value: 0.9111877937576971 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.020413982843758654, 'subsample': 0.8705337321434873, 'colsample_bytree': 0.7170531571605118, 'gamma': 0.5202797021970387, 'scale_pos_weight': 2.933389909887843}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:54,787] Trial 278 finished with value: 0.9179665940876115 and parameters: {'n_estimators': 450, 'max_depth': 13, 'learning_rate': 0.01967040845329908, 'subsample': 0.8415330035606884, 'colsample_bytree': 0.7327491341953875, 'gamma': 0.009169247973032814, 'scale_pos_weight': 1.2402309486972503}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:56,659] Trial 279 finished with value: 0.9168541023932246 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.021805379634325217, 'subsample': 0.8774971555457106, 'colsample_bytree': 0.803086531589131, 'gamma': 0.36302788163941635, 'scale_pos_weight': 1.3621593122358784}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:55:58,328] Trial 280 finished with value: 0.9179665940876115 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.018219267569200157, 'subsample': 0.8626338107049802, 'colsample_bytree': 0.7955181657885257, 'gamma': 0.6431868798026192, 'scale_pos_weight': 1.2990114258004515}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:56:00,910] Trial 281 finished with value: 0.9113841789680466 and parameters: {'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.015505907635604943, 'subsample': 0.8532744919743515, 'colsample_bytree': 0.7403643607613278, 'gamma': 0.19420200187945577, 'scale_pos_weight': 1.2175694649867832}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:56:02,209] Trial 282 finished with value: 0.9117583756969424 and parameters: {'n_estimators': 450, 'max_depth': 10, 'learning_rate': 0.02233113153325309, 'subsample': 0.8697680440376871, 'colsample_bytree': 0.704641805789619, 'gamma': 0.8614000103702427, 'scale_pos_weight': 1.2724318814192526}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:56:03,932] Trial 283 finished with value: 0.9163020670629634 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.020488297473953775, 'subsample': 0.8937117966001825, 'colsample_bytree': 0.7239922283301959, 'gamma': 0.4446404038126803, 'scale_pos_weight': 1.1643712450948087}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:56:06,003] Trial 284 finished with value: 0.9142772267086474 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.023659691001195603, 'subsample': 0.9917117820021277, 'colsample_bytree': 0.7886881789351018, 'gamma': 0.19414537247243438, 'scale_pos_weight': 1.3403249928966277}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:56:06,288] Trial 285 finished with value: 0.8926861746165008 and parameters: {'n_estimators': 50, 'max_depth': 10, 'learning_rate': 0.01700624956560984, 'subsample': 0.8781317792086694, 'colsample_bytree': 0.8104566540322781, 'gamma': 0.600215882685094, 'scale_pos_weight': 1.4053411764094363}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:56:08,200] Trial 286 finished with value: 0.9180833631577257 and parameters: {'n_estimators': 450, 'max_depth': 13, 'learning_rate': 0.021108882068752503, 'subsample': 0.8625678074775204, 'colsample_bytree': 0.7444564251125716, 'gamma': 0.413660550003614, 'scale_pos_weight': 1.3129224786484994}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:56:08,771] Trial 287 finished with value: 0.9084544241486674 and parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.20096726005429655, 'subsample': 0.8468928745133535, 'colsample_bytree': 0.8002370812686155, 'gamma': 0.7918561754013361, 'scale_pos_weight': 1.2502975382362034}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:56:11,017] Trial 288 finished with value: 0.9115177114134477 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.01914525438780901, 'subsample': 0.8702565252854438, 'colsample_bytree': 0.7809625933167996, 'gamma': 0.20932500051149708, 'scale_pos_weight': 1.189068003978992}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:56:13,421] Trial 289 finished with value: 0.9194868538868539 and parameters: {'n_estimators': 450, 'max_depth': 8, 'learning_rate': 0.022146587861074936, 'subsample': 0.8561852790067156, 'colsample_bytree': 0.9977452846223305, 'gamma': 0.014253728101552454, 'scale_pos_weight': 1.2684054917371492}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:56:15,914] Trial 290 finished with value: 0.9194868538868539 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.02828936848706702, 'subsample': 0.8517967603422318, 'colsample_bytree': 0.9692836562891647, 'gamma': 0.013727227896567606, 'scale_pos_weight': 1.2248955107215085}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:56:18,599] Trial 291 finished with value: 0.916261457061457 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.026026608135737563, 'subsample': 0.8367343656344748, 'colsample_bytree': 0.9825104398412003, 'gamma': 0.0745115669975498, 'scale_pos_weight': 1.2121807409947385}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:56:21,042] Trial 292 finished with value: 0.9180138380138381 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.02727658073481506, 'subsample': 0.8518784946881163, 'colsample_bytree': 0.9881482417375782, 'gamma': 0.006670485265737741, 'scale_pos_weight': 1.162060601415775}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:56:23,576] Trial 293 finished with value: 0.9177578216287893 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.028102385637640174, 'subsample': 0.8413161291072224, 'colsample_bytree': 0.9732196443330915, 'gamma': 0.002985402511234414, 'scale_pos_weight': 1.2426656338203372}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:56:25,874] Trial 294 finished with value: 0.9165890161165752 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.024580493095957896, 'subsample': 0.8566093810817534, 'colsample_bytree': 0.961520236294999, 'gamma': 0.22288247317702106, 'scale_pos_weight': 1.2615493314598796}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:56:27,942] Trial 295 finished with value: 0.9144808119001666 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.025267515035162252, 'subsample': 0.8454381440628225, 'colsample_bytree': 0.9975244649740248, 'gamma': 0.24850837653669702, 'scale_pos_weight': 1.2040318384038904}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:56:30,344] Trial 296 finished with value: 0.9177578216287893 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.022969500723167453, 'subsample': 0.854750667232634, 'colsample_bytree': 0.9785075068085201, 'gamma': 0.004425029509314449, 'scale_pos_weight': 1.2779088078744565}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:56:32,226] Trial 297 finished with value: 0.9149124256903785 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.02256365686641022, 'subsample': 0.8616796693852986, 'colsample_bytree': 0.9639520873301132, 'gamma': 0.34132458358787976, 'scale_pos_weight': 1.144762943728585}. Best is trial 110 with value: 0.920920352877158.\n",
      "[I 2025-03-15 18:56:34,081] Trial 298 finished with value: 0.9194868538868539 and parameters: {'n_estimators': 450, 'max_depth': 8, 'learning_rate': 0.024781431374755466, 'subsample': 0.8479212850375316, 'colsample_bytree': 0.9921774439181105, 'gamma': 0.2543551129931264, 'scale_pos_weight': 1.2483363991499015}. Best is trial 110 with value: 0.920920352877158.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trained_model = train_pipe(\n",
    "    model=model,\n",
    "    dataset_name=\"MPU_features.csv\",\n",
    "    save_name=\"MF_VIF_XGB_KFoldOptuna_Final\",\n",
    "    feature_columns=[\"median\", \"max\", \"mean\", \"p2p\", \"impulse\"],\n",
    "    target_column=\"fall_binary\",\n",
    "    experiment_name=\"Classic Models MPU\",\n",
    "    use_early_stopping=False,\n",
    "    if_optuna=True,\n",
    "    n_trials=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model does not support feature importance.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Usage (after training a model)\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mplot_feature_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmedian\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mp2p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimpulse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 14\u001b[0m, in \u001b[0;36mplot_feature_importance\u001b[0;34m(model, feature_columns)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_importances_\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# Ensure model supports feature importance\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     importances \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[0;32m---> 14\u001b[0m     feature_importance_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFeature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mImportance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimportances\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     feature_importance_df \u001b[38;5;241m=\u001b[39m feature_importance_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[0;32m~/Desktop/Master These/master/.venv/lib/python3.10/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/Desktop/Master These/master/.venv/lib/python3.10/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Master These/master/.venv/lib/python3.10/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/Desktop/Master These/master/.venv/lib/python3.10/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "def plot_feature_importance(model, feature_columns):\n",
    "    \"\"\"\n",
    "    Plots feature importance for tree-based models.\n",
    "\n",
    "    Args:\n",
    "        model: Trained XGBoost, RandomForest, or GradientBoosting model.\n",
    "        feature_columns: List of feature names.\n",
    "\n",
    "    Returns:\n",
    "        None (Displays feature importance plot)\n",
    "    \"\"\"\n",
    "    if hasattr(model, \"feature_importances_\"):  # Ensure model supports feature importance\n",
    "        importances = model.feature_importances_\n",
    "        feature_importance_df = pd.DataFrame({\"Feature\": feature_columns, \"Importance\": importances})\n",
    "        feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.barplot(x=\"Importance\", y=\"Feature\", data=feature_importance_df[:15])  # Top 15 features\n",
    "        plt.title(\"Feature Importance\")\n",
    "        plt.show()\n",
    "\n",
    "        return feature_importance_df\n",
    "    else:\n",
    "        raise ValueError(\"This model does not support feature importance.\")\n",
    "\n",
    "# Usage (after training a model)\n",
    "plot_feature_importance(trained_model, [\"median\", \"max\", \"mean\", \"p2p\", \"impulse\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def ensemble_predict(models_with_features, dataset_name, target_column):\n",
    "    \"\"\"\n",
    "    Loads a dataset, splits it, loads an ensemble of models (with different feature sets),\n",
    "    and predicts on the test set.\n",
    "\n",
    "    Args:\n",
    "        models_with_features: A list of tuples (model_path, feature_columns) specifying each model's file path\n",
    "                              and the corresponding feature columns used for training.\n",
    "        dataset_name: The name of the dataset CSV file.\n",
    "        target_column: The name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    # ✅ Load dataset\n",
    "    df = load_data(dataset_name)\n",
    "\n",
    "    # ✅ Ensure target column exists\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' not found in dataset.\")\n",
    "\n",
    "    # ✅ Train-test split\n",
    "    data_train, data_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    y_test = data_test[target_column].values  # Target remains the same for all models\n",
    "\n",
    "    # ✅ Load models and their feature columns\n",
    "    models = []\n",
    "    y_preds = []\n",
    "\n",
    "    for model_path, feature_columns in models_with_features:\n",
    "        model = joblib.load(model_path)  # Load model\n",
    "        models.append(model)\n",
    "\n",
    "        # ✅ Extract the correct feature set for this model\n",
    "        X_test = data_test[feature_columns].values  # Select only the features it was trained on\n",
    "\n",
    "        # ✅ Predict (check if the model has `predict_proba` for probability averaging)\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]  # Get probability of the positive class\n",
    "        else:\n",
    "            y_pred_proba = model.predict(X_test)  # Some models might not have `predict_proba`\n",
    "\n",
    "        y_preds.append(y_pred_proba)\n",
    "\n",
    "    # ✅ Ensemble predictions (Average probabilities and threshold at 0.5)\n",
    "    y_pred = np.mean(y_preds, axis=0) > 0.5\n",
    "\n",
    "    # ✅ Compute metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    # ✅ Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # ✅ Print metrics\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    # ✅ Plot confusion matrix\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=[\"No Fall\", \"Fall\"], yticklabels=[\"No Fall\", \"Fall\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9764\n",
      "Precision: 0.9615\n",
      "Recall: 0.9615\n",
      "F1 Score: 0.9615\n",
      "ROC AUC: 0.9722\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ensemble_predict(\n",
    "    models_with_features=[\n",
    "        (\"models/MF_XGB_Optuna.pkl\", [\"max\", \"min\", \"mean\", \"std\", \"median\", \"peak\", \"p2p\", \"energy\", \"rms\", \"crest\", \"shape\", \"impulse\", \"margin\"]),  \n",
    "        (\"models/MF_XGB_RD40_Optuna.pkl\", [\"median\", \"max\", \"peak\", \"mean\", \"p2p\"]),\n",
    "        (\"models/MF_XGB_RD41_Optuna.pkl\", [\"median\", \"max\", \"peak\", \"mean\", \"p2p\"])    \n",
    "    ],\n",
    "    dataset_name=\"MPU_features_pca.csv\",\n",
    "    target_column=\"fall_binary\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
