{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "\n",
    "# Data Handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning & Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "import optuna\n",
    "\n",
    "# Model Saving & Experiment Tracking\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow ui --port 5000\n",
      "[2025-03-14 16:56:20 +0100] [5269] [INFO] Starting gunicorn 23.0.0\n",
      "[2025-03-14 16:56:20 +0100] [5269] [ERROR] Connection in use: ('0.0.0.0', 5000)\n",
      "[2025-03-14 16:56:20 +0100] [5269] [ERROR] connection to ('0.0.0.0', 5000) failed: [Errno 48] Address already in use\n",
      "[2025-03-14 16:56:21 +0100] [5269] [ERROR] Connection in use: ('0.0.0.0', 5000)\n",
      "[2025-03-14 16:56:21 +0100] [5269] [ERROR] connection to ('0.0.0.0', 5000) failed: [Errno 48] Address already in use\n",
      "[2025-03-14 16:56:22 +0100] [5269] [ERROR] Connection in use: ('0.0.0.0', 5000)\n",
      "[2025-03-14 16:56:22 +0100] [5269] [ERROR] connection to ('0.0.0.0', 5000) failed: [Errno 48] Address already in use\n",
      "[2025-03-14 16:56:23 +0100] [5269] [ERROR] Connection in use: ('0.0.0.0', 5000)\n",
      "[2025-03-14 16:56:23 +0100] [5269] [ERROR] connection to ('0.0.0.0', 5000) failed: [Errno 48] Address already in use\n",
      "[2025-03-14 16:56:24 +0100] [5269] [ERROR] Connection in use: ('0.0.0.0', 5000)\n",
      "[2025-03-14 16:56:24 +0100] [5269] [ERROR] connection to ('0.0.0.0', 5000) failed: [Errno 48] Address already in use\n",
      "[2025-03-14 16:56:25 +0100] [5269] [ERROR] Can't connect to ('0.0.0.0', 5000)\n",
      "Running the mlflow server failed. Please see the logs above for details.\n"
     ]
    }
   ],
   "source": [
    "print(\"mlflow ui --port 5000\")\n",
    "!mlflow ui --port 5000 --host 0.0.0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    '''\n",
    "    Load data from a csv file into a pandas dataframe.\n",
    "    \n",
    "    Args:\n",
    "    file_name: The name of the csv file to load\n",
    "    \n",
    "    Returns:\n",
    "    df: A pandas dataframe containing the data from the csv file\n",
    "    '''\n",
    "    folder = \"datasets\"\n",
    "\n",
    "    df = pd.read_csv(f\"{folder}/{file_name}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratify Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_activity_split(df, target_column=\"fall_binary\", test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the dataset while ensuring 20% of each 'activity' is in the test set.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The full dataset containing 'activity' and the target variable.\n",
    "        target_column (str): The column representing the target labels.\n",
    "        test_size (float): The fraction of each activity to be in the test set.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        data_train (pd.DataFrame): Training set.\n",
    "        data_test (pd.DataFrame): Test set.\n",
    "    \"\"\"\n",
    "\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "\n",
    "    # ✅ Loop through each activity and apply train-test split\n",
    "    for activity, group in df.groupby(\"activity\"):\n",
    "        train, test = train_test_split(group, test_size=test_size, random_state=random_state, stratify=group[target_column])\n",
    "        train_list.append(train)\n",
    "        test_list.append(test)\n",
    "\n",
    "    # ✅ Concatenate results into train & test datasets\n",
    "    data_train = pd.concat(train_list).reset_index(drop=True)\n",
    "    data_test = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "    return data_train, data_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Per Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_per_activity(model, test_X, test_y, feature_columns=None):\n",
    "    \"\"\"\n",
    "    Evaluates model performance per activity type and logs the results in MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model (LSTM or Tree-based).\n",
    "        test_X: Test feature data (DataFrame).\n",
    "        test_y: Test target labels (Series).\n",
    "        target_column: The name of the target column.\n",
    "        feature_columns: The feature columns used for training.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame containing classification results per activity.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ✅ Ensure X_test is a DataFrame\n",
    "    if not isinstance(test_X, pd.DataFrame):\n",
    "        test_X = pd.DataFrame(test_X, columns=feature_columns)\n",
    "\n",
    "    # ✅ Ensure y_test is a Series\n",
    "    if isinstance(test_y, pd.DataFrame):\n",
    "        test_y = test_y.squeeze()  # Convert to Series if needed\n",
    "\n",
    "    # ✅ Ensure 'activity' column exists\n",
    "    if \"activity\" not in test_X.columns:\n",
    "        raise ValueError(\"Dataset does not contain an 'activity' column.\")\n",
    "\n",
    "    is_lstm = isinstance(model, tf.keras.Model)\n",
    "    results = []\n",
    "\n",
    "    # ✅ Loop through each unique activity and evaluate model performance\n",
    "    for activity in test_X[\"activity\"].unique():\n",
    "        # Filter test data for the current activity\n",
    "        X_test_activity = test_X[test_X[\"activity\"] == activity].copy()\n",
    "\n",
    "        # Extract the actual labels\n",
    "        y_test_activity = test_y.loc[X_test_activity.index].values.flatten()  # Ensure correct shape\n",
    "\n",
    "        # ✅ Check for missing values\n",
    "        if np.isnan(y_test_activity).any():\n",
    "            print(f\"Warning: NaN values found in y_test_activity for activity {activity}!\")\n",
    "            y_test_activity = np.nan_to_num(y_test_activity, nan=0)  # Replace NaN with 0 (No Fall)\n",
    "\n",
    "        # ✅ Ensure y_test_activity is integer\n",
    "        try:\n",
    "            y_test_activity = y_test_activity.astype(int)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error converting y_test_activity to integer for activity {activity}: {e}\")\n",
    "            continue  # Skip this activity if conversion fails\n",
    "\n",
    "        # ✅ Select feature columns\n",
    "        if is_lstm:\n",
    "            feature_columns = [col for col in X_test_activity.columns if col.startswith(\"value\")]\n",
    "\n",
    "        X_test_activity = X_test_activity[feature_columns].values  # Extract feature values\n",
    "\n",
    "        print(f\"Activity: {activity}, X shape: {X_test_activity.shape}, y shape: {y_test_activity.shape}\")\n",
    "\n",
    "        # ✅ Reshape X for LSTM input\n",
    "        if is_lstm:\n",
    "            X_test_activity = X_test_activity.reshape(-1, 500, 1)\n",
    "\n",
    "        # ✅ Predict fall_binary values\n",
    "        y_pred = model.predict(X_test_activity).round().astype(int).flatten()\n",
    "\n",
    "        # ✅ Compute correct and incorrect counts\n",
    "        correct = np.sum(y_pred == y_test_activity)\n",
    "        incorrect = len(y_pred) - correct\n",
    "\n",
    "        # ✅ Determine if the first sample of the activity is a fall or not\n",
    "        actual_fall = \"Fall\" if y_test_activity[0] == 1 else \"No Fall\"\n",
    "\n",
    "        print(f\"Activity {activity}: {correct} correct, {incorrect} incorrect\")\n",
    "\n",
    "        # ✅ Store results\n",
    "        results.append({\n",
    "            \"activity\": activity,\n",
    "            \"Actual Fall\": actual_fall,  # ✅ Single column for actual fall status\n",
    "            \"correct\": correct,\n",
    "            \"incorrect\": incorrect,\n",
    "            \"total\": len(y_pred),\n",
    "            \"accuracy\": correct / len(y_pred) if len(y_pred) > 0 else 0\n",
    "        })\n",
    "\n",
    "    # ✅ Convert results into a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # ✅ Mapping dictionary from abbreviations to full names\n",
    "    activity_mapping = {\n",
    "        \"S\": \"Still\",\n",
    "        \"CD\": \"Close Door\",\n",
    "        \"KD\": \"Knock Door\",\n",
    "        \"MA\": \"Minor Ambience (Sitting and Eating)\",\n",
    "        \"FOB\": \"Fall of object (Backpack)\",\n",
    "        \"FOL\": \"Fall of object (FaszienRolle)\",\n",
    "        \"WBS\": \"Walk by Sensor\",\n",
    "        \"RBS\": \"Rush by Sensor\",\n",
    "        \"SC\": \"Sitting down on chair\",\n",
    "        \"LC\": \"Laying down on couch\",\n",
    "        \"STC\": \"Stand up from Chair\",\n",
    "        \"PUF\": \"Picking something up from floor\",\n",
    "        \"K\": \"Kneeling down then standing up\",\n",
    "        \"SLB\": \"Standing Lost Balance\",\n",
    "        \"TF\": \"Trip and Fall - Forwards\",\n",
    "        \"SFB\": \"Slip and Fall - Backwards\",\n",
    "        \"FCS\": \"Chair - Fall to side\",\n",
    "        \"FCF\": \"Chair - Fall to Front\",\n",
    "        \"LAF\": \"Lying - Awake Fall\",\n",
    "        \"LSF\": \"Lying - Asleep Fall\",\n",
    "        \"FR\": \"Fall Recovery\",\n",
    "        \"KID\": \"Kids Running\"\n",
    "    }\n",
    "\n",
    "    # ✅ Function to extract the relevant part before the first '_'\n",
    "    def get_activity_name(code):\n",
    "        key = code.split('_')[0]  # Extract first part of activity code\n",
    "        return activity_mapping.get(key, code)  # Replace with full name if exists\n",
    "\n",
    "    # ✅ Apply the mapping to the results dataframe\n",
    "    results_df[\"activity\"] = results_df[\"activity\"].apply(get_activity_name)\n",
    "\n",
    "    # ✅ Save the results as a CSV file\n",
    "    results_path = \"activity_results.csv\"\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "\n",
    "    # ✅ Log results in MLflow\n",
    "    mlflow.log_artifact(results_path)\n",
    "\n",
    "    print(\"\\n📊 Per-Activity Results:\")\n",
    "    print(results_df)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Per Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_per_distance(model, test_X, test_y, feature_columns=None):\n",
    "    \"\"\"\n",
    "    Evaluates model performance per distance type and logs the results in MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model (LSTM or Tree-based).\n",
    "        test_X: Test feature data (DataFrame).\n",
    "        test_y: Test target labels (Series).\n",
    "        feature_columns: The feature columns used for training.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame containing classification results per distance.\n",
    "    \"\"\"\n",
    "\n",
    "    X_test = test_X.copy()\n",
    "    y_test = test_y.copy()\n",
    "\n",
    "    # ✅ Ensure X_test is a DataFrame\n",
    "    if not isinstance(X_test, pd.DataFrame):\n",
    "        X_test = pd.DataFrame(X_test, columns=feature_columns)\n",
    "\n",
    "    # ✅ Ensure y_test is a Series\n",
    "    if isinstance(y_test, pd.DataFrame):\n",
    "        y_test = y_test.squeeze()  # Convert to Series if needed\n",
    "\n",
    "    is_lstm = isinstance(model, tf.keras.Model)\n",
    "\n",
    "    # ✅ Ensure 'distance_m' column exists\n",
    "    if \"distance_m\" not in X_test.columns:\n",
    "        raise ValueError(\"Dataset does not contain a 'distance_m' column.\")\n",
    "\n",
    "    # ✅ Get unique distances and setup subplots dynamically\n",
    "    unique_distances = sorted(X_test[\"distance_m\"].unique())\n",
    "    fig, axes = plt.subplots(len(unique_distances), 1, figsize=(6, 4 * len(unique_distances))) \n",
    "\n",
    "    results = []\n",
    "    confusion_matrices = {}\n",
    "\n",
    "    # ✅ Loop through each unique distance and evaluate model performance\n",
    "    for i, distance in enumerate(unique_distances):\n",
    "        X_test_distance = X_test[X_test[\"distance_m\"] == distance].copy()\n",
    "        y_test_distance = y_test.loc[X_test_distance.index].values.flatten()  # Ensure correct shape\n",
    "\n",
    "        # ✅ Select feature columns\n",
    "        if is_lstm:\n",
    "            feature_columns = [col for col in X_test_distance.columns if col.startswith(\"value\")]\n",
    "\n",
    "        X_test_distance = X_test_distance[feature_columns].values  # Extract feature values\n",
    "\n",
    "        print(f\"Distance: {distance}, X shape: {X_test_distance.shape}, y shape: {y_test_distance.shape}\")\n",
    "\n",
    "        # ✅ Reshape X for LSTM input\n",
    "        if is_lstm:\n",
    "            X_test_distance = X_test_distance.reshape(-1, 500, 1)\n",
    "\n",
    "        # ✅ Predict fall_binary values\n",
    "        y_pred = model.predict(X_test_distance).round().astype(int).flatten()\n",
    "\n",
    "        # ✅ Compute correct and incorrect counts\n",
    "        correct = np.sum(y_pred == y_test_distance)\n",
    "        incorrect = len(y_pred) - correct\n",
    "\n",
    "        # ✅ Compute confusion matrix, ensuring both classes appear\n",
    "        cm = confusion_matrix(y_test_distance, y_pred, labels=[1, 0])\n",
    "\n",
    "        # ✅ Ensure confusion matrix always has shape (2,2)\n",
    "        if cm.shape == (1, 1):  \n",
    "            cm_fixed = np.array([[cm[0, 0], 0], [0, 0]])  \n",
    "        elif cm.shape == (1, 2):  \n",
    "            cm_fixed = np.vstack([cm, [0, 0]])  \n",
    "        elif cm.shape == (2, 1):  \n",
    "            cm_fixed = np.hstack([cm, [[0], [0]]])  \n",
    "        else:\n",
    "            cm_fixed = cm  \n",
    "\n",
    "        # ✅ Correct confusion matrix order:\n",
    "        # TP | FN\n",
    "        # FP | TN\n",
    "        cm_corrected = np.array([\n",
    "            [cm_fixed[0, 0], cm_fixed[1, 0]],  # True Positives, False Negatives\n",
    "            [cm_fixed[0, 1], cm_fixed[1, 1]]   # False Positives, True Negatives\n",
    "        ])\n",
    "\n",
    "        confusion_matrices[distance] = cm_corrected\n",
    "\n",
    "        # ✅ Plot confusion matrix with **correct** labels\n",
    "        sns.heatmap(cm_corrected, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=[\"Actual Fall\", \"Actual No Fall\"], \n",
    "                    yticklabels=[\"Predicted Fall\", \"Predicted No Fall\"],\n",
    "                    ax=axes[i] if len(unique_distances) > 1 else axes)\n",
    "        axes[i].set_title(f\"Confusion Matrix - Distance {distance}\")\n",
    "        axes[i].set_xlabel(\" \")\n",
    "        axes[i].set_ylabel(\" \")\n",
    "\n",
    "        print(f\"Distance {distance}: {correct} correct, {incorrect} incorrect\")\n",
    "\n",
    "        # ✅ Store results\n",
    "        results.append({\n",
    "            \"distance\": distance,\n",
    "            \"correct\": correct,\n",
    "            \"incorrect\": incorrect,\n",
    "            \"total\": len(y_pred),\n",
    "            \"accuracy\": correct / len(y_pred) if len(y_pred) > 0 else 0\n",
    "        })\n",
    "\n",
    "    # ✅ Save and log confusion matrix plot\n",
    "    confusion_matrix_path = \"confusion_matrices_distance.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(confusion_matrix_path)\n",
    "    plt.close()\n",
    "\n",
    "    # ✅ Convert results into a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # ✅ Save results as CSV\n",
    "    results_path = \"distance_results.csv\"\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "\n",
    "    # ✅ Log results in MLflow\n",
    "    mlflow.log_artifact(results_path)\n",
    "    mlflow.log_artifact(confusion_matrix_path)\n",
    "\n",
    "    print(\"\\n📊 Per-Distance Results:\")\n",
    "    print(results_df)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classical Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, model_class, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Defines the Optuna optimization objective with K-Fold Cross-Validation.\n",
    "    \n",
    "    Args:\n",
    "        trial: Optuna trial object.\n",
    "        model_class: The model class (e.g., XGBClassifier, RandomForestClassifier, GradientBoostingClassifier, SVC).\n",
    "        X_train, y_train: Training data (without separate test split).\n",
    "\n",
    "    Returns:\n",
    "        The average F1-score across all folds.\n",
    "    \"\"\"\n",
    "\n",
    "    # Suggest hyperparameters based on model type\n",
    "    if model_class == XGBClassifier:\n",
    "        num_no_falls = sum(y_train == 0)\n",
    "        num_falls = sum(y_train == 1)\n",
    "        default_scale_pos_weight = num_no_falls / num_falls\n",
    "\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0, 10),\n",
    "            \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", default_scale_pos_weight * 0.5, default_scale_pos_weight * 1.5)\n",
    "        }\n",
    "        model = XGBClassifier(**params, objective=\"binary:logistic\", random_state=42)\n",
    "\n",
    "    elif model_class == RandomForestClassifier:\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        }\n",
    "        model = RandomForestClassifier(**params, random_state=42)\n",
    "\n",
    "    elif model_class == GradientBoostingClassifier:\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        }\n",
    "        model = GradientBoostingClassifier(**params, random_state=42)\n",
    "\n",
    "    elif model_class == SVC:\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.1, 100, log=True),\n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"]),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0.001, 10, log=True),\n",
    "        }\n",
    "        model = SVC(**params, probability=True, random_state=42)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model class: {model_class.__name__}\")\n",
    "\n",
    "    # K-Fold Cross-Validation (Stratified to preserve class balance)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    f1_scores = []\n",
    "\n",
    "    ## Loop through each fold\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]  \n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        ## Train and evaluate the model\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "        y_pred = model.predict(X_fold_val)\n",
    "        f1_scores.append(f1_score(y_fold_val, y_pred))\n",
    "\n",
    "    ## Return average F1-score across folds\n",
    "    return np.mean(f1_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_log_classical_model(\n",
    "    model, \n",
    "    X_train, X_test, y_train, y_test, X_test_full,\n",
    "    save_name=\"classification_model\", \n",
    "    experiment_name=\"classical_models_experiment\",\n",
    "    target_column=\"fall_binary\",\n",
    "    feature_columns=None,\n",
    "    if_optuna=True,\n",
    "    n_trials=250,  # Number of hyperparameter tuning trials\n",
    "    dataset_name = \"fall_data.csv\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains a classical ML model (RandomForest, XGBoost, GradientBoosting, or SVM) with optional hyperparameter tuning\n",
    "    and logs everything to MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: A classical ML model (RandomForest, XGBoost, GradientBoosting, or SVM).\n",
    "        X_train, X_test, y_train, y_test: Pre-split training and testing datasets.\n",
    "        save_name: Name to save the trained model.\n",
    "        experiment_name: Name of the MLflow experiment.\n",
    "        n_trials: Number of hyperparameter tuning trials.\n",
    "\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Start MLflow experiment\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        # Identify model class\n",
    "        model_class = type(model)\n",
    "\n",
    "        if if_optuna:\n",
    "            # ✅ Perform hyperparameter optimization\n",
    "            study = optuna.create_study(direction=\"maximize\")\n",
    "            study.optimize(lambda trial: objective(trial, model_class, X_train, y_train), n_trials=n_trials)\n",
    "        \n",
    "            best_params = study.best_params\n",
    "            print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "            # ✅ Train final model with best params\n",
    "            if model_class == XGBClassifier:\n",
    "                best_model = XGBClassifier(**best_params, objective=\"binary:logistic\", use_label_encoder=False)\n",
    "            elif model_class.__name__ == \"GradientBoostingClassifier\":\n",
    "                best_model = model_class(**best_params, random_state=42)\n",
    "            elif model_class.__name__ == \"RandomForestClassifier\":\n",
    "                best_model = model_class(**best_params, random_state=42)\n",
    "            elif model_class == SVC:\n",
    "                best_model = SVC(**best_params, probability=True, random_state=42)  # ✅ Enable probability for ROC AUC\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported model class: {model_class.__name__}\")\n",
    "        else:\n",
    "            best_model = model\n",
    "\n",
    "        best_model.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "        # SVM needs probability predictions for AUC\n",
    "        if hasattr(best_model, \"predict_proba\"):\n",
    "            roc_auc = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "        # ✅ Log model parameters\n",
    "        mlflow.log_param(\"model_type\", best_model.__class__.__name__)\n",
    "        if if_optuna:\n",
    "            for param, value in best_params.items():\n",
    "                mlflow.log_param(param, value)\n",
    "        mlflow.log_param(\"num_features\", X_train.shape[1])\n",
    "\n",
    "        # Log features used for training as list\n",
    "        if feature_columns is not None:\n",
    "            mlflow.log_param(\"features\", feature_columns)\n",
    "        \n",
    "        # Log target column\n",
    "        mlflow.log_param(\"target_column\", target_column)\n",
    "        \n",
    "        mlflow.log_param(\"dataset\", dataset_name)\n",
    "            \n",
    "        # ✅ Log metrics\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "        # ✅ Save best model\n",
    "        models_folder = \"models\"\n",
    "        if not os.path.exists(models_folder):\n",
    "            os.makedirs(models_folder)\n",
    "        save_path = os.path.join(models_folder, f\"{save_name}.pkl\")\n",
    "        joblib.dump(best_model, save_path)\n",
    "        mlflow.log_artifact(save_path)\n",
    "\n",
    "        # Generate and save confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        conf_matrix = np.array([\n",
    "            [conf_matrix[0, 0], conf_matrix[1, 0]],  # True Positives, False Positives\n",
    "            [conf_matrix[0, 1], conf_matrix[1, 1]]   # False Negatives, True Negatives\n",
    "        ])\n",
    "\n",
    "        # Flip the order of labels for visualization\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(\n",
    "            conf_matrix[::-1, ::-1],  # Reverse rows and keep columns the same\n",
    "            annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Actual Fall\", \"Actual No Fall\"], \n",
    "            yticklabels=[\"Predicted Fall\", \"Predicted No Fall\"],\n",
    "        )\n",
    "        plt.xlabel(\" \")\n",
    "        plt.ylabel(\" \")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        conf_matrix_path = \"confusion_matrix.png\"\n",
    "        plt.savefig(conf_matrix_path)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(conf_matrix_path)\n",
    "\n",
    "        print(f\"Model trained with accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "        # ✅ After training and evaluation, call the per-activity evaluation\n",
    "        evaluate_per_activity(best_model, X_test_full, y_test, feature_columns)\n",
    "\n",
    "        # ✅ After training and evaluation, call the per-distance evaluation\n",
    "        evaluate_per_distance(best_model, X_test_full, y_test, feature_columns)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipe(\n",
    "    model, \n",
    "    dataset_name, \n",
    "    save_name=\"fall_model\", \n",
    "    feature_columns=None, \n",
    "    target_column=\"fall_binary\", \n",
    "    experiment_name=\"default_experiment\",\n",
    "    use_early_stopping=True,\n",
    "    if_optuna=True,\n",
    "    n_trials=250\n",
    "):\n",
    "    \"\"\"\n",
    "    General training pipeline for both classical models (XGBoost, RF, SVM) and deep learning models.\n",
    "\n",
    "    Args:\n",
    "        model: The initialized model (LSTM, RNN, RF, XGB, etc.).\n",
    "        dataset_name: The dataset CSV file.\n",
    "        save_name: Name to save the trained model.\n",
    "        feature_columns: List of feature column names.\n",
    "        target_column: The name of the target column.\n",
    "        experiment_name: MLflow experiment name.\n",
    "        use_early_stopping: Whether to use early stopping (for neural networks).\n",
    "        if_optuna: Whether to perform hyperparameter tuning (for tree-based models).\n",
    "\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    # ✅ Prevent overwriting existing models unless explicitly handled\n",
    "    if os.path.exists(f\"models/{save_name}.pkl\") or os.path.exists(f\"models/{save_name}.keras\"):\n",
    "        raise ValueError(f\"Model name '{save_name}' already exists. Choose a new name or delete the existing model.\")\n",
    "\n",
    "    # ✅ Load dataset\n",
    "    df = load_data(dataset_name)\n",
    "\n",
    "    # ✅ Auto-detect feature columns if not explicitly provided\n",
    "    value_columns = [col for col in df.columns if col.startswith(\"value\")]\n",
    "    if value_columns:\n",
    "        feature_columns = value_columns  \n",
    "    elif feature_columns is None:\n",
    "        raise ValueError(\"Feature columns must be specified.\")\n",
    "\n",
    "    # ✅ Ensure target column exists\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' not found in dataset.\")\n",
    "\n",
    "    data_train, data_test = stratified_activity_split(df, target_column=target_column, test_size=0.2, random_state=42)\n",
    "    print(f\"Train shape: {data_train.shape}, Test shape: {data_test.shape}\")\n",
    "\n",
    "    # ✅ Keep full test data (including metadata like 'activity' or 'distance_m')\n",
    "    X_test_full = data_test.copy()  \n",
    "\n",
    "    # ✅ Keep `X_train`, `X_test` as DataFrames & `y_train`, `y_test` as Series\n",
    "    X_train = data_train[feature_columns]  \n",
    "    X_test = data_test[feature_columns]    \n",
    "    y_train = data_train[target_column]  \n",
    "    y_test = data_test[target_column]    \n",
    "\n",
    "    # ✅ Check model type\n",
    "    is_tree = isinstance(model, (XGBClassifier, RandomForestClassifier, GradientBoostingClassifier))\n",
    "    is_svm = isinstance(model, SVC)\n",
    "\n",
    "    # ✅ Train tree-based models with optional Optuna hyperparameter tuning\n",
    "    if is_tree or is_svm:\n",
    "        model = train_and_log_classical_model(\n",
    "            model, X_train, X_test, y_train, y_test, X_test_full,\n",
    "            save_name=save_name,\n",
    "            experiment_name=experiment_name,\n",
    "            target_column=target_column,\n",
    "            feature_columns=feature_columns,\n",
    "            if_optuna=if_optuna,\n",
    "            n_trials=n_trials,\n",
    "            dataset_name=dataset_name\n",
    "        )\n",
    "    \n",
    "    # Delete the files activity_results.csv and distance_results.csv\n",
    "    os.remove(\"activity_results.csv\")\n",
    "    os.remove(\"distance_results.csv\")\n",
    "    os.remove(\"confusion_matrices_distance.png\")\n",
    "    os.remove(\"confusion_matrix.png\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mlflow.tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "def train_model(\n",
    "    model, \n",
    "    dataset_name, \n",
    "    save_name=\"lstm_fall_model\", \n",
    "    feature_columns=None, \n",
    "    target_column=\"fall_binary\", \n",
    "    experiment_name=\"default_experiment\",\n",
    "    use_early_stopping=True  # ✅ Option to enable/disable early stopping\n",
    "):\n",
    "    \"\"\"\n",
    "    Loads the dataset, reshapes it for RNN, trains the model, and logs everything to MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: The RNN model (already defined).\n",
    "        dataset_name: The name of the dataset CSV file.\n",
    "        save_name: Name to save the trained model.\n",
    "        feature_columns: List of feature column names (overwritten if 'value' columns exist).\n",
    "        target_column: The name of the target column.\n",
    "        experiment_name: Name of the MLflow experiment.\n",
    "        use_early_stopping: Whether to enable early stopping based on validation loss.\n",
    "\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load dataset\n",
    "    df = load_data(dataset_name)\n",
    "\n",
    "    # Auto-detect feature columns if they start with \"value\"\n",
    "    value_columns = [col for col in df.columns if col.startswith(\"value\")]\n",
    "    if value_columns:\n",
    "        feature_columns = value_columns  # Override feature selection\n",
    "    elif feature_columns is None:\n",
    "        raise ValueError(\"Feature columns must be specified if no 'value' columns exist.\")\n",
    "\n",
    "    # Ensure target column exists\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' not found in dataset.\")\n",
    "\n",
    "    # Train-test split but keep the full dataset for evaluation\n",
    "    data_train, data_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    print(f\"Train shape: {data_train.shape}, Test shape: {data_test.shape}\")\n",
    "\n",
    "    X_train = data_train[feature_columns].values\n",
    "    X_test = data_test[feature_columns].values\n",
    "\n",
    "    y_train = data_train[target_column].values\n",
    "    y_test = data_test[target_column].values\n",
    "    \n",
    "    X_test_full = X_test.copy()  # Keep a copy of the test data for evaluation\n",
    "    y_test_full = y_test.copy()\n",
    "\n",
    "    X_train = X_train[feature_columns].values\n",
    "    X_test = X_test[feature_columns].values\n",
    "\n",
    "    # Reshape X: (num_samples, timesteps=500, num_features)\n",
    "    if value_columns:\n",
    "        num_features = len(feature_columns) // 500  # Calculate how many features per timestep\n",
    "        X_test = X_test.reshape(-1, 500, num_features)\n",
    "        X_train = X_train.reshape(-1, 500, num_features)\n",
    "    else:\n",
    "        num_features = len(feature_columns)\n",
    "\n",
    "    # Print shapes\n",
    "    print(f\"X_test_full shape: {X_test_full.shape}\")\n",
    "    print(f\"y_test_full shape: {y_test_full.shape}\")\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "    is_lstm = isinstance(model, tf.keras.Model)\n",
    "\n",
    "    if is_lstm:\n",
    "        # ✅ Set up Early Stopping (if enabled)\n",
    "        callbacks = []\n",
    "        if use_early_stopping:\n",
    "            early_stopping = EarlyStopping(\n",
    "                monitor=\"val_loss\", patience=3, restore_best_weights=True, verbose=1\n",
    "            )\n",
    "            callbacks.append(early_stopping)\n",
    "\n",
    "    # Start MLflow experiment\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        print(f\"X_train shape: {X_train.shape}\")  # Should be (num_samples, timesteps, num_features)\n",
    "        print(f\"y_train shape: {y_train.shape}\")  # Should be (num_samples,)\n",
    "\n",
    "        # ✅ Log dataset name\n",
    "        mlflow.log_param(\"dataset_name\", dataset_name)  \n",
    "\n",
    "        if is_lstm:\n",
    "            # Train the model and log history\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                validation_data=(X_test, y_test),\n",
    "                callbacks=callbacks  # ✅ Apply Early Stopping if enabled\n",
    "            )\n",
    "        else:\n",
    "            model.fit(X_train, y_train)  # No need for epochs, batch size, or callbacks\n",
    "            \n",
    "        if is_lstm:\n",
    "            # Evaluate model\n",
    "            loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        else:\n",
    "            y_pred = model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # ✅ After training and evaluation, call the per-activity evaluation\n",
    "        results_df = evaluate_per_activity(model, X_test_full, y_test_full, target_column, feature_columns)\n",
    "        \n",
    "        # ✅ After training and evaluation, call the per-distance evaluation\n",
    "        evaluate_per_distance(model, X_test_full, y_test_full, target_column, feature_columns)\n",
    "\n",
    "        # ✅ Log per-activity accuracy in MLflow\n",
    "        mlflow.log_artifact(\"activity_results.csv\")\n",
    "\n",
    "        # ✅ Log model parameters\n",
    "        mlflow.log_param(\"num_features_used\", len(feature_columns))\n",
    "        mlflow.log_param(\"model_type\", model.__class__.__name__)\n",
    "\n",
    "        if is_lstm:\n",
    "            mlflow.log_param(\"epochs\", EPOCHS)\n",
    "            mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "            mlflow.log_param(\"optimizer\", model.optimizer.__class__.__name__)\n",
    "            mlflow.log_param(\"loss_function\", model.loss)\n",
    "            mlflow.log_param(\"early_stopping\", use_early_stopping)  # ✅ Log whether early stopping was used\n",
    "            mlflow.log_metric(\"final_loss\", loss)\n",
    "\n",
    "        # ✅ Log metrics\n",
    "        mlflow.log_metric(\"final_accuracy\", accuracy)\n",
    "\n",
    "        if is_lstm:\n",
    "            # ✅ Log accuracy and loss per epoch\n",
    "            for epoch, (train_acc, val_acc, train_loss, val_loss) in enumerate(zip(history.history['accuracy'], history.history['val_accuracy'], history.history['loss'], history.history['val_loss'])):\n",
    "                mlflow.log_metric(\"train_accuracy_epoch\", train_acc, step=epoch)\n",
    "                mlflow.log_metric(\"val_accuracy_epoch\", val_acc, step=epoch)\n",
    "                mlflow.log_metric(\"train_loss_epoch\", train_loss, step=epoch)\n",
    "                mlflow.log_metric(\"val_loss_epoch\", val_loss, step=epoch)\n",
    "\n",
    "        # ✅ Ensure models folder exists\n",
    "        models_folder = \"models\"\n",
    "        if not os.path.exists(models_folder):\n",
    "            os.makedirs(models_folder)\n",
    "\n",
    "        save_path = os.path.join(models_folder, save_name)\n",
    "\n",
    "        if is_lstm:\n",
    "            model.save(save_path + \".keras\")  # ✅ Save Keras model\n",
    "            mlflow.log_artifact(save_path + \".keras\")\n",
    "        else:\n",
    "            import joblib\n",
    "            joblib.dump(model, save_path + \".pkl\")  # ✅ Save tree-based model\n",
    "            mlflow.log_artifact(save_path + \".pkl\")\n",
    "\n",
    "        # ✅ Log the saved model file as an artifact in MLflow\n",
    "        mlflow.log_artifact(save_path + \".pkl\")\n",
    "\n",
    "        # ✅ Save confusion matrix\n",
    "        y_pred = model.predict(X_test).round()\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # Compute additional metrics\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "\n",
    "        # Log additional metrics\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "        # ✅ Save and log confusion matrix\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"No Fall\", \"Fall\"], yticklabels=[\"No Fall\", \"Fall\"])\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        conf_matrix_path = \"confusion_matrix.png\"\n",
    "        plt.savefig(conf_matrix_path)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(conf_matrix_path)\n",
    "\n",
    "        print(f\"Model trained with accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "        # Delete the files activity_results.csv and distance_results.csv\n",
    "        os.remove(\"activity_results.csv\")\n",
    "        os.remove(\"distance_results.csv\")\n",
    "        os.remove(\"confusion_matrices_distance.png\")\n",
    "        os.remove(\"confusion_matrix.png\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Collection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# XGBoost Model\n",
    "# ==========================\n",
    "\n",
    "def build_xgboost_model():\n",
    "    \"\"\"\n",
    "    Builds an XGBoost model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A compiled XGBoost model.\n",
    "    \"\"\"\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.11,\n",
    "        objective=\"binary:logistic\",\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ==========================\n",
    "# Random Forest Model\n",
    "# ==========================\n",
    "\n",
    "def build_random_forest_model():\n",
    "    \"\"\"\n",
    "    Builds a Random Forest model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Random Forest model.\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ==========================\n",
    "# GBM Model\n",
    "# ==========================\n",
    "def build_gradient_boosting_model():\n",
    "    \"\"\"\n",
    "    Builds a Gradient Boosting (GBM) model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Gradient Boosting model.\n",
    "    \"\"\"\n",
    "    return GradientBoostingClassifier(\n",
    "        n_estimators=200,  # Number of boosting stages\n",
    "        learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n",
    "        max_depth=5,  # Maximum depth of the trees\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "# ==========================\n",
    "# SVM Model\n",
    "# ==========================\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def build_svm_model():\n",
    "    \"\"\"\n",
    "    Builds an SVM model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A configured SVM model.\n",
    "    \"\"\"\n",
    "    model = SVC(\n",
    "        kernel=\"rbf\",  # Radial Basis Function (RBF) kernel (default)\n",
    "        C=1.0,         # Regularization parameter\n",
    "        gamma=\"scale\",  # Kernel coefficient\n",
    "        probability=True,  # Enable probability estimates (needed for ROC AUC)\n",
    "        random_state=42\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# RNN Model\n",
    "# ==========================\n",
    "def build_rnn_model():\n",
    "    \"\"\"\n",
    "    Builds a simple RNN model using Keras.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        SimpleRNN(RNN_UNITS, input_shape=INPUT_SHAPE, return_sequences=True),\n",
    "        SimpleRNN(RNN_UNITS),\n",
    "        Dense(DENSE_UNITS, activation=\"relu\"),\n",
    "        Dropout(DROPOUT_RATE),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNCTION, metrics=METRICS)\n",
    "    return model\n",
    "\n",
    "# ==========================\n",
    "# LSTM Model\n",
    "# ==========================\n",
    "def build_lstm_model(l2_lambda=0.001, dropout_rate=0.2, clipnorm=1.0):\n",
    "    \"\"\"\n",
    "    Builds an LSTM-based model with L2 regularization, dropout, and gradient clipping.\n",
    "\n",
    "    Args:\n",
    "        l2_lambda: Strength of L2 regularization (default: 0.001).\n",
    "        dropout_rate: Dropout rate to reduce overfitting (default: 0.2).\n",
    "        clipnorm: Gradient clipping norm (default: 1.0).\n",
    "\n",
    "    Returns:\n",
    "        A compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(RNN_UNITS, input_shape=INPUT_SHAPE, return_sequences=True, \n",
    "             kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),  # Dropout after first LSTM layer\n",
    "        LSTM(RNN_UNITS, kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),  # Dropout after second LSTM layer\n",
    "        Dense(DENSE_UNITS, activation=\"relu\", kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),  # Dropout before final layer\n",
    "        Dense(1, activation=\"sigmoid\")  # Output layer for binary classification\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(clipnorm=clipnorm)\n",
    "    model.compile(optimizer=optimizer, loss=LOSS_FUNCTION, metrics=METRICS)\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Bidirectional LSTM Model (Optional)\n",
    "# ==========================\n",
    "def build_bidirectional_lstm():\n",
    "    \"\"\"\n",
    "    Builds a Bidirectional LSTM model for improved sequence learning.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(RNN_UNITS, return_sequences=True), input_shape=INPUT_SHAPE),\n",
    "        Bidirectional(LSTM(RNN_UNITS)),\n",
    "        Dense(DENSE_UNITS, activation=\"relu\"),\n",
    "        Dropout(DROPOUT_RATE),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNCTION, metrics=METRICS)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# CONFIGURABLE VARIABLES\n",
    "# ==========================\n",
    "RNN_UNITS = 128           # Number of RNN/LSTM units\n",
    "DENSE_UNITS = 64         # Number of neurons in the dense layer\n",
    "DROPOUT_RATE = 0.1      # Dropout rate for regularization\n",
    "OPTIMIZER = \"adam\"       # Optimizer: \"adam\", \"sgd\", \"rmsprop\", etc.\n",
    "LOSS_FUNCTION = \"binary_crossentropy\"  # \"binary_crossentropy\" for classification\n",
    "METRICS = [\"accuracy\"]   # Metrics to monitor\n",
    "EPOCHS = 10              # Number of training epochs\n",
    "BATCH_SIZE = 16          # Batch size for training\n",
    "INPUT_SHAPE = (500, 1)   # (Time steps, Features) - Adjust based on your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.11, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=400, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Initialize the Model\n",
    "# ==========================\n",
    "model = build_xgboost_model()  # Change this to your desired model\n",
    "# print(model.summary())  # Print model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-14 18:30:35,223] A new study created in memory with name: no-name-0e0144b2-30c8-4de9-8b87-3c63cde49a0d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1016, 19), Test shape: (254, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-14 18:30:35,704] Trial 0 finished with value: 0.904539521609256 and parameters: {'n_estimators': 250, 'max_depth': 9, 'learning_rate': 0.06930354764506252, 'subsample': 0.6411589402505689, 'colsample_bytree': 0.7175531728375126, 'gamma': 3.140452015689066, 'scale_pos_weight': 3.1070827735031923}. Best is trial 0 with value: 0.904539521609256.\n",
      "[I 2025-03-14 18:30:35,905] Trial 1 finished with value: 0.8991926137357495 and parameters: {'n_estimators': 50, 'max_depth': 11, 'learning_rate': 0.06467076695885028, 'subsample': 0.7372312097356619, 'colsample_bytree': 0.6898951908892227, 'gamma': 3.39597302588007, 'scale_pos_weight': 2.4777494742871076}. Best is trial 0 with value: 0.904539521609256.\n",
      "[I 2025-03-14 18:30:36,499] Trial 2 finished with value: 0.8904864130840169 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.013168407803467286, 'subsample': 0.8693045297447435, 'colsample_bytree': 0.6532381258835546, 'gamma': 9.226751295512942, 'scale_pos_weight': 1.2959434183825451}. Best is trial 0 with value: 0.904539521609256.\n",
      "[I 2025-03-14 18:30:37,061] Trial 3 finished with value: 0.895629374864957 and parameters: {'n_estimators': 200, 'max_depth': 19, 'learning_rate': 0.01016434026485562, 'subsample': 0.615040451629234, 'colsample_bytree': 0.828525624520063, 'gamma': 4.851098215651186, 'scale_pos_weight': 1.397292684867392}. Best is trial 0 with value: 0.904539521609256.\n",
      "[I 2025-03-14 18:30:37,558] Trial 4 finished with value: 0.8923044312253381 and parameters: {'n_estimators': 400, 'max_depth': 12, 'learning_rate': 0.05960792194307403, 'subsample': 0.8818630086640754, 'colsample_bytree': 0.9863436037435032, 'gamma': 5.938339711929116, 'scale_pos_weight': 2.245114364467224}. Best is trial 0 with value: 0.904539521609256.\n",
      "[I 2025-03-14 18:30:38,194] Trial 5 finished with value: 0.9062127634256723 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.014540756956938954, 'subsample': 0.6552580593193927, 'colsample_bytree': 0.8284450932680971, 'gamma': 2.813487501305455, 'scale_pos_weight': 2.169503951716418}. Best is trial 5 with value: 0.9062127634256723.\n",
      "[I 2025-03-14 18:30:38,687] Trial 6 finished with value: 0.8901331561792045 and parameters: {'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.01597730062508174, 'subsample': 0.9836833034362739, 'colsample_bytree': 0.9266698926079983, 'gamma': 3.626106408031906, 'scale_pos_weight': 2.7136440499390764}. Best is trial 5 with value: 0.9062127634256723.\n",
      "[I 2025-03-14 18:30:39,312] Trial 7 finished with value: 0.8986790545256305 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.014756481605058892, 'subsample': 0.6723002158547957, 'colsample_bytree': 0.9363083029974366, 'gamma': 4.0435202421983, 'scale_pos_weight': 2.918771830061774}. Best is trial 5 with value: 0.9062127634256723.\n",
      "[I 2025-03-14 18:30:39,850] Trial 8 finished with value: 0.9147772793522548 and parameters: {'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.07065572867594383, 'subsample': 0.8283864782063912, 'colsample_bytree': 0.612161163847526, 'gamma': 2.1070398449469963, 'scale_pos_weight': 1.815118350192922}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:40,187] Trial 9 finished with value: 0.8800673591146122 and parameters: {'n_estimators': 250, 'max_depth': 3, 'learning_rate': 0.04405263555633157, 'subsample': 0.6736778771851996, 'colsample_bytree': 0.9804779070025313, 'gamma': 7.121352186895294, 'scale_pos_weight': 2.6831370902849474}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:41,447] Trial 10 finished with value: 0.8989379279439602 and parameters: {'n_estimators': 500, 'max_depth': 16, 'learning_rate': 0.28251747161821517, 'subsample': 0.804796260888994, 'colsample_bytree': 0.6080907376078978, 'gamma': 0.0441609866936874, 'scale_pos_weight': 1.7271349501290314}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:42,098] Trial 11 finished with value: 0.9078947999768902 and parameters: {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.1408798475277393, 'subsample': 0.7684470076744288, 'colsample_bytree': 0.8021748046233022, 'gamma': 1.0599635949510597, 'scale_pos_weight': 1.8940707298688977}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:42,944] Trial 12 finished with value: 0.9076897376438794 and parameters: {'n_estimators': 400, 'max_depth': 14, 'learning_rate': 0.16024021170362882, 'subsample': 0.7841817060279674, 'colsample_bytree': 0.7506240405932156, 'gamma': 0.5255949155938116, 'scale_pos_weight': 1.8121188374417423}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:43,473] Trial 13 finished with value: 0.9117788591025562 and parameters: {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.11959011715260637, 'subsample': 0.8631942007129332, 'colsample_bytree': 0.7921558484135837, 'gamma': 1.415026740449374, 'scale_pos_weight': 1.7574776555623597}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:44,392] Trial 14 finished with value: 0.9106722129246101 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.031509348894097275, 'subsample': 0.8836531872887307, 'colsample_bytree': 0.8769983892776569, 'gamma': 1.583703031523715, 'scale_pos_weight': 1.525001231943787}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:44,815] Trial 15 finished with value: 0.9017312008593736 and parameters: {'n_estimators': 350, 'max_depth': 14, 'learning_rate': 0.11652325847576733, 'subsample': 0.9344027158641275, 'colsample_bytree': 0.7514381691422775, 'gamma': 1.7684144891332958, 'scale_pos_weight': 1.1315977328982356}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:45,362] Trial 16 finished with value: 0.9136252827787622 and parameters: {'n_estimators': 450, 'max_depth': 7, 'learning_rate': 0.09761777753145236, 'subsample': 0.8272357765875182, 'colsample_bytree': 0.6158077627980401, 'gamma': 2.4079885983578766, 'scale_pos_weight': 2.0374554677937553}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:46,126] Trial 17 finished with value: 0.9093518135085557 and parameters: {'n_estimators': 450, 'max_depth': 13, 'learning_rate': 0.038372334096001985, 'subsample': 0.8278426522948629, 'colsample_bytree': 0.6069415827253719, 'gamma': 2.467773431158255, 'scale_pos_weight': 2.0344138906371207}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:46,506] Trial 18 finished with value: 0.8844387325637324 and parameters: {'n_estimators': 350, 'max_depth': 3, 'learning_rate': 0.08648047442849431, 'subsample': 0.7247577768244025, 'colsample_bytree': 0.6514886292462927, 'gamma': 6.258427055219576, 'scale_pos_weight': 2.372904135431251}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:47,220] Trial 19 finished with value: 0.8924269156493807 and parameters: {'n_estimators': 450, 'max_depth': 6, 'learning_rate': 0.026068682475847402, 'subsample': 0.929514549989913, 'colsample_bytree': 0.6562049809901853, 'gamma': 4.718332789908523, 'scale_pos_weight': 1.5973418256016534}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:47,703] Trial 20 finished with value: 0.8768313852631249 and parameters: {'n_estimators': 450, 'max_depth': 17, 'learning_rate': 0.2028765926677931, 'subsample': 0.8317360662919534, 'colsample_bytree': 0.6927661631027969, 'gamma': 8.177281581333489, 'scale_pos_weight': 2.035227742864717}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:48,276] Trial 21 finished with value: 0.9120335725908209 and parameters: {'n_estimators': 350, 'max_depth': 9, 'learning_rate': 0.09953525268254731, 'subsample': 0.8501216991843843, 'colsample_bytree': 0.6028908124983143, 'gamma': 2.071197205176345, 'scale_pos_weight': 1.9029099786636539}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:48,754] Trial 22 finished with value: 0.9086584608086241 and parameters: {'n_estimators': 350, 'max_depth': 10, 'learning_rate': 0.08670838750571985, 'subsample': 0.9308391297808718, 'colsample_bytree': 0.6123250794884847, 'gamma': 2.3432317442009056, 'scale_pos_weight': 1.9593731844790458}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:49,246] Trial 23 finished with value: 0.9126270509544991 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.08962789006443417, 'subsample': 0.8274892226873365, 'colsample_bytree': 0.64439871961855, 'gamma': 2.2226464842572105, 'scale_pos_weight': 2.3240383330016874}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:49,767] Trial 24 finished with value: 0.8981927477535766 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.04838677739958382, 'subsample': 0.7389792081628465, 'colsample_bytree': 0.646065454661328, 'gamma': 4.054054073472795, 'scale_pos_weight': 2.3602337903468675}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:50,823] Trial 25 finished with value: 0.9130096732598215 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.1898660522958529, 'subsample': 0.807467726549557, 'colsample_bytree': 0.6939072476086169, 'gamma': 0.6192688021177233, 'scale_pos_weight': 2.564496941166357}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:51,666] Trial 26 finished with value: 0.9025027354711057 and parameters: {'n_estimators': 500, 'max_depth': 6, 'learning_rate': 0.2135141163699163, 'subsample': 0.7631931600858038, 'colsample_bytree': 0.6903296062660306, 'gamma': 0.7697455874834179, 'scale_pos_weight': 2.544142942307977}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:53,493] Trial 27 finished with value: 0.9044442560749587 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.16145119180343537, 'subsample': 0.8032859972115817, 'colsample_bytree': 0.7342368219538326, 'gamma': 0.06744748209683316, 'scale_pos_weight': 2.7933074486948577}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:54,159] Trial 28 finished with value: 0.9065583699340646 and parameters: {'n_estimators': 500, 'max_depth': 4, 'learning_rate': 0.23970842237363318, 'subsample': 0.905493827118566, 'colsample_bytree': 0.6315997510563791, 'gamma': 0.9408101966584965, 'scale_pos_weight': 2.137227853425011}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:54,893] Trial 29 finished with value: 0.9094692548793247 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.06825989009507878, 'subsample': 0.9805501900296357, 'colsample_bytree': 0.7071588814782719, 'gamma': 3.009567497659617, 'scale_pos_weight': 3.089260250250972}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:55,478] Trial 30 finished with value: 0.8834761244499474 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.17240355094178722, 'subsample': 0.6978051554130797, 'colsample_bytree': 0.7242869959344831, 'gamma': 5.523554873527455, 'scale_pos_weight': 2.535238278435961}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:56,014] Trial 31 finished with value: 0.9091443376489279 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.08927137036169337, 'subsample': 0.8249926019786246, 'colsample_bytree': 0.6677335318124319, 'gamma': 2.0121553212976924, 'scale_pos_weight': 2.3290023352607148}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:56,227] Trial 32 finished with value: 0.9015054642437855 and parameters: {'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.07352975658096743, 'subsample': 0.8405179509264926, 'colsample_bytree': 0.6781135388123953, 'gamma': 3.185383139366397, 'scale_pos_weight': 2.2280892683110753}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:56,904] Trial 33 finished with value: 0.9076258651583042 and parameters: {'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.1256057591436428, 'subsample': 0.8036067003584935, 'colsample_bytree': 0.6268804986212574, 'gamma': 1.2602488521677757, 'scale_pos_weight': 2.455236518260819}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:57,417] Trial 34 finished with value: 0.8748609896308853 and parameters: {'n_estimators': 450, 'max_depth': 6, 'learning_rate': 0.07361138879030539, 'subsample': 0.7735304337438376, 'colsample_bytree': 0.6287051915383188, 'gamma': 9.983735962177034, 'scale_pos_weight': 2.5984502088331283}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:57,919] Trial 35 finished with value: 0.9145038542453051 and parameters: {'n_estimators': 250, 'max_depth': 8, 'learning_rate': 0.05568686438256261, 'subsample': 0.748644893553436, 'colsample_bytree': 0.6408568759827414, 'gamma': 2.5397943127841573, 'scale_pos_weight': 1.6579616883269053}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:58,419] Trial 36 finished with value: 0.9143182356587222 and parameters: {'n_estimators': 250, 'max_depth': 7, 'learning_rate': 0.05367142581423484, 'subsample': 0.7470677625478117, 'colsample_bytree': 0.6675059367369994, 'gamma': 2.595861668411623, 'scale_pos_weight': 1.5888005086671335}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:58,743] Trial 37 finished with value: 0.8957788059426235 and parameters: {'n_estimators': 150, 'max_depth': 11, 'learning_rate': 0.054560466481260776, 'subsample': 0.7411507034202347, 'colsample_bytree': 0.6650150362098844, 'gamma': 3.749460245848426, 'scale_pos_weight': 1.3326223410178182}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:59,481] Trial 38 finished with value: 0.9087508263035046 and parameters: {'n_estimators': 250, 'max_depth': 12, 'learning_rate': 0.023049252447158206, 'subsample': 0.7127095382613888, 'colsample_bytree': 0.6336310089552721, 'gamma': 2.746548333235929, 'scale_pos_weight': 1.5901656477615411}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:30:59,794] Trial 39 finished with value: 0.8931232099358569 and parameters: {'n_estimators': 150, 'max_depth': 4, 'learning_rate': 0.037858299282983426, 'subsample': 0.6129200469776476, 'colsample_bytree': 0.6001717179145614, 'gamma': 4.57480996525805, 'scale_pos_weight': 1.1384296632190254}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:00,188] Trial 40 finished with value: 0.9049299979042515 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.05616288853790503, 'subsample': 0.7531993325952551, 'colsample_bytree': 0.673894641696045, 'gamma': 3.3165812298536506, 'scale_pos_weight': 1.4055591019446605}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:01,179] Trial 41 finished with value: 0.910999794205879 and parameters: {'n_estimators': 250, 'max_depth': 7, 'learning_rate': 0.046260791703420845, 'subsample': 0.7913279497945913, 'colsample_bytree': 0.7096959280340152, 'gamma': 0.43532686552265765, 'scale_pos_weight': 1.6444186788290018}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:01,530] Trial 42 finished with value: 0.9103409708436617 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.06005585606007929, 'subsample': 0.8130775381659288, 'colsample_bytree': 0.6893441892797728, 'gamma': 2.7578547504015014, 'scale_pos_weight': 1.8213349613884091}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:01,846] Trial 43 finished with value: 0.8978529466553027 and parameters: {'n_estimators': 250, 'max_depth': 6, 'learning_rate': 0.10390003252643187, 'subsample': 0.6972670143019843, 'colsample_bytree': 0.7760108192288091, 'gamma': 4.076770913571924, 'scale_pos_weight': 1.455849618172667}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:02,423] Trial 44 finished with value: 0.9140300331309188 and parameters: {'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.0375399529858019, 'subsample': 0.7835570543978275, 'colsample_bytree': 0.6228593083996573, 'gamma': 1.6799131970054333, 'scale_pos_weight': 1.6794839683542482}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:02,844] Trial 45 finished with value: 0.912698989764667 and parameters: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.03280852299827592, 'subsample': 0.7755398658776008, 'colsample_bytree': 0.6198637367075496, 'gamma': 1.601750025422958, 'scale_pos_weight': 1.6960631499322991}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:03,395] Trial 46 finished with value: 0.8939049603203021 and parameters: {'n_estimators': 200, 'max_depth': 20, 'learning_rate': 0.020606214539271465, 'subsample': 0.6337333592418326, 'colsample_bytree': 0.6438779841444877, 'gamma': 3.562277237866673, 'scale_pos_weight': 1.8058621315083787}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:03,773] Trial 47 finished with value: 0.8991333157136221 and parameters: {'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.03971936015765125, 'subsample': 0.853070178864954, 'colsample_bytree': 0.8615960833014479, 'gamma': 2.67414193161901, 'scale_pos_weight': 1.235218859590597}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:04,475] Trial 48 finished with value: 0.907724101842456 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.0303052585576685, 'subsample': 0.8808543063197241, 'colsample_bytree': 0.6207902848132909, 'gamma': 1.8093844762717934, 'scale_pos_weight': 1.5451777911307432}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:05,112] Trial 49 finished with value: 0.9109230586277406 and parameters: {'n_estimators': 250, 'max_depth': 11, 'learning_rate': 0.04888825096144099, 'subsample': 0.7532359926680301, 'colsample_bytree': 0.6617172929916207, 'gamma': 1.2274133835710053, 'scale_pos_weight': 1.481716023385712}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:05,460] Trial 50 finished with value: 0.8938996239381813 and parameters: {'n_estimators': 250, 'max_depth': 12, 'learning_rate': 0.06708017010390793, 'subsample': 0.719604025395242, 'colsample_bytree': 0.9571657796641635, 'gamma': 5.115184685908151, 'scale_pos_weight': 2.021150077276604}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:06,159] Trial 51 finished with value: 0.9124165282922914 and parameters: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.05506290931434847, 'subsample': 0.7865380551419836, 'colsample_bytree': 0.6444635319425791, 'gamma': 0.504854193019598, 'scale_pos_weight': 1.6838366793678505}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:06,741] Trial 52 finished with value: 0.9059024943667193 and parameters: {'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.07727641488018053, 'subsample': 0.8156346185052179, 'colsample_bytree': 0.6853080770189339, 'gamma': 1.4699946917266986, 'scale_pos_weight': 1.9031805264967816}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:07,289] Trial 53 finished with value: 0.9101402189080311 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.13891175908029424, 'subsample': 0.7884652642618541, 'colsample_bytree': 0.6155609644092942, 'gamma': 2.331562823028006, 'scale_pos_weight': 1.746044466423621}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:07,720] Trial 54 finished with value: 0.913603848003848 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.0429818796761754, 'subsample': 0.8642028291376666, 'colsample_bytree': 0.6553396937256347, 'gamma': 0.8863680949781312, 'scale_pos_weight': 1.8340911250563332}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:08,000] Trial 55 finished with value: 0.904228839104352 and parameters: {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.04151820423163045, 'subsample': 0.896913768337531, 'colsample_bytree': 0.6352115042447473, 'gamma': 1.9560950381465956, 'scale_pos_weight': 1.8694606032320733}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:08,476] Trial 56 finished with value: 0.9140458786153758 and parameters: {'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.028535874620629485, 'subsample': 0.8592776592727536, 'colsample_bytree': 0.6602294326465119, 'gamma': 0.981300044941456, 'scale_pos_weight': 2.088361061033183}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:08,697] Trial 57 finished with value: 0.8881102074033885 and parameters: {'n_estimators': 50, 'max_depth': 10, 'learning_rate': 0.017691650393837275, 'subsample': 0.7583419210211017, 'colsample_bytree': 0.6002421762549222, 'gamma': 2.5143697487114376, 'scale_pos_weight': 2.0831510373830477}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:09,222] Trial 58 finished with value: 0.8867990842440552 and parameters: {'n_estimators': 350, 'max_depth': 8, 'learning_rate': 0.0346897461178152, 'subsample': 0.855783475466417, 'colsample_bytree': 0.6157456490736711, 'gamma': 6.476121210685081, 'scale_pos_weight': 1.9487695852734237}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:09,761] Trial 59 finished with value: 0.9107188675071887 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.027998320697232928, 'subsample': 0.8367965909962486, 'colsample_bytree': 0.668471837037588, 'gamma': 2.990796071970395, 'scale_pos_weight': 2.2410883676345517}. Best is trial 8 with value: 0.9147772793522548.\n",
      "[I 2025-03-14 18:31:10,490] Trial 60 finished with value: 0.9165800710221459 and parameters: {'n_estimators': 150, 'max_depth': 8, 'learning_rate': 0.027187046938814966, 'subsample': 0.7320035854633344, 'colsample_bytree': 0.8301276965437242, 'gamma': 0.0530953919116941, 'scale_pos_weight': 1.9830694417992778}. Best is trial 60 with value: 0.9165800710221459.\n",
      "[I 2025-03-14 18:31:11,217] Trial 61 finished with value: 0.9103779945052011 and parameters: {'n_estimators': 150, 'max_depth': 8, 'learning_rate': 0.02417620478416861, 'subsample': 0.7258860619195856, 'colsample_bytree': 0.8280130758033329, 'gamma': 0.006953395522303375, 'scale_pos_weight': 1.9828194805896393}. Best is trial 60 with value: 0.9165800710221459.\n",
      "[I 2025-03-14 18:31:11,915] Trial 62 finished with value: 0.9055299888074322 and parameters: {'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.01106574207853732, 'subsample': 0.6808984322916835, 'colsample_bytree': 0.8905148862534764, 'gamma': 1.2948385528371378, 'scale_pos_weight': 2.1140225609667738}. Best is trial 60 with value: 0.9165800710221459.\n",
      "[I 2025-03-14 18:31:12,388] Trial 63 finished with value: 0.9118518135085557 and parameters: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.021313910612327357, 'subsample': 0.7383078018581354, 'colsample_bytree': 0.8202104136862948, 'gamma': 1.6413840059047717, 'scale_pos_weight': 2.169629586910712}. Best is trial 60 with value: 0.9165800710221459.\n",
      "[I 2025-03-14 18:31:13,786] Trial 64 finished with value: 0.915053096395388 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.02770018344135927, 'subsample': 0.7037483456423899, 'colsample_bytree': 0.8414202521070062, 'gamma': 0.35102637337209974, 'scale_pos_weight': 1.7659725860507773}. Best is trial 60 with value: 0.9165800710221459.\n",
      "[I 2025-03-14 18:31:15,127] Trial 65 finished with value: 0.915053096395388 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.02770446046020014, 'subsample': 0.7058086709456967, 'colsample_bytree': 0.8490666164839418, 'gamma': 0.29777372886728304, 'scale_pos_weight': 1.6355500760305237}. Best is trial 60 with value: 0.9165800710221459.\n",
      "[I 2025-03-14 18:31:16,493] Trial 66 finished with value: 0.9118886768700722 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.02754703546285176, 'subsample': 0.7043612774491419, 'colsample_bytree': 0.8520789654742862, 'gamma': 0.23860231799740844, 'scale_pos_weight': 1.6047320174033344}. Best is trial 60 with value: 0.9165800710221459.\n",
      "[I 2025-03-14 18:31:17,578] Trial 67 finished with value: 0.9153740769681142 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.01934163238629867, 'subsample': 0.6837842568147099, 'colsample_bytree': 0.897835142772897, 'gamma': 1.0033730529507086, 'scale_pos_weight': 1.7616721862134395}. Best is trial 60 with value: 0.9165800710221459.\n",
      "[I 2025-03-14 18:31:18,790] Trial 68 finished with value: 0.9171211242122087 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.018046033982445635, 'subsample': 0.6801165024502478, 'colsample_bytree': 0.9209018834083013, 'gamma': 0.286958833321318, 'scale_pos_weight': 1.766794330445998}. Best is trial 68 with value: 0.9171211242122087.\n",
      "[I 2025-03-14 18:31:19,951] Trial 69 finished with value: 0.9140890417908135 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.01656095406622999, 'subsample': 0.6617005959534062, 'colsample_bytree': 0.9141120420630592, 'gamma': 0.3176614330628639, 'scale_pos_weight': 1.793885102480188}. Best is trial 68 with value: 0.9171211242122087.\n",
      "[I 2025-03-14 18:31:21,063] Trial 70 finished with value: 0.909067169109244 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.013268726343212495, 'subsample': 0.6852904040008595, 'colsample_bytree': 0.909433719821779, 'gamma': 0.7812128803256211, 'scale_pos_weight': 1.7230657057399468}. Best is trial 68 with value: 0.9171211242122087.\n",
      "[I 2025-03-14 18:31:22,347] Trial 71 finished with value: 0.9157703616849757 and parameters: {'n_estimators': 350, 'max_depth': 6, 'learning_rate': 0.021519421485517564, 'subsample': 0.6389314358965456, 'colsample_bytree': 0.8474859456406344, 'gamma': 0.4688488895226392, 'scale_pos_weight': 1.5207882338824428}. Best is trial 68 with value: 0.9171211242122087.\n",
      "[I 2025-03-14 18:31:23,099] Trial 72 finished with value: 0.9094852403184801 and parameters: {'n_estimators': 350, 'max_depth': 3, 'learning_rate': 0.020341684705210257, 'subsample': 0.644320472881974, 'colsample_bytree': 0.8455995691298461, 'gamma': 0.6573233155235734, 'scale_pos_weight': 1.5285833323408824}. Best is trial 68 with value: 0.9171211242122087.\n",
      "[I 2025-03-14 18:31:24,078] Trial 73 finished with value: 0.9140334116336024 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01858109852874161, 'subsample': 0.6665505604169664, 'colsample_bytree': 0.8824300893167742, 'gamma': 0.005836230766796069, 'scale_pos_weight': 1.7774108890441962}. Best is trial 68 with value: 0.9171211242122087.\n",
      "[I 2025-03-14 18:31:25,133] Trial 74 finished with value: 0.9132162966886226 and parameters: {'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.014584760313756271, 'subsample': 0.6297313475269772, 'colsample_bytree': 0.8152257937441005, 'gamma': 1.1231706349097528, 'scale_pos_weight': 1.8900931248897832}. Best is trial 68 with value: 0.9171211242122087.\n",
      "[I 2025-03-14 18:31:26,429] Trial 75 finished with value: 0.9109356018622747 and parameters: {'n_estimators': 350, 'max_depth': 6, 'learning_rate': 0.02280168834504368, 'subsample': 0.6546417989769099, 'colsample_bytree': 0.793191101952743, 'gamma': 0.23884065629434326, 'scale_pos_weight': 1.6316321074086264}. Best is trial 68 with value: 0.9171211242122087.\n",
      "[I 2025-03-14 18:31:27,819] Trial 76 finished with value: 0.9085690168275775 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.024574371620349596, 'subsample': 0.6004463671355768, 'colsample_bytree': 0.9508234370541635, 'gamma': 0.5240256518911293, 'scale_pos_weight': 1.319034455495369}. Best is trial 68 with value: 0.9171211242122087.\n",
      "[I 2025-03-14 18:31:28,927] Trial 77 finished with value: 0.9138071852207521 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.01880844790171047, 'subsample': 0.6880332535880581, 'colsample_bytree': 0.8633645881557473, 'gamma': 0.9764686290663044, 'scale_pos_weight': 1.4185799595693083}. Best is trial 68 with value: 0.9171211242122087.\n",
      "[I 2025-03-14 18:31:30,072] Trial 78 finished with value: 0.9118252583524649 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.015952476620051705, 'subsample': 0.7073606878112962, 'colsample_bytree': 0.8437974145887871, 'gamma': 0.30666995087625715, 'scale_pos_weight': 1.4815301029192418}. Best is trial 68 with value: 0.9171211242122087.\n",
      "[I 2025-03-14 18:31:31,019] Trial 79 finished with value: 0.9172746430814172 and parameters: {'n_estimators': 350, 'max_depth': 4, 'learning_rate': 0.01352076920644928, 'subsample': 0.6747291411893432, 'colsample_bytree': 0.999265595649104, 'gamma': 0.7130821624036267, 'scale_pos_weight': 1.734893356666268}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:31,775] Trial 80 finished with value: 0.8883494151656398 and parameters: {'n_estimators': 350, 'max_depth': 3, 'learning_rate': 0.010067443650001178, 'subsample': 0.6757641451035985, 'colsample_bytree': 0.7723822882334611, 'gamma': 0.5401207861089417, 'scale_pos_weight': 1.9362257284834494}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:32,570] Trial 81 finished with value: 0.9030795711882055 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.011951734711771132, 'subsample': 0.6926515495797387, 'colsample_bytree': 0.8715675264145818, 'gamma': 0.8105261926299098, 'scale_pos_weight': 1.7472507709777223}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:33,839] Trial 82 finished with value: 0.9106793695449739 and parameters: {'n_estimators': 350, 'max_depth': 16, 'learning_rate': 0.016162666512854314, 'subsample': 0.6525812727251529, 'colsample_bytree': 0.8962027734331568, 'gamma': 1.310036536079826, 'scale_pos_weight': 1.5398641624272698}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:34,991] Trial 83 finished with value: 0.9108472583461003 and parameters: {'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.01219135512653379, 'subsample': 0.7231573164655521, 'colsample_bytree': 0.808874925338287, 'gamma': 0.1737101847445098, 'scale_pos_weight': 1.6665081086808544}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:36,187] Trial 84 finished with value: 0.9168541023932246 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.0218185823276719, 'subsample': 0.7144051879597476, 'colsample_bytree': 0.9974753641200964, 'gamma': 0.6739777157518309, 'scale_pos_weight': 1.8712217535618263}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:37,347] Trial 85 finished with value: 0.913756292621897 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.025885277655843357, 'subsample': 0.6686485618860406, 'colsample_bytree': 0.998199658847349, 'gamma': 0.6467225282030882, 'scale_pos_weight': 1.851469131473407}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:38,349] Trial 86 finished with value: 0.9139861519160671 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.0221770966877521, 'subsample': 0.6440740987056586, 'colsample_bytree': 0.9823757501194261, 'gamma': 1.0802711868030033, 'scale_pos_weight': 1.7662659425926914}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:39,473] Trial 87 finished with value: 0.9123892542642542 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.018864046999135974, 'subsample': 0.7142901429661112, 'colsample_bytree': 0.9611792145638532, 'gamma': 0.38111834890186114, 'scale_pos_weight': 1.9930220555521454}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:41,121] Trial 88 finished with value: 0.9127702361971988 and parameters: {'n_estimators': 350, 'max_depth': 13, 'learning_rate': 0.013696917525792832, 'subsample': 0.6983865749905842, 'colsample_bytree': 0.9302248913142103, 'gamma': 0.7485853371265601, 'scale_pos_weight': 1.92102754599345}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:41,891] Trial 89 finished with value: 0.9146506262196953 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.03400948905258715, 'subsample': 0.6297682386791716, 'colsample_bytree': 0.9955131066225551, 'gamma': 1.3612675114733868, 'scale_pos_weight': 1.8301987697809843}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:42,474] Trial 90 finished with value: 0.892555983568255 and parameters: {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.02003823008384598, 'subsample': 0.7300723817430153, 'colsample_bytree': 0.9696412286031262, 'gamma': 7.833353993783151, 'scale_pos_weight': 1.717281077393649}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:43,309] Trial 91 finished with value: 0.9158718414499735 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.031232566314036123, 'subsample': 0.6256752586726246, 'colsample_bytree': 0.991942341000731, 'gamma': 1.1242551941125565, 'scale_pos_weight': 1.8337839788194101}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:44,415] Trial 92 finished with value: 0.9124323313281499 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.029770842694616027, 'subsample': 0.6761179317168368, 'colsample_bytree': 0.9693696899162861, 'gamma': 0.398293546032545, 'scale_pos_weight': 1.8628482062756122}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:45,232] Trial 93 finished with value: 0.9150835671867107 and parameters: {'n_estimators': 250, 'max_depth': 5, 'learning_rate': 0.025027888742395636, 'subsample': 0.6583880957723246, 'colsample_bytree': 0.8328388871261125, 'gamma': 0.017635928677459334, 'scale_pos_weight': 1.6387907759987401}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:45,906] Trial 94 finished with value: 0.910846401899659 and parameters: {'n_estimators': 250, 'max_depth': 4, 'learning_rate': 0.025652154126718965, 'subsample': 0.6213710998382258, 'colsample_bytree': 0.943794403623766, 'gamma': 0.13653737515746667, 'scale_pos_weight': 1.6260302431388118}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:46,898] Trial 95 finished with value: 0.912795160949376 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01712914735293684, 'subsample': 0.6634068205909398, 'colsample_bytree': 0.8354723470786052, 'gamma': 1.0530810004102864, 'scale_pos_weight': 1.7027832218949932}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:47,441] Trial 96 finished with value: 0.8962354787808973 and parameters: {'n_estimators': 250, 'max_depth': 3, 'learning_rate': 0.015303452815333846, 'subsample': 0.648256942011734, 'colsample_bytree': 0.9885536897631316, 'gamma': 0.008331821968293383, 'scale_pos_weight': 1.5838920228861624}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:48,357] Trial 97 finished with value: 0.9161023978732385 and parameters: {'n_estimators': 350, 'max_depth': 4, 'learning_rate': 0.022396823430169587, 'subsample': 0.6361720854711144, 'colsample_bytree': 0.9755227696336239, 'gamma': 0.6484489783792704, 'scale_pos_weight': 1.790085287780272}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:49,300] Trial 98 finished with value: 0.915592121170253 and parameters: {'n_estimators': 350, 'max_depth': 4, 'learning_rate': 0.02403452546894283, 'subsample': 0.6129045500114011, 'colsample_bytree': 0.9889924384079886, 'gamma': 0.6071800688129578, 'scale_pos_weight': 1.7941046733475454}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:50,162] Trial 99 finished with value: 0.9132606128837388 and parameters: {'n_estimators': 350, 'max_depth': 4, 'learning_rate': 0.022683864427771244, 'subsample': 0.600043259989323, 'colsample_bytree': 0.9734290961805973, 'gamma': 1.476235760764123, 'scale_pos_weight': 1.9941918424741398}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:50,906] Trial 100 finished with value: 0.9046637371800934 and parameters: {'n_estimators': 350, 'max_depth': 3, 'learning_rate': 0.03164159278079349, 'subsample': 0.6371651464003272, 'colsample_bytree': 0.9866320520737479, 'gamma': 0.6367275168948492, 'scale_pos_weight': 2.042784386575355}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:51,832] Trial 101 finished with value: 0.9158718414499735 and parameters: {'n_estimators': 350, 'max_depth': 4, 'learning_rate': 0.024625750353843665, 'subsample': 0.6161048281769161, 'colsample_bytree': 0.9756015004453902, 'gamma': 0.8259377164202437, 'scale_pos_weight': 1.771882638569906}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:52,742] Trial 102 finished with value: 0.911757155889197 and parameters: {'n_estimators': 350, 'max_depth': 4, 'learning_rate': 0.02364063133025804, 'subsample': 0.6221840566546963, 'colsample_bytree': 0.9927748392690938, 'gamma': 0.8527892131736792, 'scale_pos_weight': 1.809928981609284}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:53,550] Trial 103 finished with value: 0.9118716823421316 and parameters: {'n_estimators': 400, 'max_depth': 3, 'learning_rate': 0.02118998712136493, 'subsample': 0.6080409459102568, 'colsample_bytree': 0.9750851188996017, 'gamma': 1.8196938012242558, 'scale_pos_weight': 1.86628582617826}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:54,769] Trial 104 finished with value: 0.9162392908826409 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.019477230376780855, 'subsample': 0.6224819774098438, 'colsample_bytree': 0.9644124657302832, 'gamma': 1.0853845102994182, 'scale_pos_weight': 1.9272095141525305}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:56,025] Trial 105 finished with value: 0.9131864194550886 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.01948341992435013, 'subsample': 0.6129346028502949, 'colsample_bytree': 0.962112571763562, 'gamma': 1.1521249696078533, 'scale_pos_weight': 1.9420513966985529}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:57,029] Trial 106 finished with value: 0.912105940128409 and parameters: {'n_estimators': 350, 'max_depth': 4, 'learning_rate': 0.01788992949267597, 'subsample': 0.6208315654536308, 'colsample_bytree': 0.937349423094939, 'gamma': 0.9082225788335653, 'scale_pos_weight': 1.9095851849111565}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:58,011] Trial 107 finished with value: 0.9151175063974752 and parameters: {'n_estimators': 350, 'max_depth': 4, 'learning_rate': 0.021546988764450454, 'subsample': 0.6373218192559238, 'colsample_bytree': 0.9804054358676944, 'gamma': 1.456451055932124, 'scale_pos_weight': 1.803770417122344}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:31:59,319] Trial 108 finished with value: 0.9126544468413483 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.03571317032660172, 'subsample': 0.6268214316907323, 'colsample_bytree': 0.9509598194012887, 'gamma': 0.5353721539152587, 'scale_pos_weight': 2.049035683395971}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:32:00,434] Trial 109 finished with value: 0.9146381911086319 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.01747966445964511, 'subsample': 0.6121173419768781, 'colsample_bytree': 0.999615634006504, 'gamma': 0.7023919579086818, 'scale_pos_weight': 1.9688098762755164}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:32:01,136] Trial 110 finished with value: 0.909783620540134 and parameters: {'n_estimators': 350, 'max_depth': 3, 'learning_rate': 0.020076877555980317, 'subsample': 0.641288883276256, 'colsample_bytree': 0.9201322339297978, 'gamma': 1.9957602080533383, 'scale_pos_weight': 1.7212790893883438}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:32:02,036] Trial 111 finished with value: 0.9121860942090294 and parameters: {'n_estimators': 350, 'max_depth': 4, 'learning_rate': 0.023811988560349, 'subsample': 0.6358779059645445, 'colsample_bytree': 0.9781485199441479, 'gamma': 1.5429185782221786, 'scale_pos_weight': 1.801100116818443}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:32:02,971] Trial 112 finished with value: 0.916599820018104 and parameters: {'n_estimators': 350, 'max_depth': 4, 'learning_rate': 0.021290139107261286, 'subsample': 0.6475591132938358, 'colsample_bytree': 0.9822899988015356, 'gamma': 1.2049836530017066, 'scale_pos_weight': 1.847670641725106}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:32:04,254] Trial 113 finished with value: 0.9152510441543461 and parameters: {'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.014040258177463044, 'subsample': 0.6731828209237043, 'colsample_bytree': 0.9655367427959942, 'gamma': 1.1296330706615516, 'scale_pos_weight': 2.1584637545133636}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:32:05,415] Trial 114 finished with value: 0.9155201688033359 and parameters: {'n_estimators': 350, 'max_depth': 6, 'learning_rate': 0.026633388456164402, 'subsample': 0.6070911799503318, 'colsample_bytree': 0.9857207217182068, 'gamma': 0.9011838072046807, 'scale_pos_weight': 1.8581915997394456}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:32:06,137] Trial 115 finished with value: 0.9107180150763619 and parameters: {'n_estimators': 350, 'max_depth': 3, 'learning_rate': 0.02960101200641332, 'subsample': 0.6183991842566338, 'colsample_bytree': 0.9880048716157968, 'gamma': 1.281858807647651, 'scale_pos_weight': 1.8866971198442808}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:32:07,049] Trial 116 finished with value: 0.914206331387517 and parameters: {'n_estimators': 350, 'max_depth': 4, 'learning_rate': 0.03220776938310741, 'subsample': 0.6039222544099205, 'colsample_bytree': 0.9556342461038047, 'gamma': 0.4734440977274623, 'scale_pos_weight': 1.9090219287855568}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:32:08,078] Trial 117 finished with value: 0.9140233144408813 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.026524849195115663, 'subsample': 0.6499837288296703, 'colsample_bytree': 0.9443017635343542, 'gamma': 0.9016648894441972, 'scale_pos_weight': 1.8430593159272763}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:32:09,511] Trial 118 finished with value: 0.9143824366329285 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.015254122582992849, 'subsample': 0.6261720155086687, 'colsample_bytree': 0.9832808087927404, 'gamma': 0.7177036988424679, 'scale_pos_weight': 2.007355441737244}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:32:10,354] Trial 119 finished with value: 0.9138037747740784 and parameters: {'n_estimators': 350, 'max_depth': 4, 'learning_rate': 0.021966968166982497, 'subsample': 0.6100550530284534, 'colsample_bytree': 0.9905057875486274, 'gamma': 1.7025853816027363, 'scale_pos_weight': 1.9568982720852015}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:32:11,591] Trial 120 finished with value: 0.910018835600231 and parameters: {'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.024393790696651745, 'subsample': 0.6540158204772516, 'colsample_bytree': 0.9759567838639258, 'gamma': 0.49709094135266685, 'scale_pos_weight': 1.224089534777899}. Best is trial 79 with value: 0.9172746430814172.\n",
      "[I 2025-03-14 18:32:12,637] Trial 121 finished with value: 0.9173590263479212 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.018754303314585087, 'subsample': 0.6170509820528537, 'colsample_bytree': 0.9006482339672246, 'gamma': 1.0486232483787385, 'scale_pos_weight': 1.758705370287984}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:13,686] Trial 122 finished with value: 0.914439318318724 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.01821338081192723, 'subsample': 0.6164348622540476, 'colsample_bytree': 0.9986063282806046, 'gamma': 1.1533662760512529, 'scale_pos_weight': 1.7625365885581086}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:14,806] Trial 123 finished with value: 0.910722571505449 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.02630184882285923, 'subsample': 0.6309918404123005, 'colsample_bytree': 0.9659945627906021, 'gamma': 0.3276819937256408, 'scale_pos_weight': 1.685044050967036}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:15,868] Trial 124 finished with value: 0.9157331991601616 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.02301626164130806, 'subsample': 0.6399576241066138, 'colsample_bytree': 0.981061866854152, 'gamma': 0.7771697771334283, 'scale_pos_weight': 1.8557666771686374}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:17,065] Trial 125 finished with value: 0.9139861519160671 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.020658540434009696, 'subsample': 0.6451602952563494, 'colsample_bytree': 0.9546633259253441, 'gamma': 0.6970732956943693, 'scale_pos_weight': 1.7278547823314556}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:17,868] Trial 126 finished with value: 0.9068021493212669 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.012495489594104967, 'subsample': 0.6585946348379064, 'colsample_bytree': 0.9413405539229529, 'gamma': 0.1890090002112596, 'scale_pos_weight': 1.8354401475696085}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:18,512] Trial 127 finished with value: 0.9005754943447514 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.016781917047482418, 'subsample': 0.6345284345012099, 'colsample_bytree': 0.9277296488109958, 'gamma': 1.3657704343737138, 'scale_pos_weight': 2.070052113638734}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:19,296] Trial 128 finished with value: 0.9133240851267193 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.022334924480081578, 'subsample': 0.6404034943559594, 'colsample_bytree': 0.972921933893575, 'gamma': 2.159763664235662, 'scale_pos_weight': 1.8882267628957627}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:20,526] Trial 129 finished with value: 0.9121104965574963 and parameters: {'n_estimators': 350, 'max_depth': 6, 'learning_rate': 0.023662530317856343, 'subsample': 0.6689962798164709, 'colsample_bytree': 0.9036623250952983, 'gamma': 0.4949651796296493, 'scale_pos_weight': 1.5666687464202254}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:21,332] Trial 130 finished with value: 0.9116061635842859 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.019555811571313968, 'subsample': 0.6248139666948485, 'colsample_bytree': 0.9815779599822564, 'gamma': 0.20312286935447815, 'scale_pos_weight': 1.7678052478680286}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:22,461] Trial 131 finished with value: 0.9140683971497925 and parameters: {'n_estimators': 350, 'max_depth': 6, 'learning_rate': 0.02880990028684813, 'subsample': 0.6089609544647033, 'colsample_bytree': 0.987297409543269, 'gamma': 0.8286564649483417, 'scale_pos_weight': 1.8619206804848996}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:23,571] Trial 132 finished with value: 0.9145193296423308 and parameters: {'n_estimators': 350, 'max_depth': 6, 'learning_rate': 0.02543052074108649, 'subsample': 0.6164215985081374, 'colsample_bytree': 0.9914254355015889, 'gamma': 1.0412916361230935, 'scale_pos_weight': 1.939178670820596}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:24,888] Trial 133 finished with value: 0.9143824366329285 and parameters: {'n_estimators': 350, 'max_depth': 7, 'learning_rate': 0.021517169572046545, 'subsample': 0.6286741880230143, 'colsample_bytree': 0.9621215138619674, 'gamma': 0.8080078936753161, 'scale_pos_weight': 1.8055594972713929}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:25,979] Trial 134 finished with value: 0.9107568489695517 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.026726430729879555, 'subsample': 0.6053687822687606, 'colsample_bytree': 0.9695803922756583, 'gamma': 0.6391042822815393, 'scale_pos_weight': 1.6736306854516387}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:27,079] Trial 135 finished with value: 0.9141015488197851 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.010877568318455232, 'subsample': 0.6483729043715494, 'colsample_bytree': 0.9990703703111822, 'gamma': 1.267093510158396, 'scale_pos_weight': 1.8400337747584767}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:28,145] Trial 136 finished with value: 0.9160261161606791 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.018495643711504722, 'subsample': 0.6184383741521255, 'colsample_bytree': 0.9797048574480103, 'gamma': 0.9479248848796865, 'scale_pos_weight': 1.7249143301113055}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:28,956] Trial 137 finished with value: 0.9107294594404634 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.01618209081528441, 'subsample': 0.638866266681566, 'colsample_bytree': 0.9495169808935302, 'gamma': 0.3591124554498993, 'scale_pos_weight': 1.7347431003522737}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:29,530] Trial 138 finished with value: 0.8810738588603655 and parameters: {'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.018381163987090027, 'subsample': 0.6191969715117926, 'colsample_bytree': 0.8821611530470843, 'gamma': 8.826863649241616, 'scale_pos_weight': 1.7891800497767347}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:30,779] Trial 139 finished with value: 0.9077814062383901 and parameters: {'n_estimators': 350, 'max_depth': 18, 'learning_rate': 0.020629477237897292, 'subsample': 0.6557054093854304, 'colsample_bytree': 0.9798010332009509, 'gamma': 1.5229806318593728, 'scale_pos_weight': 2.9192778032430504}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:31,560] Trial 140 finished with value: 0.913213048323005 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.02294094360176514, 'subsample': 0.632370970722856, 'colsample_bytree': 0.961370174732349, 'gamma': 1.032764325200935, 'scale_pos_weight': 1.6860041745720848}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:32,660] Trial 141 finished with value: 0.9157703616849757 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.019339097122550126, 'subsample': 0.6002373709076854, 'colsample_bytree': 0.9913256068934853, 'gamma': 0.8918753499926557, 'scale_pos_weight': 1.8889424945895228}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:33,767] Trial 142 finished with value: 0.9126353893888339 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.01918216200309834, 'subsample': 0.6011168914999426, 'colsample_bytree': 0.9933041665479084, 'gamma': 0.5836976431475103, 'scale_pos_weight': 1.9130226094393092}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:34,691] Trial 143 finished with value: 0.9036025743690391 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.017689684988530623, 'subsample': 0.9961614081358097, 'colsample_bytree': 0.9762425219162293, 'gamma': 1.789626386969748, 'scale_pos_weight': 1.974431465553713}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:35,427] Trial 144 finished with value: 0.9060112089474014 and parameters: {'n_estimators': 350, 'max_depth': 3, 'learning_rate': 0.015072339004458726, 'subsample': 0.6219212114292811, 'colsample_bytree': 0.9712499502508568, 'gamma': 1.191065018543352, 'scale_pos_weight': 1.744932338653165}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:36,370] Trial 145 finished with value: 0.9145193296423308 and parameters: {'n_estimators': 350, 'max_depth': 4, 'learning_rate': 0.02054913900163492, 'subsample': 0.6122581111323433, 'colsample_bytree': 0.9902883111145454, 'gamma': 0.1712720889158904, 'scale_pos_weight': 1.809760477594872}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:37,161] Trial 146 finished with value: 0.9128765098614664 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.024231068029543466, 'subsample': 0.6266042909455302, 'colsample_bytree': 0.9824451183910579, 'gamma': 0.9717014847529882, 'scale_pos_weight': 2.0223021758217357}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:38,288] Trial 147 finished with value: 0.9171211242122087 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.01703596196956896, 'subsample': 0.6909498961858239, 'colsample_bytree': 0.9987331260434217, 'gamma': 0.43065989110623715, 'scale_pos_weight': 1.8845637764933005}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:39,419] Trial 148 finished with value: 0.9171796394301314 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.015349295657122668, 'subsample': 0.6803723268807694, 'colsample_bytree': 0.8554299024385823, 'gamma': 0.42245292086287134, 'scale_pos_weight': 1.886567876687933}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:40,695] Trial 149 finished with value: 0.9157331991601616 and parameters: {'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.014324019566757898, 'subsample': 0.6949637536550725, 'colsample_bytree': 0.8563210813314522, 'gamma': 0.40244707080699127, 'scale_pos_weight': 1.9152673979545145}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:41,346] Trial 150 finished with value: 0.885607590345297 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.01683193254655591, 'subsample': 0.6817654623463341, 'colsample_bytree': 0.8642303660974854, 'gamma': 6.055410137690609, 'scale_pos_weight': 1.9685644501277197}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:42,685] Trial 151 finished with value: 0.9157331991601616 and parameters: {'n_estimators': 350, 'max_depth': 6, 'learning_rate': 0.015900089688726082, 'subsample': 0.7140380907554016, 'colsample_bytree': 0.8729604182960983, 'gamma': 0.7542622398256112, 'scale_pos_weight': 1.866773999413523}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:44,009] Trial 152 finished with value: 0.9140334116336024 and parameters: {'n_estimators': 350, 'max_depth': 6, 'learning_rate': 0.018673863599854266, 'subsample': 0.6650396455208245, 'colsample_bytree': 0.9990731352697793, 'gamma': 0.26400469458308157, 'scale_pos_weight': 1.8887201953841275}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:45,530] Trial 153 finished with value: 0.9140334116336024 and parameters: {'n_estimators': 350, 'max_depth': 7, 'learning_rate': 0.01350154972462122, 'subsample': 0.6813870352499255, 'colsample_bytree': 0.8198574172947717, 'gamma': 0.028158565888947495, 'scale_pos_weight': 1.836927887359565}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:46,494] Trial 154 finished with value: 0.9143824366329285 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.017338021943373482, 'subsample': 0.6907562255728866, 'colsample_bytree': 0.9775641871546572, 'gamma': 0.49418644894162905, 'scale_pos_weight': 1.930936906744521}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:46,671] Trial 155 finished with value: 0.8907616192796901 and parameters: {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.01957390690831881, 'subsample': 0.6766560486582673, 'colsample_bytree': 0.8029858835515411, 'gamma': 4.312228154071978, 'scale_pos_weight': 1.7146975273225598}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:47,938] Trial 156 finished with value: 0.9168541023932246 and parameters: {'n_estimators': 350, 'max_depth': 7, 'learning_rate': 0.02202138099674565, 'subsample': 0.7010972633250456, 'colsample_bytree': 0.999987817011606, 'gamma': 0.856188003408191, 'scale_pos_weight': 1.7848666017659818}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:49,421] Trial 157 finished with value: 0.9141190476952641 and parameters: {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.015428470543456295, 'subsample': 0.7017720638363109, 'colsample_bytree': 0.992714841423312, 'gamma': 0.966558898450029, 'scale_pos_weight': 1.775698909560383}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:50,012] Trial 158 finished with value: 0.8894600486089054 and parameters: {'n_estimators': 350, 'max_depth': 4, 'learning_rate': 0.021386842581012665, 'subsample': 0.6906882173420712, 'colsample_bytree': 0.9188978688492357, 'gamma': 5.071876414426058, 'scale_pos_weight': 1.623581388521225}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:51,019] Trial 159 finished with value: 0.9115986161235735 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.018053344818086577, 'subsample': 0.7237252787919215, 'colsample_bytree': 0.9995537012916635, 'gamma': 1.336739965170485, 'scale_pos_weight': 1.7525144228531846}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:52,517] Trial 160 finished with value: 0.9171211242122087 and parameters: {'n_estimators': 350, 'max_depth': 7, 'learning_rate': 0.014457227145873226, 'subsample': 0.7326193011287294, 'colsample_bytree': 0.9685817314429028, 'gamma': 0.39350267735651256, 'scale_pos_weight': 2.1159504148220427}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:54,029] Trial 161 finished with value: 0.9157331991601616 and parameters: {'n_estimators': 350, 'max_depth': 7, 'learning_rate': 0.014202950368089322, 'subsample': 0.7327248589736066, 'colsample_bytree': 0.9665444264601577, 'gamma': 0.3997547348776655, 'scale_pos_weight': 2.2121502099520796}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:55,502] Trial 162 finished with value: 0.913051393266677 and parameters: {'n_estimators': 350, 'max_depth': 7, 'learning_rate': 0.012599733623589114, 'subsample': 0.7141038233622872, 'colsample_bytree': 0.8378064060607334, 'gamma': 0.6570107018298532, 'scale_pos_weight': 2.110768841542738}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:56,840] Trial 163 finished with value: 0.9126826491063692 and parameters: {'n_estimators': 350, 'max_depth': 6, 'learning_rate': 0.011574337082845311, 'subsample': 0.7031262302919491, 'colsample_bytree': 0.9864640298442268, 'gamma': 0.20565852845607288, 'scale_pos_weight': 2.281331995117726}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:58,183] Trial 164 finished with value: 0.9159711012958741 and parameters: {'n_estimators': 350, 'max_depth': 8, 'learning_rate': 0.017235580109393286, 'subsample': 0.7357478995244223, 'colsample_bytree': 0.9574129184445306, 'gamma': 1.1355443903907565, 'scale_pos_weight': 2.0187829481923676}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:32:59,653] Trial 165 finished with value: 0.9143824366329285 and parameters: {'n_estimators': 350, 'max_depth': 8, 'learning_rate': 0.013115111167704923, 'subsample': 0.7383333411056212, 'colsample_bytree': 0.9340166989301416, 'gamma': 1.1280358943163138, 'scale_pos_weight': 2.0639588553570296}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:33:01,080] Trial 166 finished with value: 0.9138203812767767 and parameters: {'n_estimators': 350, 'max_depth': 7, 'learning_rate': 0.016834860056981565, 'subsample': 0.7447761861212069, 'colsample_bytree': 0.9579126516564234, 'gamma': 0.5442303817369742, 'scale_pos_weight': 1.8226854044805243}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:33:02,784] Trial 167 finished with value: 0.9157331991601616 and parameters: {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.014904488305973584, 'subsample': 0.763710789323307, 'colsample_bytree': 0.9469712280281433, 'gamma': 0.7596333958725593, 'scale_pos_weight': 2.0202958659511916}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:33:04,289] Trial 168 finished with value: 0.9155033398659913 and parameters: {'n_estimators': 350, 'max_depth': 7, 'learning_rate': 0.01591306112791728, 'subsample': 0.7314632412395565, 'colsample_bytree': 0.8252431680025235, 'gamma': 0.014170319294703526, 'scale_pos_weight': 2.1238584015212494}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:33:05,306] Trial 169 finished with value: 0.9130715669804278 and parameters: {'n_estimators': 350, 'max_depth': 6, 'learning_rate': 0.021643417984939413, 'subsample': 0.7165564000035698, 'colsample_bytree': 0.9709292568961325, 'gamma': 1.4345858709353472, 'scale_pos_weight': 1.9918850886261543}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:33:06,866] Trial 170 finished with value: 0.9087455741584165 and parameters: {'n_estimators': 350, 'max_depth': 8, 'learning_rate': 0.01701378406930671, 'subsample': 0.7086739025845004, 'colsample_bytree': 0.7811870325830749, 'gamma': 0.46059930452438347, 'scale_pos_weight': 1.6664929288400807}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:33:07,944] Trial 171 finished with value: 0.9156592388213621 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.020165322812042134, 'subsample': 0.6986774290621284, 'colsample_bytree': 0.9928218956385405, 'gamma': 0.9151414560295041, 'scale_pos_weight': 1.9428418830885374}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:33:09,232] Trial 172 finished with value: 0.9126826491063692 and parameters: {'n_estimators': 350, 'max_depth': 14, 'learning_rate': 0.018937289075119584, 'subsample': 0.7510235508783356, 'colsample_bytree': 0.97698613720948, 'gamma': 1.1825398721823361, 'scale_pos_weight': 1.8956581715625878}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:33:09,831] Trial 173 finished with value: 0.8826303314604369 and parameters: {'n_estimators': 350, 'max_depth': 4, 'learning_rate': 0.018228162900470874, 'subsample': 0.6862078062250243, 'colsample_bytree': 0.985273041414632, 'gamma': 6.7611370629205485, 'scale_pos_weight': 2.193312509523741}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:33:10,985] Trial 174 finished with value: 0.9106922760417205 and parameters: {'n_estimators': 350, 'max_depth': 9, 'learning_rate': 0.02234866508024402, 'subsample': 0.9598212028148789, 'colsample_bytree': 0.89042697238128, 'gamma': 0.9409624211141849, 'scale_pos_weight': 1.786178906809706}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:33:12,079] Trial 175 finished with value: 0.9117936137529619 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.01984291676967604, 'subsample': 0.6168968242504483, 'colsample_bytree': 0.9644628907280735, 'gamma': 0.6733025975759932, 'scale_pos_weight': 1.36272869140733}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:33:13,560] Trial 176 finished with value: 0.9171659648677366 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.016383093984142522, 'subsample': 0.724885788943417, 'colsample_bytree': 0.8550535385789672, 'gamma': 0.25586167603836285, 'scale_pos_weight': 1.8947534986111676}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:33:15,223] Trial 177 finished with value: 0.9171211242122087 and parameters: {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.014392838045618082, 'subsample': 0.724971026799348, 'colsample_bytree': 0.8563023069807263, 'gamma': 0.30260933426341224, 'scale_pos_weight': 1.7182543318413217}. Best is trial 121 with value: 0.9173590263479212.\n",
      "[I 2025-03-14 18:33:17,396] Trial 178 finished with value: 0.9186407805157805 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.014299184752870184, 'subsample': 0.7215782109002993, 'colsample_bytree': 0.8703816901332377, 'gamma': 0.25422667935408994, 'scale_pos_weight': 1.7312990022123156}. Best is trial 178 with value: 0.9186407805157805.\n",
      "[I 2025-03-14 18:33:19,618] Trial 179 finished with value: 0.9151271182662404 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.013048263033702918, 'subsample': 0.722566400310453, 'colsample_bytree': 0.8646241281685535, 'gamma': 0.2228597478800004, 'scale_pos_weight': 1.6988548783928334}. Best is trial 178 with value: 0.9186407805157805.\n",
      "[I 2025-03-14 18:33:21,871] Trial 180 finished with value: 0.9201745593267127 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.014386512981372567, 'subsample': 0.7378617734765193, 'colsample_bytree': 0.8551845759876383, 'gamma': 0.2981980007299261, 'scale_pos_weight': 1.7219890457294176}. Best is trial 180 with value: 0.9201745593267127.\n",
      "[I 2025-03-14 18:33:24,144] Trial 181 finished with value: 0.9199817296429892 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.013709322936868634, 'subsample': 0.7306221485845222, 'colsample_bytree': 0.8548666445385239, 'gamma': 0.32363433858588536, 'scale_pos_weight': 1.7189765248383533}. Best is trial 180 with value: 0.9201745593267127.\n",
      "[I 2025-03-14 18:33:26,539] Trial 182 finished with value: 0.9216493749747567 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.014133315170299162, 'subsample': 0.7354039464320217, 'colsample_bytree': 0.8567773051192157, 'gamma': 0.29414810394354374, 'scale_pos_weight': 1.7299305622959376}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:33:28,976] Trial 183 finished with value: 0.9201745593267127 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.014319306919226256, 'subsample': 0.7262425557641232, 'colsample_bytree': 0.8581785233101318, 'gamma': 0.21589206698147512, 'scale_pos_weight': 1.7260090265814145}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:33:31,401] Trial 184 finished with value: 0.9216493749747567 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.014511892099124995, 'subsample': 0.7252512814321241, 'colsample_bytree': 0.8556014980109571, 'gamma': 0.23013229246569172, 'scale_pos_weight': 1.6620042921380938}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:33:33,848] Trial 185 finished with value: 0.9214445618667177 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.014069978761564414, 'subsample': 0.7277374440885073, 'colsample_bytree': 0.8536123884745253, 'gamma': 0.18182463723894277, 'scale_pos_weight': 1.6455943249106415}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:33:36,280] Trial 186 finished with value: 0.9214445618667177 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.01425126994772987, 'subsample': 0.7270691101258259, 'colsample_bytree': 0.8552033624862562, 'gamma': 0.17163084291305947, 'scale_pos_weight': 1.6456518191805112}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:33:38,707] Trial 187 finished with value: 0.918280142341402 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.013801737911069407, 'subsample': 0.7259252790931037, 'colsample_bytree': 0.8547257698014471, 'gamma': 0.25724574926335697, 'scale_pos_weight': 1.5932524552999712}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:33:41,145] Trial 188 finished with value: 0.9199023277306623 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.013869073547664992, 'subsample': 0.7438853579012942, 'colsample_bytree': 0.8594714588475032, 'gamma': 0.2066010521321666, 'scale_pos_weight': 1.6114908093661113}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:33:43,684] Trial 189 finished with value: 0.918280142341402 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.014004148960208648, 'subsample': 0.7257371570997562, 'colsample_bytree': 0.8557423476623156, 'gamma': 0.1491509372398927, 'scale_pos_weight': 1.6043444975189078}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:33:46,323] Trial 190 finished with value: 0.9164717081710103 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.011270313442505769, 'subsample': 0.7430330152093794, 'colsample_bytree': 0.8492370330473344, 'gamma': 0.007643512718343515, 'scale_pos_weight': 1.5782193282782604}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:33:48,711] Trial 191 finished with value: 0.9200287055678278 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.01424626557667335, 'subsample': 0.723201908595601, 'colsample_bytree': 0.8575375119000801, 'gamma': 0.2466225552357602, 'scale_pos_weight': 1.613684404223094}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:33:51,108] Trial 192 finished with value: 0.9166140129919658 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.013945509406333097, 'subsample': 0.7249588733874355, 'colsample_bytree': 0.8545575272848135, 'gamma': 0.2329766927466548, 'scale_pos_weight': 1.510441076322092}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:33:53,638] Trial 193 finished with value: 0.9183271182662404 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.01304896860661672, 'subsample': 0.7567492070480497, 'colsample_bytree': 0.8585668872933766, 'gamma': 0.2777688546819788, 'scale_pos_weight': 1.604773869375755}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:33:56,122] Trial 194 finished with value: 0.9199477876731693 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.012169949458271673, 'subsample': 0.7541196578653537, 'colsample_bytree': 0.868786922829074, 'gamma': 0.12529158903597212, 'scale_pos_weight': 1.605456045886374}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:33:58,708] Trial 195 finished with value: 0.9130938921603573 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.012552659936120774, 'subsample': 0.7593647639463966, 'colsample_bytree': 0.8698950394344741, 'gamma': 0.001893897993308552, 'scale_pos_weight': 1.609462719310216}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:01,384] Trial 196 finished with value: 0.9167477876731693 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.011705601586892076, 'subsample': 0.7723162260529977, 'colsample_bytree': 0.8779213920166105, 'gamma': 0.2154876498449993, 'scale_pos_weight': 1.562966421950527}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:04,209] Trial 197 finished with value: 0.9216493749747567 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.013243289328499337, 'subsample': 0.7516656829274057, 'colsample_bytree': 0.8602483668260934, 'gamma': 0.1758454541575472, 'scale_pos_weight': 1.6407775155694668}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:06,927] Trial 198 finished with value: 0.9182187554151048 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.010808223020557178, 'subsample': 0.7516115933709515, 'colsample_bytree': 0.8440601285182208, 'gamma': 0.192493791322064, 'scale_pos_weight': 1.6448818842457993}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:09,630] Trial 199 finished with value: 0.9164616088113806 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.010293146962801737, 'subsample': 0.7483143032637978, 'colsample_bytree': 0.8433251282553672, 'gamma': 0.1684121147446379, 'scale_pos_weight': 1.6420888976140806}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:12,527] Trial 200 finished with value: 0.9216493749747567 and parameters: {'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.013185527924097457, 'subsample': 0.7559999357874257, 'colsample_bytree': 0.8580451808809628, 'gamma': 0.14294258332982876, 'scale_pos_weight': 1.6009744034898667}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:15,283] Trial 201 finished with value: 0.9182187554151048 and parameters: {'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.01327108926903646, 'subsample': 0.7544209471773011, 'colsample_bytree': 0.8619240682814078, 'gamma': 0.004916958805304822, 'scale_pos_weight': 1.6073036595368448}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:17,953] Trial 202 finished with value: 0.9182187554151048 and parameters: {'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.012107171560161339, 'subsample': 0.7569705929093349, 'colsample_bytree': 0.862978539701503, 'gamma': 0.10637128008000171, 'scale_pos_weight': 1.6002455467287915}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:20,693] Trial 203 finished with value: 0.9164616088113806 and parameters: {'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.011987978835451876, 'subsample': 0.7655478597985538, 'colsample_bytree': 0.86677067341725, 'gamma': 0.023058527056922185, 'scale_pos_weight': 1.4888974081601776}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:23,321] Trial 204 finished with value: 0.9199477876731693 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.01336230152966812, 'subsample': 0.7521223375437337, 'colsample_bytree': 0.8616364796070686, 'gamma': 0.15374712753575626, 'scale_pos_weight': 1.590110145674463}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:26,018] Trial 205 finished with value: 0.9182187554151048 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.010728591441319912, 'subsample': 0.7582604413707532, 'colsample_bytree': 0.8618589990297951, 'gamma': 0.17303483455372543, 'scale_pos_weight': 1.5921245031978957}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:28,671] Trial 206 finished with value: 0.9164616088113806 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.010732026801407784, 'subsample': 0.7567784953804761, 'colsample_bytree': 0.8613347828059548, 'gamma': 0.1397342679566443, 'scale_pos_weight': 1.5453934248840646}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:31,427] Trial 207 finished with value: 0.9152473234809427 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.013031620145278311, 'subsample': 0.7807144670224612, 'colsample_bytree': 0.8763550859439524, 'gamma': 0.00755350313971985, 'scale_pos_weight': 1.590626317188864}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:34,018] Trial 208 finished with value: 0.9165800710221459 and parameters: {'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.012182486253495734, 'subsample': 0.7533239740895913, 'colsample_bytree': 0.8861583190626081, 'gamma': 0.2223144573567879, 'scale_pos_weight': 1.4433088920643742}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:36,589] Trial 209 finished with value: 0.9199477876731693 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.013627839337478787, 'subsample': 0.7442388290352605, 'colsample_bytree': 0.8431124216111349, 'gamma': 0.20047457173997504, 'scale_pos_weight': 1.6083571501610452}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:39,087] Trial 210 finished with value: 0.9216493749747567 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.013356067967470074, 'subsample': 0.7425628128873433, 'colsample_bytree': 0.8423426379731365, 'gamma': 0.3725204960198255, 'scale_pos_weight': 1.6542415745875159}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:41,592] Trial 211 finished with value: 0.9199477876731693 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.013461394565088812, 'subsample': 0.7446942737905967, 'colsample_bytree': 0.847450929397139, 'gamma': 0.360102751715217, 'scale_pos_weight': 1.6272371918690904}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:44,026] Trial 212 finished with value: 0.9182187554151048 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.01334701006098081, 'subsample': 0.7431899818061225, 'colsample_bytree': 0.8416424712630926, 'gamma': 0.3693245044208915, 'scale_pos_weight': 1.6528858936728288}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:46,455] Trial 213 finished with value: 0.9199477876731693 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.013266760621579242, 'subsample': 0.7398600992799244, 'colsample_bytree': 0.8482027834047954, 'gamma': 0.3399695161126881, 'scale_pos_weight': 1.6491220048642463}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:48,620] Trial 214 finished with value: 0.9201745593267127 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.01422357183178683, 'subsample': 0.7385660402536481, 'colsample_bytree': 0.8474143364625036, 'gamma': 0.3659913986342067, 'scale_pos_weight': 1.6472734734792}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:50,735] Trial 215 finished with value: 0.9182007404290748 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.013917418273543418, 'subsample': 0.740049678439391, 'colsample_bytree': 0.8489723094632048, 'gamma': 0.4141280190427598, 'scale_pos_weight': 1.5456931951850166}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:52,974] Trial 216 finished with value: 0.9199477876731693 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.01456398665028192, 'subsample': 0.736163332577878, 'colsample_bytree': 0.8350404701017479, 'gamma': 0.5026737191016398, 'scale_pos_weight': 1.6695818714578268}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:55,318] Trial 217 finished with value: 0.9184747718001536 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.01276911108739748, 'subsample': 0.7371685087066165, 'colsample_bytree': 0.8377789704398741, 'gamma': 0.502697532430922, 'scale_pos_weight': 1.6530357673925036}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:57,463] Trial 218 finished with value: 0.9167277245560591 and parameters: {'n_estimators': 450, 'max_depth': 9, 'learning_rate': 0.012664259181285737, 'subsample': 0.737783340203345, 'colsample_bytree': 0.8333476159105438, 'gamma': 0.49385004463875876, 'scale_pos_weight': 1.6343353291211258}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:34:59,594] Trial 219 finished with value: 0.9199477876731693 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.014899910308062154, 'subsample': 0.7391884073465596, 'colsample_bytree': 0.8348333187926024, 'gamma': 0.5472321154726254, 'scale_pos_weight': 1.678137722277322}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:01,763] Trial 220 finished with value: 0.9185538899197837 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.014844049142406437, 'subsample': 0.7438593465664838, 'colsample_bytree': 0.8372319532740126, 'gamma': 0.5334892951299711, 'scale_pos_weight': 1.6797343677652856}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:03,920] Trial 221 finished with value: 0.9183271182662404 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.014927000201869245, 'subsample': 0.7448086912643125, 'colsample_bytree': 0.836465464964955, 'gamma': 0.5439850753600083, 'scale_pos_weight': 1.6772349682372443}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:06,229] Trial 222 finished with value: 0.9216493749747567 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.01492738084396206, 'subsample': 0.7326619231819711, 'colsample_bytree': 0.8263319494075542, 'gamma': 0.4345072622501953, 'scale_pos_weight': 1.668884451457372}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:08,538] Trial 223 finished with value: 0.9199477876731693 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.014972757816279566, 'subsample': 0.7327149242849559, 'colsample_bytree': 0.8263353359579229, 'gamma': 0.3679136563001492, 'scale_pos_weight': 1.6808041756164473}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:10,841] Trial 224 finished with value: 0.9199477876731693 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.014790326918847888, 'subsample': 0.7313483423589464, 'colsample_bytree': 0.8260096594621938, 'gamma': 0.36333971865218206, 'scale_pos_weight': 1.6903099770927694}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:13,177] Trial 225 finished with value: 0.9200287055678278 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.015358851943406202, 'subsample': 0.7364718614742425, 'colsample_bytree': 0.8267050285773078, 'gamma': 0.38442414391685736, 'scale_pos_weight': 1.6750686118639329}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:15,492] Trial 226 finished with value: 0.9200287055678278 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.015430009881025015, 'subsample': 0.7320432090362068, 'colsample_bytree': 0.8263918834225719, 'gamma': 0.38244577190176987, 'scale_pos_weight': 1.680783538829494}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:17,875] Trial 227 finished with value: 0.9200287055678278 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.015145145238668556, 'subsample': 0.7315573003904224, 'colsample_bytree': 0.8105696989879043, 'gamma': 0.4074331972645839, 'scale_pos_weight': 1.656513255829277}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:20,009] Trial 228 finished with value: 0.9137584875561704 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.015642104657474832, 'subsample': 0.7361274881519261, 'colsample_bytree': 0.8203275394237741, 'gamma': 0.5617591552002752, 'scale_pos_weight': 1.5223014272652526}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:22,556] Trial 229 finished with value: 0.9183271182662404 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.011774371664857345, 'subsample': 0.7478472935086461, 'colsample_bytree': 0.812081153010336, 'gamma': 0.3860276043188685, 'scale_pos_weight': 1.65423851488595}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:24,796] Trial 230 finished with value: 0.9184747718001536 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.013284120571581839, 'subsample': 0.7350396842228447, 'colsample_bytree': 0.8487898571049345, 'gamma': 0.591063452606448, 'scale_pos_weight': 1.6551235637812032}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:27,134] Trial 231 finished with value: 0.9170102977088271 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.01539810221272076, 'subsample': 0.7175491723170129, 'colsample_bytree': 0.829893470628412, 'gamma': 0.34894844964329375, 'scale_pos_weight': 1.6915672849422116}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:29,460] Trial 232 finished with value: 0.9165800710221459 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.014596847567847484, 'subsample': 0.7307073759948666, 'colsample_bytree': 0.846242331788233, 'gamma': 0.3815763218755538, 'scale_pos_weight': 1.5534555644868557}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:31,746] Trial 233 finished with value: 0.916908093855383 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.015601261486957884, 'subsample': 0.7302767005419851, 'colsample_bytree': 0.8195619905953023, 'gamma': 0.5139849337521852, 'scale_pos_weight': 1.6395328021754054}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:34,109] Trial 234 finished with value: 0.9182187554151048 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.013678842722310344, 'subsample': 0.7394853471579644, 'colsample_bytree': 0.8301426198289983, 'gamma': 0.024777646503002973, 'scale_pos_weight': 1.6913309293965695}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:35,033] Trial 235 finished with value: 0.8910508668276694 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.012595567335701852, 'subsample': 0.7660032141339291, 'colsample_bytree': 0.8451803013403221, 'gamma': 5.389603763944249, 'scale_pos_weight': 1.6361491980792031}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:37,438] Trial 236 finished with value: 0.9182816583237333 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.014582374092735977, 'subsample': 0.7477646752078242, 'colsample_bytree': 0.8090444886104363, 'gamma': 0.3485321604957351, 'scale_pos_weight': 1.561753961364236}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:39,575] Trial 237 finished with value: 0.9172031273925505 and parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.013687836604775207, 'subsample': 0.7156277240525661, 'colsample_bytree': 0.8244499494701323, 'gamma': 0.6512339630846822, 'scale_pos_weight': 1.7033919245740874}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:41,997] Trial 238 finished with value: 0.9200287055678278 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.015765094924990796, 'subsample': 0.733298749904645, 'colsample_bytree': 0.8493471436977849, 'gamma': 0.33202944410389607, 'scale_pos_weight': 1.6729465947280453}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:44,322] Trial 239 finished with value: 0.9216493749747567 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.015874827118985992, 'subsample': 0.7421008896166704, 'colsample_bytree': 0.8498802729132304, 'gamma': 0.16349847028894232, 'scale_pos_weight': 1.6300369429217536}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:46,733] Trial 240 finished with value: 0.9182187554151048 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.01265044290379694, 'subsample': 0.7488376932941428, 'colsample_bytree': 0.8504881688042665, 'gamma': 0.008865827082155137, 'scale_pos_weight': 1.6240427145911889}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:49,217] Trial 241 finished with value: 0.9183610602360602 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.015784867563372332, 'subsample': 0.7394430518403671, 'colsample_bytree': 0.8367662597600442, 'gamma': 0.25231077780953554, 'scale_pos_weight': 1.6553440467451737}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:51,802] Trial 242 finished with value: 0.9216493749747567 and parameters: {'n_estimators': 500, 'max_depth': 13, 'learning_rate': 0.014165901708811414, 'subsample': 0.7309533271760569, 'colsample_bytree': 0.8428766719614663, 'gamma': 0.18932378330727, 'scale_pos_weight': 1.5730155072009746}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:54,183] Trial 243 finished with value: 0.916659472934473 and parameters: {'n_estimators': 450, 'max_depth': 13, 'learning_rate': 0.013861872766024456, 'subsample': 0.7200795373904842, 'colsample_bytree': 0.8496432170766288, 'gamma': 0.1415060615374554, 'scale_pos_weight': 1.5707959752709297}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:56,584] Trial 244 finished with value: 0.9198594729344729 and parameters: {'n_estimators': 500, 'max_depth': 13, 'learning_rate': 0.016087605100964505, 'subsample': 0.7284338515029455, 'colsample_bytree': 0.8696580941195392, 'gamma': 0.3088980761775729, 'scale_pos_weight': 1.526848177711437}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:35:59,183] Trial 245 finished with value: 0.9182816583237333 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.011859428388445645, 'subsample': 0.7302517941630664, 'colsample_bytree': 0.8435990284082261, 'gamma': 0.21098447318698926, 'scale_pos_weight': 1.6252346745926063}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:36:01,623] Trial 246 finished with value: 0.9185970251459363 and parameters: {'n_estimators': 500, 'max_depth': 11, 'learning_rate': 0.013228952180009107, 'subsample': 0.7471736426764125, 'colsample_bytree': 0.8537575499500188, 'gamma': 0.43362577648570305, 'scale_pos_weight': 1.7192906543914317}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:36:04,016] Trial 247 finished with value: 0.9183610602360602 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.014233410087666563, 'subsample': 0.7181109321708524, 'colsample_bytree': 0.8413417246811106, 'gamma': 0.012721131155522009, 'scale_pos_weight': 1.5751916547674865}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:36:06,658] Trial 248 finished with value: 0.9182187554151048 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.013112054740613796, 'subsample': 0.7387865065117849, 'colsample_bytree': 0.873841604388964, 'gamma': 0.17162191327725412, 'scale_pos_weight': 1.6138537897575096}. Best is trial 182 with value: 0.9216493749747567.\n",
      "[I 2025-03-14 18:36:08,637] Trial 249 finished with value: 0.9171021182662404 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.01583503243171014, 'subsample': 0.7292378763308822, 'colsample_bytree': 0.8496539079457787, 'gamma': 0.6317299147582158, 'scale_pos_weight': 1.6639998078945057}. Best is trial 182 with value: 0.9216493749747567.\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [18:36:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.014133315170299162, 'subsample': 0.7354039464320217, 'colsample_bytree': 0.8567773051192157, 'gamma': 0.29414810394354374, 'scale_pos_weight': 1.7299305622959376}\n",
      "Model trained with accuracy: 0.9606\n",
      "Precision: 0.9500, Recall: 0.9268, F1-score: 0.9383, ROC-AUC: 0.9909\n",
      "Confusion Matrix:\n",
      "[[168   6]\n",
      " [  4  76]]\n",
      "Activity: CD, X shape: (4, 5), y shape: (4,)\n",
      "Activity CD: 4 correct, 0 incorrect\n",
      "Activity: FCF, X shape: (12, 5), y shape: (12,)\n",
      "Activity FCF: 11 correct, 1 incorrect\n",
      "Activity: FCS, X shape: (10, 5), y shape: (10,)\n",
      "Activity FCS: 7 correct, 3 incorrect\n",
      "Activity: FOB, X shape: (12, 5), y shape: (12,)\n",
      "Activity FOB: 12 correct, 0 incorrect\n",
      "Activity: FOL, X shape: (12, 5), y shape: (12,)\n",
      "Activity FOL: 12 correct, 0 incorrect\n",
      "Activity: FR, X shape: (12, 5), y shape: (12,)\n",
      "Activity FR: 10 correct, 2 incorrect\n",
      "Activity: K, X shape: (24, 5), y shape: (24,)\n",
      "Activity K: 23 correct, 1 incorrect\n",
      "Activity: KD, X shape: (2, 5), y shape: (2,)\n",
      "Activity KD: 2 correct, 0 incorrect\n",
      "Activity: KID, X shape: (4, 5), y shape: (4,)\n",
      "Activity KID: 4 correct, 0 incorrect\n",
      "Activity: LAF, X shape: (12, 5), y shape: (12,)\n",
      "Activity LAF: 10 correct, 2 incorrect\n",
      "Activity: LC, X shape: (12, 5), y shape: (12,)\n",
      "Activity LC: 12 correct, 0 incorrect\n",
      "Activity: LSF, X shape: (12, 5), y shape: (12,)\n",
      "Activity LSF: 12 correct, 0 incorrect\n",
      "Activity: MA, X shape: (9, 5), y shape: (9,)\n",
      "Activity MA: 9 correct, 0 incorrect\n",
      "Activity: PUF, X shape: (12, 5), y shape: (12,)\n",
      "Activity PUF: 12 correct, 0 incorrect\n",
      "Activity: RBS, X shape: (18, 5), y shape: (18,)\n",
      "Activity RBS: 17 correct, 1 incorrect\n",
      "Activity: S, X shape: (9, 5), y shape: (9,)\n",
      "Activity S: 9 correct, 0 incorrect\n",
      "Activity: SC, X shape: (12, 5), y shape: (12,)\n",
      "Activity SC: 12 correct, 0 incorrect\n",
      "Activity: SFB, X shape: (12, 5), y shape: (12,)\n",
      "Activity SFB: 12 correct, 0 incorrect\n",
      "Activity: SLB, X shape: (12, 5), y shape: (12,)\n",
      "Activity SLB: 12 correct, 0 incorrect\n",
      "Activity: STC, X shape: (12, 5), y shape: (12,)\n",
      "Activity STC: 12 correct, 0 incorrect\n",
      "Activity: TF, X shape: (12, 5), y shape: (12,)\n",
      "Activity TF: 12 correct, 0 incorrect\n",
      "Activity: WBS, X shape: (18, 5), y shape: (18,)\n",
      "Activity WBS: 18 correct, 0 incorrect\n",
      "\n",
      "📊 Per-Activity Results:\n",
      "                               activity Actual Fall  correct  incorrect  \\\n",
      "0                            Close Door     No Fall        4          0   \n",
      "1                 Chair - Fall to Front        Fall       11          1   \n",
      "2                  Chair - Fall to side        Fall        7          3   \n",
      "3             Fall of object (Backpack)     No Fall       12          0   \n",
      "4         Fall of object (FaszienRolle)     No Fall       12          0   \n",
      "5                         Fall Recovery     No Fall       10          2   \n",
      "6        Kneeling down then standing up     No Fall       23          1   \n",
      "7                            Knock Door     No Fall        2          0   \n",
      "8                          Kids Running     No Fall        4          0   \n",
      "9                    Lying - Awake Fall        Fall       10          2   \n",
      "10                 Laying down on couch     No Fall       12          0   \n",
      "11                  Lying - Asleep Fall        Fall       12          0   \n",
      "12  Minor Ambience (Sitting and Eating)     No Fall        9          0   \n",
      "13      Picking something up from floor     No Fall       12          0   \n",
      "14                       Rush by Sensor     No Fall       17          1   \n",
      "15                                Still     No Fall        9          0   \n",
      "16                Sitting down on chair     No Fall       12          0   \n",
      "17            Slip and Fall - Backwards        Fall       12          0   \n",
      "18                Standing Lost Balance        Fall       12          0   \n",
      "19                  Stand up from Chair     No Fall       12          0   \n",
      "20             Trip and Fall - Forwards        Fall       12          0   \n",
      "21                       Walk by Sensor     No Fall       18          0   \n",
      "\n",
      "    total  accuracy  \n",
      "0       4  1.000000  \n",
      "1      12  0.916667  \n",
      "2      10  0.700000  \n",
      "3      12  1.000000  \n",
      "4      12  1.000000  \n",
      "5      12  0.833333  \n",
      "6      24  0.958333  \n",
      "7       2  1.000000  \n",
      "8       4  1.000000  \n",
      "9      12  0.833333  \n",
      "10     12  1.000000  \n",
      "11     12  1.000000  \n",
      "12      9  1.000000  \n",
      "13     12  1.000000  \n",
      "14     18  0.944444  \n",
      "15      9  1.000000  \n",
      "16     12  1.000000  \n",
      "17     12  1.000000  \n",
      "18     12  1.000000  \n",
      "19     12  1.000000  \n",
      "20     12  1.000000  \n",
      "21     18  1.000000  \n",
      "Distance: 0, X shape: (13, 5), y shape: (13,)\n",
      "Distance 0: 13 correct, 0 incorrect\n",
      "Distance: 1, X shape: (64, 5), y shape: (64,)\n",
      "Distance 1: 62 correct, 2 incorrect\n",
      "Distance: 2, X shape: (92, 5), y shape: (92,)\n",
      "Distance 2: 87 correct, 5 incorrect\n",
      "Distance: 3, X shape: (85, 5), y shape: (85,)\n",
      "Distance 3: 82 correct, 3 incorrect\n",
      "\n",
      "📊 Per-Distance Results:\n",
      "   distance  correct  incorrect  total  accuracy\n",
      "0         0       13          0     13  1.000000\n",
      "1         1       62          2     64  0.968750\n",
      "2         2       87          5     92  0.945652\n",
      "3         3       82          3     85  0.964706\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trained_model = train_pipe(\n",
    "    model=model,\n",
    "    dataset_name=\"MPU_features.csv\",\n",
    "    save_name=\"MF_NewF_XGB_KFoldOptuna\",\n",
    "    feature_columns=[\"median\", \"max\", \"mean\", \"p2p\", \"impulse\"],\n",
    "    target_column=\"fall_binary\",\n",
    "    experiment_name=\"Classic Variants MPU\",\n",
    "    use_early_stopping=False,\n",
    "    if_optuna=True,\n",
    "    n_trials=250\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>median</td>\n",
       "      <td>0.541134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.190252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p2p</td>\n",
       "      <td>0.104618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max</td>\n",
       "      <td>0.090955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>impulse</td>\n",
       "      <td>0.073041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature  Importance\n",
       "0   median    0.541134\n",
       "2     mean    0.190252\n",
       "3      p2p    0.104618\n",
       "1      max    0.090955\n",
       "4  impulse    0.073041"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_feature_importance(model, feature_columns):\n",
    "    \"\"\"\n",
    "    Plots feature importance for tree-based models.\n",
    "\n",
    "    Args:\n",
    "        model: Trained XGBoost, RandomForest, or GradientBoosting model.\n",
    "        feature_columns: List of feature names.\n",
    "\n",
    "    Returns:\n",
    "        None (Displays feature importance plot)\n",
    "    \"\"\"\n",
    "    if hasattr(model, \"feature_importances_\"):  # Ensure model supports feature importance\n",
    "        importances = model.feature_importances_\n",
    "        feature_importance_df = pd.DataFrame({\"Feature\": feature_columns, \"Importance\": importances})\n",
    "        feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.barplot(x=\"Importance\", y=\"Feature\", data=feature_importance_df[:15])  # Top 15 features\n",
    "        plt.title(\"Feature Importance\")\n",
    "        plt.show()\n",
    "\n",
    "        return feature_importance_df\n",
    "    else:\n",
    "        raise ValueError(\"This model does not support feature importance.\")\n",
    "\n",
    "# Usage (after training a model)\n",
    "plot_feature_importance(trained_model, [\"median\", \"max\", \"mean\", \"p2p\", \"impulse\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def ensemble_predict(models_with_features, dataset_name, target_column):\n",
    "    \"\"\"\n",
    "    Loads a dataset, splits it, loads an ensemble of models (with different feature sets),\n",
    "    and predicts on the test set.\n",
    "\n",
    "    Args:\n",
    "        models_with_features: A list of tuples (model_path, feature_columns) specifying each model's file path\n",
    "                              and the corresponding feature columns used for training.\n",
    "        dataset_name: The name of the dataset CSV file.\n",
    "        target_column: The name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    # ✅ Load dataset\n",
    "    df = load_data(dataset_name)\n",
    "\n",
    "    # ✅ Ensure target column exists\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' not found in dataset.\")\n",
    "\n",
    "    # ✅ Train-test split\n",
    "    data_train, data_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    y_test = data_test[target_column].values  # Target remains the same for all models\n",
    "\n",
    "    # ✅ Load models and their feature columns\n",
    "    models = []\n",
    "    y_preds = []\n",
    "\n",
    "    for model_path, feature_columns in models_with_features:\n",
    "        model = joblib.load(model_path)  # Load model\n",
    "        models.append(model)\n",
    "\n",
    "        # ✅ Extract the correct feature set for this model\n",
    "        X_test = data_test[feature_columns].values  # Select only the features it was trained on\n",
    "\n",
    "        # ✅ Predict (check if the model has `predict_proba` for probability averaging)\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]  # Get probability of the positive class\n",
    "        else:\n",
    "            y_pred_proba = model.predict(X_test)  # Some models might not have `predict_proba`\n",
    "\n",
    "        y_preds.append(y_pred_proba)\n",
    "\n",
    "    # ✅ Ensemble predictions (Average probabilities and threshold at 0.5)\n",
    "    y_pred = np.mean(y_preds, axis=0) > 0.5\n",
    "\n",
    "    # ✅ Compute metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    # ✅ Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # ✅ Print metrics\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    # ✅ Plot confusion matrix\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=[\"No Fall\", \"Fall\"], yticklabels=[\"No Fall\", \"Fall\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9764\n",
      "Precision: 0.9615\n",
      "Recall: 0.9615\n",
      "F1 Score: 0.9615\n",
      "ROC AUC: 0.9722\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ensemble_predict(\n",
    "    models_with_features=[\n",
    "        (\"models/MF_XGB_Optuna.pkl\", [\"max\", \"min\", \"mean\", \"std\", \"median\", \"peak\", \"p2p\", \"energy\", \"rms\", \"crest\", \"shape\", \"impulse\", \"margin\"]),  \n",
    "        (\"models/MF_XGB_RD40_Optuna.pkl\", [\"median\", \"max\", \"peak\", \"mean\", \"p2p\"]),\n",
    "        (\"models/MF_XGB_RD41_Optuna.pkl\", [\"median\", \"max\", \"peak\", \"mean\", \"p2p\"])    \n",
    "    ],\n",
    "    dataset_name=\"MPU_features_pca.csv\",\n",
    "    target_column=\"fall_binary\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
