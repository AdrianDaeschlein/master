{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "\n",
    "# Data Handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "\n",
    "# Machine Learning & Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "import optuna\n",
    "\n",
    "# Model Saving & Experiment Tracking\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow ui --port 5000\n"
     ]
    }
   ],
   "source": [
    "print(\"mlflow ui --port 5000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACKING_URI = \"azureml://northeurope.api.azureml.ms/mlflow/v1.0/subscriptions/716d3e14-e009-4f92-89c9-01fa8347272a/resourceGroups/adda23ac-rg/providers/Microsoft.MachineLearningServices/workspaces/fall\"\n",
    "mlflow.set_tracking_uri(TRACKING_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    '''\n",
    "    Load data from a csv file into a pandas dataframe.\n",
    "    \n",
    "    Args:\n",
    "    file_name: The name of the csv file to load\n",
    "    \n",
    "    Returns:\n",
    "    df: A pandas dataframe containing the data from the csv file\n",
    "    '''\n",
    "    folder = \"datasets\"\n",
    "\n",
    "    df = pd.read_csv(f\"{folder}/{file_name}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratify Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_activity_split(df, target_column=\"fall_binary\", test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the dataset while ensuring 20% of each 'activity' is in the test set.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The full dataset containing 'activity' and the target variable.\n",
    "        target_column (str): The column representing the target labels.\n",
    "        test_size (float): The fraction of each activity to be in the test set.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        data_train (pd.DataFrame): Training set.\n",
    "        data_test (pd.DataFrame): Test set.\n",
    "    \"\"\"\n",
    "\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "\n",
    "    # ✅ Loop through each activity and apply train-test split\n",
    "    for activity, group in df.groupby(\"activity\"):\n",
    "        train, test = train_test_split(group, test_size=test_size, random_state=random_state, stratify=group[target_column])\n",
    "        train_list.append(train)\n",
    "        test_list.append(test)\n",
    "\n",
    "    # ✅ Concatenate results into train & test datasets\n",
    "    data_train = pd.concat(train_list).reset_index(drop=True)\n",
    "    data_test = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "    return data_train, data_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Per Activity / Distance Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_per_activity(model, test_X, test_y, feature_columns=None):\n",
    "    \"\"\"\n",
    "    Evaluates model performance per activity type and logs the results in MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model (LSTM or Tree-based).\n",
    "        test_X: Test feature data (DataFrame).\n",
    "        test_y: Test target labels (Series).\n",
    "        target_column: The name of the target column.\n",
    "        feature_columns: The feature columns used for training.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame containing classification results per activity.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ✅ Ensure X_test is a DataFrame\n",
    "    if not isinstance(test_X, pd.DataFrame):\n",
    "        test_X = pd.DataFrame(test_X, columns=feature_columns)\n",
    "\n",
    "    # ✅ Ensure y_test is a Series\n",
    "    if isinstance(test_y, pd.DataFrame):\n",
    "        test_y = test_y.squeeze()  # Convert to Series if needed\n",
    "\n",
    "    # ✅ Ensure 'activity' column exists\n",
    "    if \"activity\" not in test_X.columns:\n",
    "        raise ValueError(\"Dataset does not contain an 'activity' column.\")\n",
    "\n",
    "    is_lstm = isinstance(model, tf.keras.Model)\n",
    "    results = []\n",
    "\n",
    "    # ✅ Loop through each unique activity and evaluate model performance\n",
    "    for activity in test_X[\"activity\"].unique():\n",
    "        # Filter test data for the current activity\n",
    "        X_test_activity = test_X[test_X[\"activity\"] == activity].copy()\n",
    "\n",
    "        # Extract the actual labels\n",
    "        y_test_activity = test_y.loc[X_test_activity.index].values.flatten()  # Ensure correct shape\n",
    "\n",
    "        # ✅ Check for missing values\n",
    "        if np.isnan(y_test_activity).any():\n",
    "            print(f\"Warning: NaN values found in y_test_activity for activity {activity}!\")\n",
    "            y_test_activity = np.nan_to_num(y_test_activity, nan=0)  # Replace NaN with 0 (No Fall)\n",
    "\n",
    "        # ✅ Ensure y_test_activity is integer\n",
    "        try:\n",
    "            y_test_activity = y_test_activity.astype(int)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error converting y_test_activity to integer for activity {activity}: {e}\")\n",
    "            continue  # Skip this activity if conversion fails\n",
    "\n",
    "        # ✅ Select feature columns\n",
    "        if is_lstm:\n",
    "            feature_columns = [col for col in X_test_activity.columns if col.startswith(\"value\")]\n",
    "\n",
    "        X_test_activity = X_test_activity[feature_columns].values  # Extract feature values\n",
    "\n",
    "        print(f\"Activity: {activity}, X shape: {X_test_activity.shape}, y shape: {y_test_activity.shape}\")\n",
    "\n",
    "        # ✅ Reshape X for LSTM input\n",
    "        if is_lstm:\n",
    "            X_test_activity = X_test_activity.reshape(-1, 500, 1)\n",
    "\n",
    "        # ✅ Predict fall_binary values\n",
    "        y_pred = model.predict(X_test_activity).round().astype(int).flatten()\n",
    "\n",
    "        # ✅ Compute correct and incorrect counts\n",
    "        correct = np.sum(y_pred == y_test_activity)\n",
    "        incorrect = len(y_pred) - correct\n",
    "\n",
    "        # ✅ Determine if the first sample of the activity is a fall or not\n",
    "        actual_fall = \"Fall\" if y_test_activity[0] == 1 else \"No Fall\"\n",
    "\n",
    "        print(f\"Activity {activity}: {correct} correct, {incorrect} incorrect\")\n",
    "\n",
    "        # ✅ Store results\n",
    "        results.append({\n",
    "            \"activity\": activity,\n",
    "            \"Actual Fall\": actual_fall,  # ✅ Single column for actual fall status\n",
    "            \"correct\": correct,\n",
    "            \"incorrect\": incorrect,\n",
    "            \"total\": len(y_pred),\n",
    "            \"accuracy\": correct / len(y_pred) if len(y_pred) > 0 else 0\n",
    "        })\n",
    "\n",
    "    # ✅ Convert results into a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # ✅ Mapping dictionary from abbreviations to full names\n",
    "    activity_mapping = {\n",
    "        \"S\": \"Still\",\n",
    "        \"CD\": \"Close Door\",\n",
    "        \"KD\": \"Knock Door\",\n",
    "        \"MA\": \"Minor Ambience (Sitting and Eating)\",\n",
    "        \"FOB\": \"Fall of object (Backpack)\",\n",
    "        \"FOL\": \"Fall of object (FaszienRolle)\",\n",
    "        \"WBS\": \"Walk by Sensor\",\n",
    "        \"RBS\": \"Rush by Sensor\",\n",
    "        \"SC\": \"Sitting down on chair\",\n",
    "        \"LC\": \"Laying down on couch\",\n",
    "        \"STC\": \"Stand up from Chair\",\n",
    "        \"PUF\": \"Picking something up from floor\",\n",
    "        \"K\": \"Kneeling down then standing up\",\n",
    "        \"SLB\": \"Standing Lost Balance\",\n",
    "        \"TF\": \"Trip and Fall - Forwards\",\n",
    "        \"SFB\": \"Slip and Fall - Backwards\",\n",
    "        \"FCS\": \"Chair - Fall to side\",\n",
    "        \"FCF\": \"Chair - Fall to Front\",\n",
    "        \"LAF\": \"Lying - Awake Fall\",\n",
    "        \"LSF\": \"Lying - Asleep Fall\",\n",
    "        \"FR\": \"Fall Recovery\",\n",
    "        \"KID\": \"Kids Running\"\n",
    "    }\n",
    "\n",
    "    # ✅ Function to extract the relevant part before the first '_'\n",
    "    def get_activity_name(code):\n",
    "        key = code.split('_')[0]  # Extract first part of activity code\n",
    "        return activity_mapping.get(key, code)  # Replace with full name if exists\n",
    "\n",
    "    # ✅ Apply the mapping to the results dataframe\n",
    "    results_df[\"activity\"] = results_df[\"activity\"].apply(get_activity_name)\n",
    "\n",
    "    # ✅ Save the results as a CSV file\n",
    "    results_path = \"activity_results.csv\"\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "\n",
    "    # ✅ Log results in MLflow\n",
    "    mlflow.log_artifact(results_path)\n",
    "\n",
    "    print(\"\\n📊 Per-Activity Results:\")\n",
    "    print(results_df)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_per_distance(model, test_X, test_y, feature_columns=None):\n",
    "    \"\"\"\n",
    "    Evaluates model performance per distance type and logs the results in MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model (LSTM or Tree-based).\n",
    "        test_X: Test feature data (DataFrame).\n",
    "        test_y: Test target labels (Series).\n",
    "        feature_columns: The feature columns used for training.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame containing classification results per distance.\n",
    "    \"\"\"\n",
    "\n",
    "    X_test = test_X.copy()\n",
    "    y_test = test_y.copy()\n",
    "\n",
    "    # ✅ Ensure X_test is a DataFrame\n",
    "    if not isinstance(X_test, pd.DataFrame):\n",
    "        X_test = pd.DataFrame(X_test, columns=feature_columns)\n",
    "\n",
    "    # ✅ Ensure y_test is a Series\n",
    "    if isinstance(y_test, pd.DataFrame):\n",
    "        y_test = y_test.squeeze()  # Convert to Series if needed\n",
    "\n",
    "    is_lstm = isinstance(model, tf.keras.Model)\n",
    "\n",
    "    # ✅ Ensure 'distance_m' column exists\n",
    "    if \"distance_m\" not in X_test.columns:\n",
    "        raise ValueError(\"Dataset does not contain a 'distance_m' column.\")\n",
    "\n",
    "    # ✅ Get unique distances and setup subplots dynamically\n",
    "    unique_distances = sorted(X_test[\"distance_m\"].unique())\n",
    "    fig, axes = plt.subplots(len(unique_distances), 1, figsize=(6, 4 * len(unique_distances))) \n",
    "\n",
    "    results = []\n",
    "    confusion_matrices = {}\n",
    "\n",
    "    # ✅ Loop through each unique distance and evaluate model performance\n",
    "    for i, distance in enumerate(unique_distances):\n",
    "        X_test_distance = X_test[X_test[\"distance_m\"] == distance].copy()\n",
    "        y_test_distance = y_test.loc[X_test_distance.index].values.flatten()  # Ensure correct shape\n",
    "\n",
    "        # ✅ Select feature columns\n",
    "        if is_lstm:\n",
    "            feature_columns = [col for col in X_test_distance.columns if col.startswith(\"value\")]\n",
    "\n",
    "        X_test_distance = X_test_distance[feature_columns].values  # Extract feature values\n",
    "\n",
    "        print(f\"Distance: {distance}, X shape: {X_test_distance.shape}, y shape: {y_test_distance.shape}\")\n",
    "\n",
    "        # ✅ Reshape X for LSTM input\n",
    "        if is_lstm:\n",
    "            X_test_distance = X_test_distance.reshape(-1, 500, 1)\n",
    "\n",
    "        # ✅ Predict fall_binary values\n",
    "        y_pred = model.predict(X_test_distance).round().astype(int).flatten()\n",
    "\n",
    "        # ✅ Compute correct and incorrect counts\n",
    "        correct = np.sum(y_pred == y_test_distance)\n",
    "        incorrect = len(y_pred) - correct\n",
    "\n",
    "        # ✅ Compute confusion matrix, ensuring both classes appear\n",
    "        cm = confusion_matrix(y_test_distance, y_pred, labels=[1, 0])\n",
    "\n",
    "        # ✅ Ensure confusion matrix always has shape (2,2)\n",
    "        if cm.shape == (1, 1):  \n",
    "            cm_fixed = np.array([[cm[0, 0], 0], [0, 0]])  \n",
    "        elif cm.shape == (1, 2):  \n",
    "            cm_fixed = np.vstack([cm, [0, 0]])  \n",
    "        elif cm.shape == (2, 1):  \n",
    "            cm_fixed = np.hstack([cm, [[0], [0]]])  \n",
    "        else:\n",
    "            cm_fixed = cm  \n",
    "\n",
    "        # ✅ Correct confusion matrix order:\n",
    "        # TP | FN\n",
    "        # FP | TN\n",
    "        cm_corrected = np.array([\n",
    "            [cm_fixed[0, 0], cm_fixed[1, 0]],  # True Positives, False Negatives\n",
    "            [cm_fixed[0, 1], cm_fixed[1, 1]]   # False Positives, True Negatives\n",
    "        ])\n",
    "\n",
    "        confusion_matrices[distance] = cm_corrected\n",
    "\n",
    "        # ✅ Plot confusion matrix with **correct** labels\n",
    "        sns.heatmap(cm_corrected, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=[\"Actual Fall\", \"Actual No Fall\"], \n",
    "                    yticklabels=[\"Predicted Fall\", \"Predicted No Fall\"],\n",
    "                    ax=axes[i] if len(unique_distances) > 1 else axes)\n",
    "        axes[i].set_title(f\"Confusion Matrix - Distance {distance}\")\n",
    "        axes[i].set_xlabel(\" \")\n",
    "        axes[i].set_ylabel(\" \")\n",
    "\n",
    "        print(f\"Distance {distance}: {correct} correct, {incorrect} incorrect\")\n",
    "\n",
    "        # ✅ Store results\n",
    "        results.append({\n",
    "            \"distance\": distance,\n",
    "            \"correct\": correct,\n",
    "            \"incorrect\": incorrect,\n",
    "            \"total\": len(y_pred),\n",
    "            \"accuracy\": correct / len(y_pred) if len(y_pred) > 0 else 0\n",
    "        })\n",
    "\n",
    "    # ✅ Save and log confusion matrix plot\n",
    "    confusion_matrix_path = \"confusion_matrices_distance.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(confusion_matrix_path)\n",
    "    plt.close()\n",
    "\n",
    "    # ✅ Convert results into a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # ✅ Save results as CSV\n",
    "    results_path = \"distance_results.csv\"\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "\n",
    "    # ✅ Log results in MLflow\n",
    "    mlflow.log_artifact(results_path)\n",
    "    mlflow.log_artifact(confusion_matrix_path)\n",
    "\n",
    "    print(\"\\n📊 Per-Distance Results:\")\n",
    "    print(results_df)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classical Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, model_class, X_train, y_train, augment_data=None):\n",
    "    \"\"\"\n",
    "    Defines the Optuna optimization objective with K-Fold Cross-Validation.\n",
    "    \n",
    "    Args:\n",
    "        trial: Optuna trial object.\n",
    "        model_class: The model class (e.g., XGBClassifier, RandomForestClassifier, GradientBoostingClassifier, SVC).\n",
    "        X_train, y_train: Training data (without separate test split).\n",
    "\n",
    "    Returns:\n",
    "        The average F1-score across all folds.\n",
    "    \"\"\"\n",
    "\n",
    "    # Suggest hyperparameters based on model type\n",
    "    if model_class == XGBClassifier:\n",
    "        num_no_falls = sum(y_train == 0)\n",
    "        num_falls = sum(y_train == 1)\n",
    "        default_scale_pos_weight = num_no_falls / num_falls\n",
    "\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0, 10),\n",
    "            \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", default_scale_pos_weight * 0.5, default_scale_pos_weight * 1.5)\n",
    "        }\n",
    "        model = XGBClassifier(**params, objective=\"binary:logistic\", random_state=42)\n",
    "\n",
    "    elif model_class == RandomForestClassifier:\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        }\n",
    "        model = RandomForestClassifier(**params, random_state=42)\n",
    "\n",
    "    elif model_class == GradientBoostingClassifier:\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        }\n",
    "        model = GradientBoostingClassifier(**params, random_state=42)\n",
    "\n",
    "    elif model_class == SVC:\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.1, 100, log=True),\n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"]),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0.001, 10, log=True),\n",
    "        }\n",
    "        model = SVC(**params, probability=True, random_state=42)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model class: {model_class.__name__}\")\n",
    "\n",
    "    # K-Fold Cross-Validation (Stratified to preserve class balance)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    f1_scores = []\n",
    "\n",
    "    ## Loop through each fold\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]  \n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # ✅ Apply augmentation\n",
    "        if augment_data == \"ADASYN\":\n",
    "            adasyn = ADASYN()\n",
    "            X_fold_train, y_fold_train = adasyn.fit_resample(X_fold_train, y_fold_train)\n",
    "\n",
    "        elif augment_data == \"SMOTE\":\n",
    "            smote = SMOTE()\n",
    "            X_fold_train, y_fold_train = smote.fit_resample(X_fold_train, y_fold_train)\n",
    "\n",
    "        ## Train and evaluate the model\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "        y_pred = model.predict(X_fold_val)\n",
    "        f1_scores.append(f1_score(y_fold_val, y_pred))\n",
    "\n",
    "    ## Return average F1-score across folds\n",
    "    return np.mean(f1_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_log_classical_model(\n",
    "    model, \n",
    "    X_train, X_test, y_train, y_test, X_test_full,\n",
    "    save_name=\"classification_model\", \n",
    "    experiment_name=\"classical_models_experiment\",\n",
    "    target_column=\"fall_binary\",\n",
    "    feature_columns=None,\n",
    "    if_optuna=True,\n",
    "    n_trials=250,  # Number of hyperparameter tuning trials\n",
    "    dataset_name=\"fall_data.csv\",\n",
    "    augment_data=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains a classical ML model (RandomForest, XGBoost, GradientBoosting, or SVM) with optional hyperparameter tuning\n",
    "    and logs everything to MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: A classical ML model (RandomForest, XGBoost, GradientBoosting, or SVM).\n",
    "        X_train, X_test, y_train, y_test: Pre-split training and testing datasets.\n",
    "        save_name: Name to save the trained model.\n",
    "        experiment_name: Name of the MLflow experiment.\n",
    "        n_trials: Number of hyperparameter tuning trials.\n",
    "\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Start MLflow experiment\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        # Identify model class\n",
    "        model_class = type(model)\n",
    "\n",
    "        if if_optuna:\n",
    "            # ✅ Perform hyperparameter optimization\n",
    "            study = optuna.create_study(direction=\"maximize\")\n",
    "            study.optimize(lambda trial: objective(trial, model_class, X_train, y_train, augment_data=augment_data), n_trials=n_trials)\n",
    "        \n",
    "            best_params = study.best_params\n",
    "            print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "            # ✅ Train final model with best params\n",
    "            if model_class == XGBClassifier:\n",
    "                best_model = XGBClassifier(**best_params, objective=\"binary:logistic\", use_label_encoder=False)\n",
    "            elif model_class.__name__ == \"GradientBoostingClassifier\":\n",
    "                best_model = model_class(**best_params, random_state=42)\n",
    "            elif model_class.__name__ == \"RandomForestClassifier\":\n",
    "                best_model = model_class(**best_params, random_state=42)\n",
    "            elif model_class == SVC:\n",
    "                best_model = SVC(**best_params, probability=True, random_state=42)  # ✅ Enable probability for ROC AUC\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported model class: {model_class.__name__}\")\n",
    "        else:\n",
    "            best_model = model\n",
    "\n",
    "        if augment_data == \"ADASYN\":\n",
    "            # Count of Fall labels in training data\n",
    "            num_falls = y_train.sum()\n",
    "            num_no_falls = len(y_train) - num_falls\n",
    "\n",
    "            adasyn = ADASYN()\n",
    "            X_train, y_train = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "            # Count of Fall labels in augmented training data\n",
    "            num_falls_augmented = y_train.sum()\n",
    "            num_no_falls_augmented = len(y_train) - num_falls_augmented\n",
    "            \n",
    "            print(f\"ADASYN: Original Fall count: {num_falls}, Augmented Fall count: {num_falls_augmented}\")\n",
    "            print(f\"ADASYN: Original No Fall count: {num_no_falls}, Augmented No Fall count: {num_no_falls_augmented}\")\n",
    "\n",
    "            mlflow.log_param(\"ADASYN_Original_Falls\", num_falls)\n",
    "            mlflow.log_param(\"ADASYN_Augmented_Falls\", num_falls_augmented)\n",
    "\n",
    "        elif augment_data == \"SMOTE\":\n",
    "            # Count of Fall labels in training data\n",
    "            num_falls = y_train.sum()\n",
    "            num_no_falls = len(y_train) - num_falls\n",
    "\n",
    "            smote = SMOTE()\n",
    "            X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "            # Count of Fall labels in augmented training data\n",
    "            num_falls_augmented = y_train.sum()\n",
    "            num_no_falls_augmented = len(y_train) - num_falls_augmented\n",
    "\n",
    "            print(f\"SMOTE: Original Fall count: {num_falls}, Augmented Fall count: {num_falls_augmented}\")\n",
    "            print(f\"SMOTE: Original No Fall count: {num_no_falls}, Augmented No Fall count: {num_no_falls_augmented}\")\n",
    "\n",
    "            mlflow.log_param(\"SMOTE_Original_Falls\", num_falls)\n",
    "            mlflow.log_param(\"SMOTE_Augmented_Falls\", num_falls_augmented)\n",
    "\n",
    "        best_model.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "        # SVM needs probability predictions for AUC\n",
    "        if hasattr(best_model, \"predict_proba\"):\n",
    "            roc_auc = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "        # ✅ Log model parameters\n",
    "        mlflow.log_param(\"model_type\", best_model.__class__.__name__)\n",
    "        if if_optuna:\n",
    "            for param, value in best_params.items():\n",
    "                mlflow.log_param(param, value)\n",
    "        mlflow.log_param(\"num_features\", X_train.shape[1])\n",
    "\n",
    "        # Log features used for training as list\n",
    "        if feature_columns is not None:\n",
    "            mlflow.log_param(\"features\", feature_columns)\n",
    "        \n",
    "        # Log target column\n",
    "        mlflow.log_param(\"target_column\", target_column)\n",
    "        \n",
    "        mlflow.log_param(\"dataset\", dataset_name)\n",
    "            \n",
    "        # ✅ Log metrics\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "        # ✅ Save best model\n",
    "        models_folder = \"models\"\n",
    "        if not os.path.exists(models_folder):\n",
    "            os.makedirs(models_folder)\n",
    "        save_path = os.path.join(models_folder, f\"{save_name}.pkl\")\n",
    "        joblib.dump(best_model, save_path)\n",
    "        mlflow.log_artifact(save_path)\n",
    "\n",
    "        # Generate and save confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        conf_matrix = np.array([\n",
    "            [conf_matrix[0, 0], conf_matrix[1, 0]],  # True Positives, False Positives\n",
    "            [conf_matrix[0, 1], conf_matrix[1, 1]]   # False Negatives, True Negatives\n",
    "        ])\n",
    "\n",
    "        # Flip the order of labels for visualization\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(\n",
    "            conf_matrix[::-1, ::-1],  # Reverse rows and keep columns the same\n",
    "            annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Actual Fall\", \"Actual No Fall\"], \n",
    "            yticklabels=[\"Predicted Fall\", \"Predicted No Fall\"],\n",
    "        )\n",
    "        plt.xlabel(\" \")\n",
    "        plt.ylabel(\" \")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        conf_matrix_path = \"confusion_matrix.png\"\n",
    "        plt.savefig(conf_matrix_path)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(conf_matrix_path)\n",
    "\n",
    "        print(f\"Model trained with accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "        # ✅ After training and evaluation, call the per-activity evaluation\n",
    "        evaluate_per_activity(best_model, X_test_full, y_test, feature_columns)\n",
    "\n",
    "        # ✅ After training and evaluation, call the per-distance evaluation\n",
    "        evaluate_per_distance(best_model, X_test_full, y_test, feature_columns)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipe(\n",
    "    model, \n",
    "    dataset_name, \n",
    "    save_name=\"fall_model\", \n",
    "    feature_columns=None, \n",
    "    target_column=\"fall_binary\", \n",
    "    experiment_name=\"default_experiment\",\n",
    "    use_early_stopping=True,\n",
    "    if_optuna=True,\n",
    "    n_trials=250,\n",
    "    augment_data=None\n",
    "):\n",
    "    \"\"\"\n",
    "    General training pipeline for both classical models (XGBoost, RF, SVM) and deep learning models.\n",
    "\n",
    "    Args:\n",
    "        model: The initialized model (LSTM, RNN, RF, XGB, etc.).\n",
    "        dataset_name: The dataset CSV file.\n",
    "        save_name: Name to save the trained model.\n",
    "        feature_columns: List of feature column names.\n",
    "        target_column: The name of the target column.\n",
    "        experiment_name: MLflow experiment name.\n",
    "        use_early_stopping: Whether to use early stopping (for neural networks).\n",
    "        if_optuna: Whether to perform hyperparameter tuning (for tree-based models).\n",
    "\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    # ✅ Prevent overwriting existing models unless explicitly handled\n",
    "    if os.path.exists(f\"models/{save_name}.pkl\") or os.path.exists(f\"models/{save_name}.keras\"):\n",
    "        raise ValueError(f\"Model name '{save_name}' already exists. Choose a new name or delete the existing model.\")\n",
    "\n",
    "    # ✅ Load dataset\n",
    "    df = load_data(dataset_name)\n",
    "\n",
    "    # ✅ Auto-detect feature columns if not explicitly provided\n",
    "    value_columns = [col for col in df.columns if col.startswith(\"value\")]\n",
    "    if value_columns:\n",
    "        feature_columns = value_columns  \n",
    "    elif feature_columns is None:\n",
    "        raise ValueError(\"Feature columns must be specified.\")\n",
    "\n",
    "    # ✅ Ensure target column exists\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' not found in dataset.\")\n",
    "\n",
    "    data_train, data_test = stratified_activity_split(df, target_column=target_column, test_size=0.2, random_state=42)\n",
    "    print(f\"Train shape: {data_train.shape}, Test shape: {data_test.shape}\")\n",
    "\n",
    "    # ✅ Keep full test data (including metadata like 'activity' or 'distance_m')\n",
    "    X_test_full = data_test.copy()  \n",
    "\n",
    "    # ✅ Keep `X_train`, `X_test` as DataFrames & `y_train`, `y_test` as Series\n",
    "    X_train = data_train[feature_columns]  \n",
    "    X_test = data_test[feature_columns]    \n",
    "    y_train = data_train[target_column]  \n",
    "    y_test = data_test[target_column]    \n",
    "\n",
    "    # ✅ Check model type\n",
    "    is_tree = isinstance(model, (XGBClassifier, RandomForestClassifier, GradientBoostingClassifier))\n",
    "    is_svm = isinstance(model, SVC)\n",
    "\n",
    "    if is_svm:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        X_test_full[feature_columns] = scaler.transform(X_test_full[feature_columns])\n",
    "\n",
    "        # ✅ Convert X_train back to DataFrame\n",
    "        X_train = pd.DataFrame(X_train, columns=feature_columns, index=data_train.index)\n",
    "        X_test = pd.DataFrame(X_test, columns=feature_columns, index=data_test.index)\n",
    "        X_test_full[feature_columns] = pd.DataFrame(X_test_full[feature_columns], columns=feature_columns, index=data_test.index)\n",
    "\n",
    "    # ✅ Train tree-based models with optional Optuna hyperparameter tuning\n",
    "    if is_tree or is_svm:\n",
    "        model = train_and_log_classical_model(\n",
    "            model, X_train, X_test, y_train, y_test, X_test_full,\n",
    "            save_name=save_name,\n",
    "            experiment_name=experiment_name,\n",
    "            target_column=target_column,\n",
    "            feature_columns=feature_columns,\n",
    "            if_optuna=if_optuna,\n",
    "            n_trials=n_trials,\n",
    "            dataset_name=dataset_name,\n",
    "            augment_data=augment_data\n",
    "        )\n",
    "    \n",
    "    # Delete the files activity_results.csv and distance_results.csv\n",
    "    os.remove(\"activity_results.csv\")\n",
    "    os.remove(\"distance_results.csv\")\n",
    "    os.remove(\"confusion_matrices_distance.png\")\n",
    "    os.remove(\"confusion_matrix.png\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mlflow.tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "def train_model(\n",
    "    model, \n",
    "    dataset_name, \n",
    "    save_name=\"lstm_fall_model\", \n",
    "    feature_columns=None, \n",
    "    target_column=\"fall_binary\", \n",
    "    experiment_name=\"default_experiment\",\n",
    "    use_early_stopping=True  # ✅ Option to enable/disable early stopping\n",
    "):\n",
    "    \"\"\"\n",
    "    Loads the dataset, reshapes it for RNN, trains the model, and logs everything to MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: The RNN model (already defined).\n",
    "        dataset_name: The name of the dataset CSV file.\n",
    "        save_name: Name to save the trained model.\n",
    "        feature_columns: List of feature column names (overwritten if 'value' columns exist).\n",
    "        target_column: The name of the target column.\n",
    "        experiment_name: Name of the MLflow experiment.\n",
    "        use_early_stopping: Whether to enable early stopping based on validation loss.\n",
    "\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load dataset\n",
    "    df = load_data(dataset_name)\n",
    "\n",
    "    # Auto-detect feature columns if they start with \"value\"\n",
    "    value_columns = [col for col in df.columns if col.startswith(\"value\")]\n",
    "    if value_columns:\n",
    "        feature_columns = value_columns  # Override feature selection\n",
    "    elif feature_columns is None:\n",
    "        raise ValueError(\"Feature columns must be specified if no 'value' columns exist.\")\n",
    "\n",
    "    # Ensure target column exists\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' not found in dataset.\")\n",
    "\n",
    "    # Train-test split but keep the full dataset for evaluation\n",
    "    data_train, data_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    print(f\"Train shape: {data_train.shape}, Test shape: {data_test.shape}\")\n",
    "\n",
    "    X_train = data_train[feature_columns].values\n",
    "    X_test = data_test[feature_columns].values\n",
    "\n",
    "    y_train = data_train[target_column].values\n",
    "    y_test = data_test[target_column].values\n",
    "    \n",
    "    X_test_full = X_test.copy()  # Keep a copy of the test data for evaluation\n",
    "    y_test_full = y_test.copy()\n",
    "\n",
    "    X_train = X_train[feature_columns].values\n",
    "    X_test = X_test[feature_columns].values\n",
    "\n",
    "    # Reshape X: (num_samples, timesteps=500, num_features)\n",
    "    if value_columns:\n",
    "        num_features = len(feature_columns) // 500  # Calculate how many features per timestep\n",
    "        X_test = X_test.reshape(-1, 500, num_features)\n",
    "        X_train = X_train.reshape(-1, 500, num_features)\n",
    "    else:\n",
    "        num_features = len(feature_columns)\n",
    "\n",
    "    # Print shapes\n",
    "    print(f\"X_test_full shape: {X_test_full.shape}\")\n",
    "    print(f\"y_test_full shape: {y_test_full.shape}\")\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "    is_lstm = isinstance(model, tf.keras.Model)\n",
    "\n",
    "    if is_lstm:\n",
    "        # ✅ Set up Early Stopping (if enabled)\n",
    "        callbacks = []\n",
    "        if use_early_stopping:\n",
    "            early_stopping = EarlyStopping(\n",
    "                monitor=\"val_loss\", patience=3, restore_best_weights=True, verbose=1\n",
    "            )\n",
    "            callbacks.append(early_stopping)\n",
    "\n",
    "    # Start MLflow experiment\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        print(f\"X_train shape: {X_train.shape}\")  # Should be (num_samples, timesteps, num_features)\n",
    "        print(f\"y_train shape: {y_train.shape}\")  # Should be (num_samples,)\n",
    "\n",
    "        # ✅ Log dataset name\n",
    "        mlflow.log_param(\"dataset_name\", dataset_name)  \n",
    "\n",
    "        if is_lstm:\n",
    "            # Train the model and log history\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                validation_data=(X_test, y_test),\n",
    "                callbacks=callbacks  # ✅ Apply Early Stopping if enabled\n",
    "            )\n",
    "        else:\n",
    "            model.fit(X_train, y_train)  # No need for epochs, batch size, or callbacks\n",
    "            \n",
    "        if is_lstm:\n",
    "            # Evaluate model\n",
    "            loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        else:\n",
    "            y_pred = model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # ✅ After training and evaluation, call the per-activity evaluation\n",
    "        results_df = evaluate_per_activity(model, X_test_full, y_test_full, target_column, feature_columns)\n",
    "        \n",
    "        # ✅ After training and evaluation, call the per-distance evaluation\n",
    "        evaluate_per_distance(model, X_test_full, y_test_full, target_column, feature_columns)\n",
    "\n",
    "        # ✅ Log per-activity accuracy in MLflow\n",
    "        mlflow.log_artifact(\"activity_results.csv\")\n",
    "\n",
    "        # ✅ Log model parameters\n",
    "        mlflow.log_param(\"num_features_used\", len(feature_columns))\n",
    "        mlflow.log_param(\"model_type\", model.__class__.__name__)\n",
    "\n",
    "        if is_lstm:\n",
    "            mlflow.log_param(\"epochs\", EPOCHS)\n",
    "            mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "            mlflow.log_param(\"optimizer\", model.optimizer.__class__.__name__)\n",
    "            mlflow.log_param(\"loss_function\", model.loss)\n",
    "            mlflow.log_param(\"early_stopping\", use_early_stopping)  # ✅ Log whether early stopping was used\n",
    "            mlflow.log_metric(\"final_loss\", loss)\n",
    "\n",
    "        # ✅ Log metrics\n",
    "        mlflow.log_metric(\"final_accuracy\", accuracy)\n",
    "\n",
    "        if is_lstm:\n",
    "            # ✅ Log accuracy and loss per epoch\n",
    "            for epoch, (train_acc, val_acc, train_loss, val_loss) in enumerate(zip(history.history['accuracy'], history.history['val_accuracy'], history.history['loss'], history.history['val_loss'])):\n",
    "                mlflow.log_metric(\"train_accuracy_epoch\", train_acc, step=epoch)\n",
    "                mlflow.log_metric(\"val_accuracy_epoch\", val_acc, step=epoch)\n",
    "                mlflow.log_metric(\"train_loss_epoch\", train_loss, step=epoch)\n",
    "                mlflow.log_metric(\"val_loss_epoch\", val_loss, step=epoch)\n",
    "\n",
    "        # ✅ Ensure models folder exists\n",
    "        models_folder = \"models\"\n",
    "        if not os.path.exists(models_folder):\n",
    "            os.makedirs(models_folder)\n",
    "\n",
    "        save_path = os.path.join(models_folder, save_name)\n",
    "\n",
    "        if is_lstm:\n",
    "            model.save(save_path + \".keras\")  # ✅ Save Keras model\n",
    "            mlflow.log_artifact(save_path + \".keras\")\n",
    "        else:\n",
    "            import joblib\n",
    "            joblib.dump(model, save_path + \".pkl\")  # ✅ Save tree-based model\n",
    "            mlflow.log_artifact(save_path + \".pkl\")\n",
    "\n",
    "        # ✅ Log the saved model file as an artifact in MLflow\n",
    "        mlflow.log_artifact(save_path + \".pkl\")\n",
    "\n",
    "        # ✅ Save confusion matrix\n",
    "        y_pred = model.predict(X_test).round()\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # Compute additional metrics\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "\n",
    "        # Log additional metrics\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "        # ✅ Save and log confusion matrix\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"No Fall\", \"Fall\"], yticklabels=[\"No Fall\", \"Fall\"])\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        conf_matrix_path = \"confusion_matrix.png\"\n",
    "        plt.savefig(conf_matrix_path)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(conf_matrix_path)\n",
    "\n",
    "        print(f\"Model trained with accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "        # Delete the files activity_results.csv and distance_results.csv\n",
    "        os.remove(\"activity_results.csv\")\n",
    "        os.remove(\"distance_results.csv\")\n",
    "        os.remove(\"confusion_matrices_distance.png\")\n",
    "        os.remove(\"confusion_matrix.png\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# XGBoost Model\n",
    "# ==========================\n",
    "\n",
    "def build_xgboost_model():\n",
    "    \"\"\"\n",
    "    Builds an XGBoost model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A compiled XGBoost model.\n",
    "    \"\"\"\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.11,\n",
    "        objective=\"binary:logistic\",\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ==========================\n",
    "# Random Forest Model\n",
    "# ==========================\n",
    "\n",
    "def build_random_forest_model():\n",
    "    \"\"\"\n",
    "    Builds a Random Forest model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Random Forest model.\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ==========================\n",
    "# GBM Model\n",
    "# ==========================\n",
    "def build_gradient_boosting_model():\n",
    "    \"\"\"\n",
    "    Builds a Gradient Boosting (GBM) model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Gradient Boosting model.\n",
    "    \"\"\"\n",
    "    return GradientBoostingClassifier(\n",
    "        n_estimators=200,  # Number of boosting stages\n",
    "        learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n",
    "        max_depth=5,  # Maximum depth of the trees\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "# ==========================\n",
    "# SVM Model\n",
    "# ==========================\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def build_svm_model():\n",
    "    \"\"\"\n",
    "    Builds an SVM model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A configured SVM model.\n",
    "    \"\"\"\n",
    "    model = SVC(\n",
    "        kernel=\"rbf\",  # Radial Basis Function (RBF) kernel (default)\n",
    "        C=1.0,         # Regularization parameter\n",
    "        gamma=\"scale\",  # Kernel coefficient\n",
    "        probability=True,  # Enable probability estimates (needed for ROC AUC)\n",
    "        random_state=42\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# RNN Model\n",
    "# ==========================\n",
    "def build_rnn_model():\n",
    "    \"\"\"\n",
    "    Builds a simple RNN model using Keras.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        SimpleRNN(RNN_UNITS, input_shape=INPUT_SHAPE, return_sequences=True),\n",
    "        SimpleRNN(RNN_UNITS),\n",
    "        Dense(DENSE_UNITS, activation=\"relu\"),\n",
    "        Dropout(DROPOUT_RATE),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNCTION, metrics=METRICS)\n",
    "    return model\n",
    "\n",
    "# ==========================\n",
    "# LSTM Model\n",
    "# ==========================\n",
    "def build_lstm_model(l2_lambda=0.001, dropout_rate=0.2, clipnorm=1.0):\n",
    "    \"\"\"\n",
    "    Builds an LSTM-based model with L2 regularization, dropout, and gradient clipping.\n",
    "\n",
    "    Args:\n",
    "        l2_lambda: Strength of L2 regularization (default: 0.001).\n",
    "        dropout_rate: Dropout rate to reduce overfitting (default: 0.2).\n",
    "        clipnorm: Gradient clipping norm (default: 1.0).\n",
    "\n",
    "    Returns:\n",
    "        A compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(RNN_UNITS, input_shape=INPUT_SHAPE, return_sequences=True, \n",
    "             kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),  # Dropout after first LSTM layer\n",
    "        LSTM(RNN_UNITS, kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),  # Dropout after second LSTM layer\n",
    "        Dense(DENSE_UNITS, activation=\"relu\", kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),  # Dropout before final layer\n",
    "        Dense(1, activation=\"sigmoid\")  # Output layer for binary classification\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(clipnorm=clipnorm)\n",
    "    model.compile(optimizer=optimizer, loss=LOSS_FUNCTION, metrics=METRICS)\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Bidirectional LSTM Model (Optional)\n",
    "# ==========================\n",
    "def build_bidirectional_lstm():\n",
    "    \"\"\"\n",
    "    Builds a Bidirectional LSTM model for improved sequence learning.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(RNN_UNITS, return_sequences=True), input_shape=INPUT_SHAPE),\n",
    "        Bidirectional(LSTM(RNN_UNITS)),\n",
    "        Dense(DENSE_UNITS, activation=\"relu\"),\n",
    "        Dropout(DROPOUT_RATE),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNCTION, metrics=METRICS)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# CONFIGURABLE VARIABLES\n",
    "# ==========================\n",
    "RNN_UNITS = 128           # Number of RNN/LSTM units\n",
    "DENSE_UNITS = 64         # Number of neurons in the dense layer\n",
    "DROPOUT_RATE = 0.1      # Dropout rate for regularization\n",
    "OPTIMIZER = \"adam\"       # Optimizer: \"adam\", \"sgd\", \"rmsprop\", etc.\n",
    "LOSS_FUNCTION = \"binary_crossentropy\"  # \"binary_crossentropy\" for classification\n",
    "METRICS = [\"accuracy\"]   # Metrics to monitor\n",
    "EPOCHS = 10              # Number of training epochs\n",
    "BATCH_SIZE = 16          # Batch size for training\n",
    "INPUT_SHAPE = (500, 1)   # (Time steps, Features) - Adjust based on your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(max_depth=5, n_estimators=200, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Initialize the Model\n",
    "# ==========================\n",
    "model = build_gradient_boosting_model()  # Change this to your desired model\n",
    "# print(model.summary())  # Print model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1016, 19), Test shape: (254, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-17 08:48:49,856] A new study created in memory with name: no-name-7e860455-328c-4324-aa38-29238fe707bc\n",
      "[I 2025-03-17 08:48:52,907] Trial 0 finished with value: 0.9002329745933461 and parameters: {'n_estimators': 300, 'learning_rate': 0.06784040069358245, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.9002329745933461.\n",
      "[I 2025-03-17 08:48:54,831] Trial 1 finished with value: 0.9001816239316239 and parameters: {'n_estimators': 250, 'learning_rate': 0.021844387561788466, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.9002329745933461.\n",
      "[I 2025-03-17 08:48:57,521] Trial 2 finished with value: 0.8982976789727408 and parameters: {'n_estimators': 200, 'learning_rate': 0.2067743156774491, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.9002329745933461.\n",
      "[I 2025-03-17 08:48:58,090] Trial 3 finished with value: 0.8992497296713908 and parameters: {'n_estimators': 50, 'learning_rate': 0.016282826556443208, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.9002329745933461.\n",
      "[I 2025-03-17 08:48:59,848] Trial 4 finished with value: 0.8805615071285564 and parameters: {'n_estimators': 100, 'learning_rate': 0.033668214091763446, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.9002329745933461.\n",
      "[I 2025-03-17 08:49:06,925] Trial 5 finished with value: 0.881301108063887 and parameters: {'n_estimators': 450, 'learning_rate': 0.014772685587671966, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.9002329745933461.\n",
      "[I 2025-03-17 08:49:13,460] Trial 6 finished with value: 0.9134123911739185 and parameters: {'n_estimators': 450, 'learning_rate': 0.03197258881617446, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:49:14,399] Trial 7 finished with value: 0.9059887371193497 and parameters: {'n_estimators': 200, 'learning_rate': 0.06613077250379001, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:49:16,450] Trial 8 finished with value: 0.9020053660735549 and parameters: {'n_estimators': 150, 'learning_rate': 0.0920273754611027, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:49:17,472] Trial 9 finished with value: 0.9079233970688076 and parameters: {'n_estimators': 100, 'learning_rate': 0.18975529372550218, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:49:24,595] Trial 10 finished with value: 0.9036940957792149 and parameters: {'n_estimators': 500, 'learning_rate': 0.01026982943375293, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:49:27,318] Trial 11 finished with value: 0.892851183477384 and parameters: {'n_estimators': 350, 'learning_rate': 0.27451201307942247, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:49:31,827] Trial 12 finished with value: 0.9033626893546114 and parameters: {'n_estimators': 400, 'learning_rate': 0.13450815289869114, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:49:35,487] Trial 13 finished with value: 0.906722446915515 and parameters: {'n_estimators': 500, 'learning_rate': 0.03736461766673919, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:49:39,651] Trial 14 finished with value: 0.9019237275837144 and parameters: {'n_estimators': 350, 'learning_rate': 0.03682485137155663, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:49:40,371] Trial 15 finished with value: 0.9071026778141281 and parameters: {'n_estimators': 50, 'learning_rate': 0.1326696358840137, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:49:43,029] Trial 16 finished with value: 0.9012243398392652 and parameters: {'n_estimators': 250, 'learning_rate': 0.025178025702094937, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:49:44,864] Trial 17 finished with value: 0.9094549262370979 and parameters: {'n_estimators': 400, 'learning_rate': 0.04771265009110565, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:49:46,725] Trial 18 finished with value: 0.9056158395920166 and parameters: {'n_estimators': 400, 'learning_rate': 0.05324815100127778, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:49:49,392] Trial 19 finished with value: 0.8953149211478092 and parameters: {'n_estimators': 450, 'learning_rate': 0.05410133509464863, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:49:55,205] Trial 20 finished with value: 0.911258259284575 and parameters: {'n_estimators': 400, 'learning_rate': 0.027246714310994524, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:50:01,048] Trial 21 finished with value: 0.9012765181926528 and parameters: {'n_estimators': 400, 'learning_rate': 0.026400594778282212, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:50:07,993] Trial 22 finished with value: 0.9071643690252585 and parameters: {'n_estimators': 450, 'learning_rate': 0.03968802810252119, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:50:12,929] Trial 23 finished with value: 0.8988097838996806 and parameters: {'n_estimators': 350, 'learning_rate': 0.01755426425883979, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:50:17,758] Trial 24 finished with value: 0.9040987331258016 and parameters: {'n_estimators': 300, 'learning_rate': 0.02941514323753722, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:50:22,211] Trial 25 finished with value: 0.8979349064455031 and parameters: {'n_estimators': 500, 'learning_rate': 0.050117792916984163, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:50:27,416] Trial 26 finished with value: 0.9004686567164178 and parameters: {'n_estimators': 400, 'learning_rate': 0.08914442760100516, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:50:33,981] Trial 27 finished with value: 0.8917186424099091 and parameters: {'n_estimators': 450, 'learning_rate': 0.02072266042806045, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:50:38,239] Trial 28 finished with value: 0.9061209020477194 and parameters: {'n_estimators': 350, 'learning_rate': 0.011273465743968628, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:50:40,936] Trial 29 finished with value: 0.8996059316546818 and parameters: {'n_estimators': 300, 'learning_rate': 0.07083514516788493, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:50:43,607] Trial 30 finished with value: 0.8954628666976021 and parameters: {'n_estimators': 450, 'learning_rate': 0.043254474449571714, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:50:44,640] Trial 31 finished with value: 0.8985311545564416 and parameters: {'n_estimators': 100, 'learning_rate': 0.14087772549242814, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:50:46,505] Trial 32 finished with value: 0.904255345340745 and parameters: {'n_estimators': 250, 'learning_rate': 0.06991200306846078, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.9134123911739185.\n",
      "[I 2025-03-17 08:50:47,711] Trial 33 finished with value: 0.917579954042469 and parameters: {'n_estimators': 200, 'learning_rate': 0.0300805300918361, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:50:48,933] Trial 34 finished with value: 0.9084269091205209 and parameters: {'n_estimators': 200, 'learning_rate': 0.03050227387411487, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:50:49,642] Trial 35 finished with value: 0.8924973326060984 and parameters: {'n_estimators': 150, 'learning_rate': 0.020493364799376333, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:50:56,086] Trial 36 finished with value: 0.8950223642615727 and parameters: {'n_estimators': 400, 'learning_rate': 0.04337978583188823, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:50:57,010] Trial 37 finished with value: 0.9061448794156032 and parameters: {'n_estimators': 150, 'learning_rate': 0.014187285761389118, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:00,229] Trial 38 finished with value: 0.9040367727274923 and parameters: {'n_estimators': 200, 'learning_rate': 0.02408098569593656, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:01,393] Trial 39 finished with value: 0.9138503642096781 and parameters: {'n_estimators': 250, 'learning_rate': 0.029869762819897748, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:03,265] Trial 40 finished with value: 0.9067291364391149 and parameters: {'n_estimators': 250, 'learning_rate': 0.03225708986884324, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:04,655] Trial 41 finished with value: 0.9047917893488737 and parameters: {'n_estimators': 300, 'learning_rate': 0.028090481899348586, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:05,592] Trial 42 finished with value: 0.8968942902127113 and parameters: {'n_estimators': 200, 'learning_rate': 0.019602479687118115, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:07,095] Trial 43 finished with value: 0.9097801393495036 and parameters: {'n_estimators': 250, 'learning_rate': 0.044541451262964105, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:08,614] Trial 44 finished with value: 0.9063848292791377 and parameters: {'n_estimators': 250, 'learning_rate': 0.033864939022963274, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:10,466] Trial 45 finished with value: 0.9080586334620762 and parameters: {'n_estimators': 250, 'learning_rate': 0.06018733957207561, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:12,260] Trial 46 finished with value: 0.9018491229007022 and parameters: {'n_estimators': 300, 'learning_rate': 0.01608687924590023, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:14,219] Trial 47 finished with value: 0.8950972705582411 and parameters: {'n_estimators': 150, 'learning_rate': 0.03972051062673172, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:17,580] Trial 48 finished with value: 0.9007176722080852 and parameters: {'n_estimators': 200, 'learning_rate': 0.02256897477242743, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:20,218] Trial 49 finished with value: 0.9073990538958521 and parameters: {'n_estimators': 300, 'learning_rate': 0.03516721006094428, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:22,786] Trial 50 finished with value: 0.8947941612653822 and parameters: {'n_estimators': 200, 'learning_rate': 0.012971439044726266, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:24,402] Trial 51 finished with value: 0.9115331245490557 and parameters: {'n_estimators': 350, 'learning_rate': 0.04575070267102534, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:26,010] Trial 52 finished with value: 0.9154072812423413 and parameters: {'n_estimators': 350, 'learning_rate': 0.045472168071005785, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:27,637] Trial 53 finished with value: 0.9125606935959858 and parameters: {'n_estimators': 350, 'learning_rate': 0.02686281379661564, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:29,249] Trial 54 finished with value: 0.9088719283878139 and parameters: {'n_estimators': 350, 'learning_rate': 0.06041533462221777, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:30,868] Trial 55 finished with value: 0.9037345064875846 and parameters: {'n_estimators': 350, 'learning_rate': 0.03206605870028292, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:32,476] Trial 56 finished with value: 0.9036104086433833 and parameters: {'n_estimators': 350, 'learning_rate': 0.08440513191568567, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:34,075] Trial 57 finished with value: 0.9085138460467409 and parameters: {'n_estimators': 300, 'learning_rate': 0.024378186014058893, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:37,034] Trial 58 finished with value: 0.9034680394203285 and parameters: {'n_estimators': 500, 'learning_rate': 0.03749403341729725, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:38,641] Trial 59 finished with value: 0.9044354955290924 and parameters: {'n_estimators': 350, 'learning_rate': 0.017503081076715606, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:41,303] Trial 60 finished with value: 0.9022235522471187 and parameters: {'n_estimators': 450, 'learning_rate': 0.04624215749846145, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:43,134] Trial 61 finished with value: 0.9114795944551275 and parameters: {'n_estimators': 400, 'learning_rate': 0.02622994473236189, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:44,973] Trial 62 finished with value: 0.9098894503333067 and parameters: {'n_estimators': 400, 'learning_rate': 0.026888233047873914, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:47,039] Trial 63 finished with value: 0.9071875883517103 and parameters: {'n_estimators': 450, 'learning_rate': 0.030356167477407364, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:48,878] Trial 64 finished with value: 0.9161915244329535 and parameters: {'n_estimators': 400, 'learning_rate': 0.02307961167664943, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:51,469] Trial 65 finished with value: 0.9047810339854058 and parameters: {'n_estimators': 350, 'learning_rate': 0.039688826092133846, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:53,835] Trial 66 finished with value: 0.9079166254682713 and parameters: {'n_estimators': 400, 'learning_rate': 0.022400015149404037, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:55,443] Trial 67 finished with value: 0.9095516479182674 and parameters: {'n_estimators': 350, 'learning_rate': 0.051716381480558134, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:57,806] Trial 68 finished with value: 0.9106742533037127 and parameters: {'n_estimators': 400, 'learning_rate': 0.01959983047365183, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:51:59,887] Trial 69 finished with value: 0.9088417072523519 and parameters: {'n_estimators': 450, 'learning_rate': 0.059965700021884526, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:02,117] Trial 70 finished with value: 0.9107298834609237 and parameters: {'n_estimators': 300, 'learning_rate': 0.02921555442112508, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:03,961] Trial 71 finished with value: 0.9086960218284252 and parameters: {'n_estimators': 400, 'learning_rate': 0.025171915984959495, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:06,242] Trial 72 finished with value: 0.9085498136818794 and parameters: {'n_estimators': 500, 'learning_rate': 0.03560814329228446, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:08,616] Trial 73 finished with value: 0.9016501590514748 and parameters: {'n_estimators': 400, 'learning_rate': 0.022914855526554267, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:10,219] Trial 74 finished with value: 0.9110722891457212 and parameters: {'n_estimators': 350, 'learning_rate': 0.0271624175011458, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:12,050] Trial 75 finished with value: 0.9035925871642638 and parameters: {'n_estimators': 400, 'learning_rate': 0.041990278836151765, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:14,718] Trial 76 finished with value: 0.9015224944300376 and parameters: {'n_estimators': 450, 'learning_rate': 0.032101612259236335, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:16,216] Trial 77 finished with value: 0.9138741313427431 and parameters: {'n_estimators': 250, 'learning_rate': 0.018823679130148915, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:17,712] Trial 78 finished with value: 0.909413786843612 and parameters: {'n_estimators': 250, 'learning_rate': 0.018197467725494212, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:19,640] Trial 79 finished with value: 0.9073588935780437 and parameters: {'n_estimators': 250, 'learning_rate': 0.015108252512308726, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:20,838] Trial 80 finished with value: 0.9082487527377132 and parameters: {'n_estimators': 200, 'learning_rate': 0.048688194238581534, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:22,221] Trial 81 finished with value: 0.9017667431620919 and parameters: {'n_estimators': 300, 'learning_rate': 0.020930400877774265, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:23,826] Trial 82 finished with value: 0.9013127316650493 and parameters: {'n_estimators': 350, 'learning_rate': 0.01886718009174191, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:24,984] Trial 83 finished with value: 0.9157863102943959 and parameters: {'n_estimators': 250, 'learning_rate': 0.025413829645230084, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:26,163] Trial 84 finished with value: 0.9142055757050201 and parameters: {'n_estimators': 250, 'learning_rate': 0.028617232113165185, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:27,657] Trial 85 finished with value: 0.9168600588008482 and parameters: {'n_estimators': 250, 'learning_rate': 0.023482006030913216, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:29,153] Trial 86 finished with value: 0.9108966452849664 and parameters: {'n_estimators': 250, 'learning_rate': 0.023708455235756442, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:30,673] Trial 87 finished with value: 0.9072707113148291 and parameters: {'n_estimators': 200, 'learning_rate': 0.021339810297777626, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:32,175] Trial 88 finished with value: 0.9028985491019919 and parameters: {'n_estimators': 250, 'learning_rate': 0.017182437123305385, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:36,137] Trial 89 finished with value: 0.9010266357688114 and parameters: {'n_estimators': 250, 'learning_rate': 0.03146403160169836, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:37,947] Trial 90 finished with value: 0.9126456222363147 and parameters: {'n_estimators': 200, 'learning_rate': 0.013639526577713921, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:39,521] Trial 91 finished with value: 0.9012816747252665 and parameters: {'n_estimators': 150, 'learning_rate': 0.014523826138679826, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:41,340] Trial 92 finished with value: 0.8984864291407149 and parameters: {'n_estimators': 200, 'learning_rate': 0.013384044943115866, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:43,447] Trial 93 finished with value: 0.9055742640529066 and parameters: {'n_estimators': 200, 'learning_rate': 0.01597969699765706, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:44,952] Trial 94 finished with value: 0.9030255303293625 and parameters: {'n_estimators': 250, 'learning_rate': 0.011559827267214618, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:47,325] Trial 95 finished with value: 0.9128445198282618 and parameters: {'n_estimators': 200, 'learning_rate': 0.010037506823682357, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:50,975] Trial 96 finished with value: 0.8768661181723776 and parameters: {'n_estimators': 250, 'learning_rate': 0.010006856289439623, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:53,533] Trial 97 finished with value: 0.890152266180675 and parameters: {'n_estimators': 200, 'learning_rate': 0.02931670184925072, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:55,768] Trial 98 finished with value: 0.9062719784386154 and parameters: {'n_estimators': 150, 'learning_rate': 0.034482298125427815, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:52:57,705] Trial 99 finished with value: 0.8960131339378663 and parameters: {'n_estimators': 250, 'learning_rate': 0.012193086937390674, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:01,146] Trial 100 finished with value: 0.9065590681761794 and parameters: {'n_estimators': 300, 'learning_rate': 0.037697647510555723, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:02,075] Trial 101 finished with value: 0.8828040847429823 and parameters: {'n_estimators': 200, 'learning_rate': 0.01088144310545757, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:03,875] Trial 102 finished with value: 0.9046181641303592 and parameters: {'n_estimators': 200, 'learning_rate': 0.024399825071283507, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:04,786] Trial 103 finished with value: 0.9046350955843494 and parameters: {'n_estimators': 150, 'learning_rate': 0.02032500209059186, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:07,396] Trial 104 finished with value: 0.9117480975165186 and parameters: {'n_estimators': 250, 'learning_rate': 0.028499205740453105, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:08,323] Trial 105 finished with value: 0.8942694106556518 and parameters: {'n_estimators': 200, 'learning_rate': 0.22134271821537504, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:09,095] Trial 106 finished with value: 0.9068182385935909 and parameters: {'n_estimators': 100, 'learning_rate': 0.022110169558365964, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:12,796] Trial 107 finished with value: 0.8999060877179467 and parameters: {'n_estimators': 250, 'learning_rate': 0.025459874190610222, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:14,590] Trial 108 finished with value: 0.9088911425258501 and parameters: {'n_estimators': 300, 'learning_rate': 0.012738980672236803, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:17,987] Trial 109 finished with value: 0.9011039424557812 and parameters: {'n_estimators': 250, 'learning_rate': 0.016435167128871293, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:20,332] Trial 110 finished with value: 0.9068693977578212 and parameters: {'n_estimators': 250, 'learning_rate': 0.010834166295585567, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:21,713] Trial 111 finished with value: 0.9130279118340733 and parameters: {'n_estimators': 300, 'learning_rate': 0.026239435751010783, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:23,097] Trial 112 finished with value: 0.905966209377695 and parameters: {'n_estimators': 300, 'learning_rate': 0.03302436259270837, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:24,482] Trial 113 finished with value: 0.912051587753346 and parameters: {'n_estimators': 300, 'learning_rate': 0.02787803199104333, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:25,414] Trial 114 finished with value: 0.8910303734948446 and parameters: {'n_estimators': 200, 'learning_rate': 0.018841354098658884, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:26,570] Trial 115 finished with value: 0.9166284493588914 and parameters: {'n_estimators': 250, 'learning_rate': 0.02315052823908242, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:27,730] Trial 116 finished with value: 0.9120400817817268 and parameters: {'n_estimators': 250, 'learning_rate': 0.023611380882461307, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:29,115] Trial 117 finished with value: 0.9084761200207225 and parameters: {'n_estimators': 300, 'learning_rate': 0.03046476845250242, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:30,274] Trial 118 finished with value: 0.9135439854848657 and parameters: {'n_estimators': 250, 'learning_rate': 0.025375479416427496, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:31,431] Trial 119 finished with value: 0.902578768527361 and parameters: {'n_estimators': 250, 'learning_rate': 0.026450636320742796, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:32,938] Trial 120 finished with value: 0.9110775698502259 and parameters: {'n_estimators': 250, 'learning_rate': 0.022588728072520055, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:34,097] Trial 121 finished with value: 0.9104321266352124 and parameters: {'n_estimators': 250, 'learning_rate': 0.02527665874926738, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:35,480] Trial 122 finished with value: 0.9118105505605506 and parameters: {'n_estimators': 300, 'learning_rate': 0.028697632070920524, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:36,646] Trial 123 finished with value: 0.903175684670981 and parameters: {'n_estimators': 250, 'learning_rate': 0.07727511701142342, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:37,806] Trial 124 finished with value: 0.9081595075875935 and parameters: {'n_estimators': 250, 'learning_rate': 0.02144032412961334, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:39,616] Trial 125 finished with value: 0.907886794718492 and parameters: {'n_estimators': 300, 'learning_rate': 0.03574888562336578, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:43,502] Trial 126 finished with value: 0.8911670938264835 and parameters: {'n_estimators': 250, 'learning_rate': 0.11643123056476974, 'max_depth': 12, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:44,681] Trial 127 finished with value: 0.9100699551672362 and parameters: {'n_estimators': 250, 'learning_rate': 0.04050237392260595, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:45,888] Trial 128 finished with value: 0.9052659512871839 and parameters: {'n_estimators': 200, 'learning_rate': 0.01958780055851129, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:47,268] Trial 129 finished with value: 0.9083680391673987 and parameters: {'n_estimators': 300, 'learning_rate': 0.031445655522790564, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:49,556] Trial 130 finished with value: 0.9169855422016269 and parameters: {'n_estimators': 500, 'learning_rate': 0.024442637783749298, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:51,839] Trial 131 finished with value: 0.90933166353273 and parameters: {'n_estimators': 500, 'learning_rate': 0.024000305083676145, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:53,892] Trial 132 finished with value: 0.9047292108476318 and parameters: {'n_estimators': 450, 'learning_rate': 0.025821895210074667, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:56,168] Trial 133 finished with value: 0.9112359886550359 and parameters: {'n_estimators': 500, 'learning_rate': 0.027845045537609144, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:53:59,142] Trial 134 finished with value: 0.912332760148886 and parameters: {'n_estimators': 500, 'learning_rate': 0.021889176256664686, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:01,191] Trial 135 finished with value: 0.9155864705838258 and parameters: {'n_estimators': 450, 'learning_rate': 0.03323407635702227, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:03,247] Trial 136 finished with value: 0.9057976636961712 and parameters: {'n_estimators': 450, 'learning_rate': 0.038206767849502575, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:05,305] Trial 137 finished with value: 0.9100240314511968 and parameters: {'n_estimators': 450, 'learning_rate': 0.029696002414298487, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:07,584] Trial 138 finished with value: 0.9128000083035929 and parameters: {'n_estimators': 500, 'learning_rate': 0.03464410387637699, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:10,239] Trial 139 finished with value: 0.910471452262497 and parameters: {'n_estimators': 450, 'learning_rate': 0.023505931346168765, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:12,095] Trial 140 finished with value: 0.9066693190926621 and parameters: {'n_estimators': 400, 'learning_rate': 0.03300830069442339, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:13,257] Trial 141 finished with value: 0.9108428454126856 and parameters: {'n_estimators': 250, 'learning_rate': 0.026581308271807894, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:14,415] Trial 142 finished with value: 0.9128785245573567 and parameters: {'n_estimators': 250, 'learning_rate': 0.03052461521753059, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:15,569] Trial 143 finished with value: 0.911063171503319 and parameters: {'n_estimators': 250, 'learning_rate': 0.02989660547806637, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:16,726] Trial 144 finished with value: 0.9135819481585035 and parameters: {'n_estimators': 250, 'learning_rate': 0.024915431117746255, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:18,222] Trial 145 finished with value: 0.9107726617219155 and parameters: {'n_estimators': 250, 'learning_rate': 0.02500364540217236, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:20,517] Trial 146 finished with value: 0.9074951005114048 and parameters: {'n_estimators': 500, 'learning_rate': 0.027767453227085362, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:21,678] Trial 147 finished with value: 0.9056630395465961 and parameters: {'n_estimators': 250, 'learning_rate': 0.020920362264619054, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:22,861] Trial 148 finished with value: 0.9044746459161646 and parameters: {'n_estimators': 250, 'learning_rate': 0.022651384101211956, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:25,224] Trial 149 finished with value: 0.9082407989369201 and parameters: {'n_estimators': 400, 'learning_rate': 0.019597815789341413, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:26,606] Trial 150 finished with value: 0.9049282771408158 and parameters: {'n_estimators': 300, 'learning_rate': 0.017894798778415055, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:27,761] Trial 151 finished with value: 0.9104087380768784 and parameters: {'n_estimators': 250, 'learning_rate': 0.02551643431497959, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:28,920] Trial 152 finished with value: 0.9100478285725954 and parameters: {'n_estimators': 250, 'learning_rate': 0.03045044415022164, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:30,072] Trial 153 finished with value: 0.9078661657520586 and parameters: {'n_estimators': 250, 'learning_rate': 0.033501914746840875, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:30,328] Trial 154 finished with value: 0.8816671575105748 and parameters: {'n_estimators': 50, 'learning_rate': 0.027609927289949415, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:31,822] Trial 155 finished with value: 0.9076542471818062 and parameters: {'n_estimators': 250, 'learning_rate': 0.023734069847817982, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:32,977] Trial 156 finished with value: 0.907629962319362 and parameters: {'n_estimators': 250, 'learning_rate': 0.030749782228370232, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:35,028] Trial 157 finished with value: 0.910794533039508 and parameters: {'n_estimators': 450, 'learning_rate': 0.02601731211290795, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:36,191] Trial 158 finished with value: 0.9085899970492995 and parameters: {'n_estimators': 250, 'learning_rate': 0.0369523259245285, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:37,977] Trial 159 finished with value: 0.9037230976575679 and parameters: {'n_estimators': 300, 'learning_rate': 0.020910318649743454, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:39,129] Trial 160 finished with value: 0.9134712087942493 and parameters: {'n_estimators': 250, 'learning_rate': 0.02857823364313867, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:40,290] Trial 161 finished with value: 0.9115967848215508 and parameters: {'n_estimators': 250, 'learning_rate': 0.028531284396157805, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:41,447] Trial 162 finished with value: 0.9096239845465851 and parameters: {'n_estimators': 250, 'learning_rate': 0.031979010566526106, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:42,602] Trial 163 finished with value: 0.9066988145920309 and parameters: {'n_estimators': 250, 'learning_rate': 0.024767893729155124, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:43,787] Trial 164 finished with value: 0.9113564002061662 and parameters: {'n_estimators': 250, 'learning_rate': 0.027214917975818848, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:45,391] Trial 165 finished with value: 0.9124819629921653 and parameters: {'n_estimators': 350, 'learning_rate': 0.02322577705878151, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:47,226] Trial 166 finished with value: 0.9125856323161334 and parameters: {'n_estimators': 400, 'learning_rate': 0.028579734827973814, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:48,441] Trial 167 finished with value: 0.9066184266327395 and parameters: {'n_estimators': 200, 'learning_rate': 0.034841246779311635, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:49,824] Trial 168 finished with value: 0.9042324396942465 and parameters: {'n_estimators': 300, 'learning_rate': 0.0425970872074139, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:50,987] Trial 169 finished with value: 0.9121598430500409 and parameters: {'n_estimators': 250, 'learning_rate': 0.022166693280575224, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:52,478] Trial 170 finished with value: 0.9080209303378639 and parameters: {'n_estimators': 250, 'learning_rate': 0.0319099088308432, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:53,415] Trial 171 finished with value: 0.9053936964114199 and parameters: {'n_estimators': 200, 'learning_rate': 0.024791682761738397, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:55,864] Trial 172 finished with value: 0.9069762146722627 and parameters: {'n_estimators': 200, 'learning_rate': 0.026429156739207618, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:54:58,486] Trial 173 finished with value: 0.9018364910388345 and parameters: {'n_estimators': 200, 'learning_rate': 0.029921886789187058, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:02,105] Trial 174 finished with value: 0.897718716710021 and parameters: {'n_estimators': 200, 'learning_rate': 0.026857393199571294, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:06,343] Trial 175 finished with value: 0.8955090663630593 and parameters: {'n_estimators': 250, 'learning_rate': 0.05577273123905653, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:08,406] Trial 176 finished with value: 0.9084974783638031 and parameters: {'n_estimators': 450, 'learning_rate': 0.033750997415756635, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:09,563] Trial 177 finished with value: 0.9042265881735174 and parameters: {'n_estimators': 250, 'learning_rate': 0.024368534457115103, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:10,718] Trial 178 finished with value: 0.9041131957914932 and parameters: {'n_estimators': 250, 'learning_rate': 0.02260767724787153, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:13,878] Trial 179 finished with value: 0.8949196283335382 and parameters: {'n_estimators': 200, 'learning_rate': 0.029306246441149573, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:16,151] Trial 180 finished with value: 0.9135471553442958 and parameters: {'n_estimators': 500, 'learning_rate': 0.019810771215137767, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:18,433] Trial 181 finished with value: 0.9150427249276113 and parameters: {'n_estimators': 500, 'learning_rate': 0.019901158526902923, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:20,719] Trial 182 finished with value: 0.9098871771569705 and parameters: {'n_estimators': 500, 'learning_rate': 0.018497507811465592, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:23,003] Trial 183 finished with value: 0.9116214552260267 and parameters: {'n_estimators': 500, 'learning_rate': 0.019603786772661228, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:25,297] Trial 184 finished with value: 0.9065606447436302 and parameters: {'n_estimators': 500, 'learning_rate': 0.020535939446102956, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:27,580] Trial 185 finished with value: 0.9120349492197952 and parameters: {'n_estimators': 500, 'learning_rate': 0.02162339457705084, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:29,866] Trial 186 finished with value: 0.907400670353099 and parameters: {'n_estimators': 500, 'learning_rate': 0.017372863550912627, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:32,144] Trial 187 finished with value: 0.906678482299019 and parameters: {'n_estimators': 500, 'learning_rate': 0.016255395999953157, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:34,448] Trial 188 finished with value: 0.9089948631115081 and parameters: {'n_estimators': 500, 'learning_rate': 0.023690359712508362, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:37,113] Trial 189 finished with value: 0.9073334104985953 and parameters: {'n_estimators': 450, 'learning_rate': 0.02012852796696952, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:39,423] Trial 190 finished with value: 0.9096172159320071 and parameters: {'n_estimators': 500, 'learning_rate': 0.025533381647459923, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:40,588] Trial 191 finished with value: 0.9147148349642794 and parameters: {'n_estimators': 250, 'learning_rate': 0.028317005960046514, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:41,744] Trial 192 finished with value: 0.9115587381860026 and parameters: {'n_estimators': 250, 'learning_rate': 0.027847223357407604, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:42,904] Trial 193 finished with value: 0.9106833974338657 and parameters: {'n_estimators': 250, 'learning_rate': 0.03126768146592297, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:44,067] Trial 194 finished with value: 0.9103913556138895 and parameters: {'n_estimators': 250, 'learning_rate': 0.02197730273934212, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:45,220] Trial 195 finished with value: 0.8964925407269341 and parameters: {'n_estimators': 250, 'learning_rate': 0.2944812582843273, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:46,828] Trial 196 finished with value: 0.9123584891345144 and parameters: {'n_estimators': 350, 'learning_rate': 0.02565235953867786, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:47,985] Trial 197 finished with value: 0.9121547828041727 and parameters: {'n_estimators': 250, 'learning_rate': 0.029151531799299173, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:49,380] Trial 198 finished with value: 0.9115348799862991 and parameters: {'n_estimators': 300, 'learning_rate': 0.018710755658944114, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:52,025] Trial 199 finished with value: 0.9066293680648219 and parameters: {'n_estimators': 450, 'learning_rate': 0.022856148149162328, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:53,189] Trial 200 finished with value: 0.913078571835479 and parameters: {'n_estimators': 250, 'learning_rate': 0.02714411369096106, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:54,349] Trial 201 finished with value: 0.910747203041241 and parameters: {'n_estimators': 250, 'learning_rate': 0.026415956921909206, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:55,509] Trial 202 finished with value: 0.9032649247442771 and parameters: {'n_estimators': 250, 'learning_rate': 0.023992995472179743, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:56,668] Trial 203 finished with value: 0.9069684972086135 and parameters: {'n_estimators': 250, 'learning_rate': 0.02830328376110945, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:57,849] Trial 204 finished with value: 0.9118841923543336 and parameters: {'n_estimators': 250, 'learning_rate': 0.03264227278810124, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:55:59,005] Trial 205 finished with value: 0.9123892621990283 and parameters: {'n_estimators': 250, 'learning_rate': 0.030711635136569257, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:00,162] Trial 206 finished with value: 0.9072939783148402 and parameters: {'n_estimators': 250, 'learning_rate': 0.026997904312707557, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:03,103] Trial 207 finished with value: 0.9085672760417207 and parameters: {'n_estimators': 500, 'learning_rate': 0.024571240483966687, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:04,259] Trial 208 finished with value: 0.9123055865076442 and parameters: {'n_estimators': 250, 'learning_rate': 0.03649700504981615, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:05,650] Trial 209 finished with value: 0.909805062616867 and parameters: {'n_estimators': 300, 'learning_rate': 0.029453215221807393, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:07,487] Trial 210 finished with value: 0.911868995260703 and parameters: {'n_estimators': 400, 'learning_rate': 0.02096795641095896, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:08,200] Trial 211 finished with value: 0.9021265834219518 and parameters: {'n_estimators': 150, 'learning_rate': 0.0274219548397699, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:12,255] Trial 212 finished with value: 0.8984305311874552 and parameters: {'n_estimators': 250, 'learning_rate': 0.0252368306878602, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:13,410] Trial 213 finished with value: 0.8986190734765815 and parameters: {'n_estimators': 250, 'learning_rate': 0.015112106003730265, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:19,202] Trial 214 finished with value: 0.8849342396025455 and parameters: {'n_estimators': 500, 'learning_rate': 0.06516479048953432, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:20,140] Trial 215 finished with value: 0.8940473315574018 and parameters: {'n_estimators': 200, 'learning_rate': 0.02352561537924052, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:21,297] Trial 216 finished with value: 0.9087023092657803 and parameters: {'n_estimators': 250, 'learning_rate': 0.03237630847245309, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:22,853] Trial 217 finished with value: 0.8957909079506973 and parameters: {'n_estimators': 200, 'learning_rate': 0.026227589884677997, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:25,467] Trial 218 finished with value: 0.9046221099162276 and parameters: {'n_estimators': 250, 'learning_rate': 0.029330956358440363, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:26,763] Trial 219 finished with value: 0.9059593777106947 and parameters: {'n_estimators': 100, 'learning_rate': 0.02258094946589239, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:29,422] Trial 220 finished with value: 0.897162392601867 and parameters: {'n_estimators': 450, 'learning_rate': 0.046821121793639654, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:31,701] Trial 221 finished with value: 0.9035478540511516 and parameters: {'n_estimators': 500, 'learning_rate': 0.036451102809403536, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:33,985] Trial 222 finished with value: 0.9082209634737133 and parameters: {'n_estimators': 500, 'learning_rate': 0.03449206117853914, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:36,263] Trial 223 finished with value: 0.9131373819685702 and parameters: {'n_estimators': 500, 'learning_rate': 0.03081877237169797, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:38,542] Trial 224 finished with value: 0.9060760622190165 and parameters: {'n_estimators': 500, 'learning_rate': 0.030331022686911433, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:40,823] Trial 225 finished with value: 0.908336970121629 and parameters: {'n_estimators': 500, 'learning_rate': 0.027900785064533917, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:42,880] Trial 226 finished with value: 0.9127734250853266 and parameters: {'n_estimators': 450, 'learning_rate': 0.031899594712232214, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:44,045] Trial 227 finished with value: 0.9036804619723743 and parameters: {'n_estimators': 250, 'learning_rate': 0.02524324769871906, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:46,324] Trial 228 finished with value: 0.910758503774808 and parameters: {'n_estimators': 500, 'learning_rate': 0.026190826429514556, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:47,485] Trial 229 finished with value: 0.9112626874838907 and parameters: {'n_estimators': 250, 'learning_rate': 0.02869477781542543, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:48,659] Trial 230 finished with value: 0.9102009044226722 and parameters: {'n_estimators': 250, 'learning_rate': 0.03906157877407304, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:50,969] Trial 231 finished with value: 0.9110008466209661 and parameters: {'n_estimators': 500, 'learning_rate': 0.033474692373245525, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.917579954042469.\n",
      "[I 2025-03-17 08:56:53,250] Trial 232 finished with value: 0.9200612994893556 and parameters: {'n_estimators': 500, 'learning_rate': 0.030772843709441024, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:56:55,530] Trial 233 finished with value: 0.9085827475757933 and parameters: {'n_estimators': 500, 'learning_rate': 0.03143529528599607, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:56:57,810] Trial 234 finished with value: 0.9065007957051675 and parameters: {'n_estimators': 500, 'learning_rate': 0.027751259971275654, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:00,088] Trial 235 finished with value: 0.9072083749850682 and parameters: {'n_estimators': 500, 'learning_rate': 0.030386431473536726, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:01,920] Trial 236 finished with value: 0.9112868641132833 and parameters: {'n_estimators': 400, 'learning_rate': 0.02432486380486455, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:03,081] Trial 237 finished with value: 0.9072288430596789 and parameters: {'n_estimators': 250, 'learning_rate': 0.026999541714811538, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:04,240] Trial 238 finished with value: 0.9170661692342283 and parameters: {'n_estimators': 250, 'learning_rate': 0.028694319137683683, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:05,399] Trial 239 finished with value: 0.907773754260195 and parameters: {'n_estimators': 250, 'learning_rate': 0.029715179709049754, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:06,558] Trial 240 finished with value: 0.9055824125139946 and parameters: {'n_estimators': 250, 'learning_rate': 0.019345382680105116, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:07,720] Trial 241 finished with value: 0.9131790373556473 and parameters: {'n_estimators': 250, 'learning_rate': 0.029122742662734045, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:08,907] Trial 242 finished with value: 0.9091125150052901 and parameters: {'n_estimators': 250, 'learning_rate': 0.028530824465758855, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:10,066] Trial 243 finished with value: 0.9147127367527187 and parameters: {'n_estimators': 250, 'learning_rate': 0.031424985960636066, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:11,227] Trial 244 finished with value: 0.9102130063872055 and parameters: {'n_estimators': 250, 'learning_rate': 0.033028595481818995, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:12,389] Trial 245 finished with value: 0.908722199724464 and parameters: {'n_estimators': 250, 'learning_rate': 0.0257008004140397, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:13,995] Trial 246 finished with value: 0.913367135355635 and parameters: {'n_estimators': 350, 'learning_rate': 0.027642794065451053, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:15,159] Trial 247 finished with value: 0.9091594186662642 and parameters: {'n_estimators': 250, 'learning_rate': 0.028417730851634595, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:16,995] Trial 248 finished with value: 0.9087342919895433 and parameters: {'n_estimators': 400, 'learning_rate': 0.021237629419630536, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:19,953] Trial 249 finished with value: 0.9019092410528655 and parameters: {'n_estimators': 500, 'learning_rate': 0.03118497225106378, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:21,116] Trial 250 finished with value: 0.9104321266352124 and parameters: {'n_estimators': 250, 'learning_rate': 0.02289929353052144, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:22,728] Trial 251 finished with value: 0.9089716228568998 and parameters: {'n_estimators': 350, 'learning_rate': 0.03489178729568238, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:23,888] Trial 252 finished with value: 0.9175618150385352 and parameters: {'n_estimators': 250, 'learning_rate': 0.027238290749121027, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:25,953] Trial 253 finished with value: 0.9137609731069979 and parameters: {'n_estimators': 450, 'learning_rate': 0.029761617057332386, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:28,025] Trial 254 finished with value: 0.9042940901122073 and parameters: {'n_estimators': 450, 'learning_rate': 0.017339751410073434, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:30,760] Trial 255 finished with value: 0.9122234940984942 and parameters: {'n_estimators': 450, 'learning_rate': 0.024255887308628966, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:32,827] Trial 256 finished with value: 0.9013414945443378 and parameters: {'n_estimators': 450, 'learning_rate': 0.027868871228108084, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:34,887] Trial 257 finished with value: 0.911584829232925 and parameters: {'n_estimators': 450, 'learning_rate': 0.02922084268682409, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:36,045] Trial 258 finished with value: 0.9106712452448708 and parameters: {'n_estimators': 250, 'learning_rate': 0.02526106280496282, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:37,650] Trial 259 finished with value: 0.9057587567924766 and parameters: {'n_estimators': 350, 'learning_rate': 0.031950208543159456, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:40,321] Trial 260 finished with value: 0.910090429928378 and parameters: {'n_estimators': 450, 'learning_rate': 0.020596737999335552, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:41,477] Trial 261 finished with value: 0.9034944112627553 and parameters: {'n_estimators': 250, 'learning_rate': 0.02322415822251528, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:42,644] Trial 262 finished with value: 0.90920192957188 and parameters: {'n_estimators': 250, 'learning_rate': 0.025976355856802958, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:43,803] Trial 263 finished with value: 0.9094642242780072 and parameters: {'n_estimators': 250, 'learning_rate': 0.029458287554894762, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:45,632] Trial 264 finished with value: 0.9108393501468128 and parameters: {'n_estimators': 400, 'learning_rate': 0.03362524660827923, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:47,012] Trial 265 finished with value: 0.9134042354790022 and parameters: {'n_estimators': 300, 'learning_rate': 0.1002911232775946, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:48,404] Trial 266 finished with value: 0.9036608960486255 and parameters: {'n_estimators': 300, 'learning_rate': 0.2458076648784609, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:49,815] Trial 267 finished with value: 0.9063652237845785 and parameters: {'n_estimators': 300, 'learning_rate': 0.09455859651025253, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:52,404] Trial 268 finished with value: 0.9026339766289688 and parameters: {'n_estimators': 350, 'learning_rate': 0.01872998183687629, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:54,193] Trial 269 finished with value: 0.9066879730420577 and parameters: {'n_estimators': 300, 'learning_rate': 0.05203016847210094, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:55,808] Trial 270 finished with value: 0.901586556403732 and parameters: {'n_estimators': 350, 'learning_rate': 0.1820474872494158, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:56,968] Trial 271 finished with value: 0.9119384987962293 and parameters: {'n_estimators': 250, 'learning_rate': 0.10865210266840111, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:57:59,322] Trial 272 finished with value: 0.9045426513039029 and parameters: {'n_estimators': 400, 'learning_rate': 0.13242706750363553, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:58:01,377] Trial 273 finished with value: 0.914126670617212 and parameters: {'n_estimators': 450, 'learning_rate': 0.022447417752902765, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:58:03,438] Trial 274 finished with value: 0.9082826490408145 and parameters: {'n_estimators': 450, 'learning_rate': 0.022004041904426553, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:58:05,500] Trial 275 finished with value: 0.905421284789336 and parameters: {'n_estimators': 450, 'learning_rate': 0.05701558033655772, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:58:07,562] Trial 276 finished with value: 0.9102489612590505 and parameters: {'n_estimators': 450, 'learning_rate': 0.021866577334667014, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 232 with value: 0.9200612994893556.\n",
      "[I 2025-03-17 08:58:09,628] Trial 277 finished with value: 0.9220933035533637 and parameters: {'n_estimators': 450, 'learning_rate': 0.023948831838671292, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:10,813] Trial 278 finished with value: 0.900772236793871 and parameters: {'n_estimators': 250, 'learning_rate': 0.023138930382379904, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:14,156] Trial 279 finished with value: 0.9033191915683737 and parameters: {'n_estimators': 450, 'learning_rate': 0.02409198486337327, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:16,210] Trial 280 finished with value: 0.911075223901643 and parameters: {'n_estimators': 450, 'learning_rate': 0.020301066093119543, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:18,275] Trial 281 finished with value: 0.9159218923049778 and parameters: {'n_estimators': 450, 'learning_rate': 0.01977331969467511, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:20,344] Trial 282 finished with value: 0.9114703976911018 and parameters: {'n_estimators': 450, 'learning_rate': 0.018517084739576764, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:22,403] Trial 283 finished with value: 0.9097943367196141 and parameters: {'n_estimators': 450, 'learning_rate': 0.01953142870062034, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:24,465] Trial 284 finished with value: 0.909691701560073 and parameters: {'n_estimators': 450, 'learning_rate': 0.021226450201041313, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:26,747] Trial 285 finished with value: 0.9091703086094679 and parameters: {'n_estimators': 500, 'learning_rate': 0.020110020543886806, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:29,402] Trial 286 finished with value: 0.9077689801706313 and parameters: {'n_estimators': 450, 'learning_rate': 0.022589250080998786, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:30,565] Trial 287 finished with value: 0.8963275076483811 and parameters: {'n_estimators': 250, 'learning_rate': 0.01719856100393285, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:32,618] Trial 288 finished with value: 0.9102156743057433 and parameters: {'n_estimators': 450, 'learning_rate': 0.024681397744498876, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:33,815] Trial 289 finished with value: 0.9058165921071503 and parameters: {'n_estimators': 250, 'learning_rate': 0.02455626112456405, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:34,972] Trial 290 finished with value: 0.9074243204678826 and parameters: {'n_estimators': 250, 'learning_rate': 0.021176694445440174, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:37,926] Trial 291 finished with value: 0.9089755176247373 and parameters: {'n_estimators': 500, 'learning_rate': 0.026002770027527454, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:39,091] Trial 292 finished with value: 0.908161116013774 and parameters: {'n_estimators': 250, 'learning_rate': 0.022564026853956448, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:41,148] Trial 293 finished with value: 0.9126243483302977 and parameters: {'n_estimators': 450, 'learning_rate': 0.019659614836720095, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:42,301] Trial 294 finished with value: 0.9072348774526009 and parameters: {'n_estimators': 250, 'learning_rate': 0.02690920918210439, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:44,584] Trial 295 finished with value: 0.9161963706038604 and parameters: {'n_estimators': 500, 'learning_rate': 0.02361522390286333, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:47,527] Trial 296 finished with value: 0.9140992053627173 and parameters: {'n_estimators': 500, 'learning_rate': 0.023463597592165316, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:50,484] Trial 297 finished with value: 0.916905138102155 and parameters: {'n_estimators': 500, 'learning_rate': 0.021430736304930677, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:53,439] Trial 298 finished with value: 0.9133889221300441 and parameters: {'n_estimators': 500, 'learning_rate': 0.02146955519534859, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:56,387] Trial 299 finished with value: 0.9092528483125035 and parameters: {'n_estimators': 500, 'learning_rate': 0.023885690816747567, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:58:59,362] Trial 300 finished with value: 0.9075687840593252 and parameters: {'n_estimators': 500, 'learning_rate': 0.02301279582408448, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:02,330] Trial 301 finished with value: 0.9084849623815947 and parameters: {'n_estimators': 500, 'learning_rate': 0.02139465482597204, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:05,272] Trial 302 finished with value: 0.9104579171535878 and parameters: {'n_estimators': 500, 'learning_rate': 0.023473954954743626, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:08,217] Trial 303 finished with value: 0.9109106844755168 and parameters: {'n_estimators': 500, 'learning_rate': 0.022036062921304143, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:11,159] Trial 304 finished with value: 0.9091366783800995 and parameters: {'n_estimators': 500, 'learning_rate': 0.02470989597538943, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:14,105] Trial 305 finished with value: 0.9066376363924054 and parameters: {'n_estimators': 500, 'learning_rate': 0.0261814582153114, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:17,052] Trial 306 finished with value: 0.9013400967034688 and parameters: {'n_estimators': 500, 'learning_rate': 0.01844209535499389, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:19,715] Trial 307 finished with value: 0.913071476921691 and parameters: {'n_estimators': 450, 'learning_rate': 0.022918043159795225, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:22,715] Trial 308 finished with value: 0.9088486444807252 and parameters: {'n_estimators': 500, 'learning_rate': 0.02115616646303436, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:24,771] Trial 309 finished with value: 0.9154635357737867 and parameters: {'n_estimators': 450, 'learning_rate': 0.024719407544378225, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:26,827] Trial 310 finished with value: 0.9100192606151911 and parameters: {'n_estimators': 450, 'learning_rate': 0.020158742894906916, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:28,881] Trial 311 finished with value: 0.9088883772709535 and parameters: {'n_estimators': 450, 'learning_rate': 0.024185228523206526, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:31,544] Trial 312 finished with value: 0.9112953324594546 and parameters: {'n_estimators': 450, 'learning_rate': 0.027135233035699244, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:34,842] Trial 313 finished with value: 0.9061276446931281 and parameters: {'n_estimators': 450, 'learning_rate': 0.025331505424492785, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:36,699] Trial 314 finished with value: 0.9130144503333067 and parameters: {'n_estimators': 400, 'learning_rate': 0.022140787173371174, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:38,987] Trial 315 finished with value: 0.9106925563385364 and parameters: {'n_estimators': 500, 'learning_rate': 0.04379008653595931, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:41,044] Trial 316 finished with value: 0.9082496438746439 and parameters: {'n_estimators': 450, 'learning_rate': 0.031076575800814372, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:43,108] Trial 317 finished with value: 0.9086145279781862 and parameters: {'n_estimators': 450, 'learning_rate': 0.026910966836168282, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:43,817] Trial 318 finished with value: 0.8882541287883846 and parameters: {'n_estimators': 150, 'learning_rate': 0.017895727640941498, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:46,776] Trial 319 finished with value: 0.9032572020293731 and parameters: {'n_estimators': 500, 'learning_rate': 0.023075544173792144, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:48,620] Trial 320 finished with value: 0.9118030844595788 and parameters: {'n_estimators': 400, 'learning_rate': 0.019929922866495406, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:50,680] Trial 321 finished with value: 0.9049639951549304 and parameters: {'n_estimators': 450, 'learning_rate': 0.024170615999431846, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:52,958] Trial 322 finished with value: 0.9125551820195794 and parameters: {'n_estimators': 500, 'learning_rate': 0.036558560803625274, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:55,241] Trial 323 finished with value: 0.9095675583313282 and parameters: {'n_estimators': 500, 'learning_rate': 0.03303729332980256, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 08:59:57,310] Trial 324 finished with value: 0.9157864852591713 and parameters: {'n_estimators': 450, 'learning_rate': 0.016261274956892228, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:00,005] Trial 325 finished with value: 0.9153054353054353 and parameters: {'n_estimators': 450, 'learning_rate': 0.014114027184955611, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:02,674] Trial 326 finished with value: 0.9135208603569993 and parameters: {'n_estimators': 450, 'learning_rate': 0.015554632946410093, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:05,347] Trial 327 finished with value: 0.9107713971156854 and parameters: {'n_estimators': 450, 'learning_rate': 0.01419930911530549, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:08,008] Trial 328 finished with value: 0.9034470352683593 and parameters: {'n_estimators': 450, 'learning_rate': 0.016071659100883453, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:10,671] Trial 329 finished with value: 0.91817308767227 and parameters: {'n_estimators': 450, 'learning_rate': 0.015130814227453214, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:13,998] Trial 330 finished with value: 0.9105202177423383 and parameters: {'n_estimators': 450, 'learning_rate': 0.012050576184650975, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:16,670] Trial 331 finished with value: 0.9095337779605908 and parameters: {'n_estimators': 450, 'learning_rate': 0.014071549038922913, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:20,653] Trial 332 finished with value: 0.9060308250942315 and parameters: {'n_estimators': 450, 'learning_rate': 0.014637908672610164, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:23,320] Trial 333 finished with value: 0.9121215010839595 and parameters: {'n_estimators': 450, 'learning_rate': 0.012163637083684127, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:25,732] Trial 334 finished with value: 0.9163318055353502 and parameters: {'n_estimators': 400, 'learning_rate': 0.014200809783448391, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:27,604] Trial 335 finished with value: 0.9068050713961965 and parameters: {'n_estimators': 400, 'learning_rate': 0.012741585900745776, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:29,439] Trial 336 finished with value: 0.9038533863672786 and parameters: {'n_estimators': 400, 'learning_rate': 0.013254023438289476, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:32,107] Trial 337 finished with value: 0.9140124722900314 and parameters: {'n_estimators': 450, 'learning_rate': 0.01474195419321473, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:33,964] Trial 338 finished with value: 0.9072469574470563 and parameters: {'n_estimators': 400, 'learning_rate': 0.013732003237392485, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:36,663] Trial 339 finished with value: 0.9174582548296291 and parameters: {'n_estimators': 450, 'learning_rate': 0.013388829414771783, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:39,362] Trial 340 finished with value: 0.9092446569941014 and parameters: {'n_estimators': 450, 'learning_rate': 0.015387580558590921, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:42,053] Trial 341 finished with value: 0.907952186382509 and parameters: {'n_estimators': 450, 'learning_rate': 0.01579359427033651, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:44,747] Trial 342 finished with value: 0.9063039184538395 and parameters: {'n_estimators': 450, 'learning_rate': 0.01313369920663816, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:47,439] Trial 343 finished with value: 0.9127477427001598 and parameters: {'n_estimators': 450, 'learning_rate': 0.01379673181926049, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:50,150] Trial 344 finished with value: 0.912816869461178 and parameters: {'n_estimators': 450, 'learning_rate': 0.011195442056241433, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:52,547] Trial 345 finished with value: 0.9091694711623877 and parameters: {'n_estimators': 400, 'learning_rate': 0.0170516170741891, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:55,263] Trial 346 finished with value: 0.9096590996060584 and parameters: {'n_estimators': 450, 'learning_rate': 0.01507629052286186, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:57,924] Trial 347 finished with value: 0.9096350931130571 and parameters: {'n_estimators': 450, 'learning_rate': 0.014254855694421443, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:00:59,761] Trial 348 finished with value: 0.906277069470678 and parameters: {'n_estimators': 400, 'learning_rate': 0.01645553365040487, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:02,047] Trial 349 finished with value: 0.9040280035028495 and parameters: {'n_estimators': 500, 'learning_rate': 0.012058319157961116, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:05,448] Trial 350 finished with value: 0.9077626014947924 and parameters: {'n_estimators': 450, 'learning_rate': 0.013561538480613138, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:07,525] Trial 351 finished with value: 0.9115305517216094 and parameters: {'n_estimators': 450, 'learning_rate': 0.016091373429753565, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:09,354] Trial 352 finished with value: 0.9008452349831867 and parameters: {'n_estimators': 400, 'learning_rate': 0.013163599734237835, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:12,334] Trial 353 finished with value: 0.9124490322750989 and parameters: {'n_estimators': 500, 'learning_rate': 0.014672640046488026, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:14,620] Trial 354 finished with value: 0.9081825676145006 and parameters: {'n_estimators': 500, 'learning_rate': 0.012981755465500509, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:15,556] Trial 355 finished with value: 0.8902162410538669 and parameters: {'n_estimators': 200, 'learning_rate': 0.016793899469505873, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:17,618] Trial 356 finished with value: 0.9089230507077095 and parameters: {'n_estimators': 450, 'learning_rate': 0.014907155786172188, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:19,715] Trial 357 finished with value: 0.9107099332629893 and parameters: {'n_estimators': 450, 'learning_rate': 0.026034546135249054, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:23,342] Trial 358 finished with value: 0.9059522392593877 and parameters: {'n_estimators': 500, 'learning_rate': 0.03972301927296047, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:25,738] Trial 359 finished with value: 0.9097499263961932 and parameters: {'n_estimators': 400, 'learning_rate': 0.02717325121937553, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:27,795] Trial 360 finished with value: 0.9100075588069305 and parameters: {'n_estimators': 450, 'learning_rate': 0.0253625395489351, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:30,071] Trial 361 finished with value: 0.9112783455001134 and parameters: {'n_estimators': 500, 'learning_rate': 0.028676519231890723, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:32,133] Trial 362 finished with value: 0.9101896438082671 and parameters: {'n_estimators': 450, 'learning_rate': 0.017896916809174077, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:33,385] Trial 363 finished with value: 0.9034903481851115 and parameters: {'n_estimators': 200, 'learning_rate': 0.012543419201980727, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:35,440] Trial 364 finished with value: 0.9048859215644448 and parameters: {'n_estimators': 450, 'learning_rate': 0.07788635417707328, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:36,150] Trial 365 finished with value: 0.9067983493506565 and parameters: {'n_estimators': 150, 'learning_rate': 0.04887039722731429, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:38,447] Trial 366 finished with value: 0.914275661077545 and parameters: {'n_estimators': 500, 'learning_rate': 0.021261723023009327, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:42,926] Trial 367 finished with value: 0.9045144690749229 and parameters: {'n_estimators': 500, 'learning_rate': 0.02091811183560136, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:45,895] Trial 368 finished with value: 0.9015096094105151 and parameters: {'n_estimators': 500, 'learning_rate': 0.021721876286802534, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:48,211] Trial 369 finished with value: 0.9103401791977734 and parameters: {'n_estimators': 500, 'learning_rate': 0.018232994216022626, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:50,500] Trial 370 finished with value: 0.9032413720434374 and parameters: {'n_estimators': 500, 'learning_rate': 0.020508125229433998, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:53,474] Trial 371 finished with value: 0.8984188226680387 and parameters: {'n_estimators': 500, 'learning_rate': 0.02388779193612795, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:55,759] Trial 372 finished with value: 0.910219311502465 and parameters: {'n_estimators': 500, 'learning_rate': 0.0188570421109753, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:58,043] Trial 373 finished with value: 0.9131747090909574 and parameters: {'n_estimators': 500, 'learning_rate': 0.01413517434358829, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:59,655] Trial 374 finished with value: 0.9023189513959735 and parameters: {'n_estimators': 350, 'learning_rate': 0.015401344393745763, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:01:59,989] Trial 375 finished with value: 0.90724683845495 and parameters: {'n_estimators': 50, 'learning_rate': 0.06368246945875418, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:02,053] Trial 376 finished with value: 0.9188823247173848 and parameters: {'n_estimators': 450, 'learning_rate': 0.022030993216311776, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:02,538] Trial 377 finished with value: 0.8881834837138349 and parameters: {'n_estimators': 100, 'learning_rate': 0.024069398197840288, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:05,222] Trial 378 finished with value: 0.9026991678809647 and parameters: {'n_estimators': 450, 'learning_rate': 0.0253897955424311, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:07,282] Trial 379 finished with value: 0.9121206911192505 and parameters: {'n_estimators': 450, 'learning_rate': 0.022640358672258807, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:09,337] Trial 380 finished with value: 0.9022745678715418 and parameters: {'n_estimators': 450, 'learning_rate': 0.011452626897451445, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:12,013] Trial 381 finished with value: 0.9069865219357757 and parameters: {'n_estimators': 450, 'learning_rate': 0.01963906953672155, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:13,868] Trial 382 finished with value: 0.9147670050616077 and parameters: {'n_estimators': 400, 'learning_rate': 0.022943868195673782, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:15,702] Trial 383 finished with value: 0.908251955412928 and parameters: {'n_estimators': 400, 'learning_rate': 0.02257676158066845, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:17,534] Trial 384 finished with value: 0.9081768346644097 and parameters: {'n_estimators': 400, 'learning_rate': 0.024304256180941976, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:19,908] Trial 385 finished with value: 0.9065680745249747 and parameters: {'n_estimators': 400, 'learning_rate': 0.021350160637959067, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:21,742] Trial 386 finished with value: 0.9162154482725967 and parameters: {'n_estimators': 400, 'learning_rate': 0.023025312039746167, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:23,578] Trial 387 finished with value: 0.9083315410607717 and parameters: {'n_estimators': 400, 'learning_rate': 0.022473604256632747, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:26,511] Trial 388 finished with value: 0.9161391313342919 and parameters: {'n_estimators': 400, 'learning_rate': 0.023249332357834353, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:29,447] Trial 389 finished with value: 0.9033021413775435 and parameters: {'n_estimators': 400, 'learning_rate': 0.02023695271302469, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:32,390] Trial 390 finished with value: 0.9105783432354201 and parameters: {'n_estimators': 400, 'learning_rate': 0.024591209747652304, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:34,792] Trial 391 finished with value: 0.9060368820979203 and parameters: {'n_estimators': 400, 'learning_rate': 0.016867019837428502, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:37,164] Trial 392 finished with value: 0.9168496814347415 and parameters: {'n_estimators': 400, 'learning_rate': 0.021463845869564967, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:39,555] Trial 393 finished with value: 0.9123752220430876 and parameters: {'n_estimators': 400, 'learning_rate': 0.02163211724885187, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:41,938] Trial 394 finished with value: 0.9115715971656979 and parameters: {'n_estimators': 400, 'learning_rate': 0.023615806354816703, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:44,873] Trial 395 finished with value: 0.9071645484286706 and parameters: {'n_estimators': 400, 'learning_rate': 0.02530286526181537, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:47,270] Trial 396 finished with value: 0.9070993549598378 and parameters: {'n_estimators': 400, 'learning_rate': 0.02212647811110179, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:49,650] Trial 397 finished with value: 0.908011977585123 and parameters: {'n_estimators': 400, 'learning_rate': 0.02386956206838174, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:52,043] Trial 398 finished with value: 0.907616740755939 and parameters: {'n_estimators': 400, 'learning_rate': 0.026116202114720717, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:54,148] Trial 399 finished with value: 0.9138768354370864 and parameters: {'n_estimators': 350, 'learning_rate': 0.020736446663062014, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:02:58,926] Trial 400 finished with value: 0.8943964894160352 and parameters: {'n_estimators': 450, 'learning_rate': 0.014011377273336886, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:01,301] Trial 401 finished with value: 0.9052203976911019 and parameters: {'n_estimators': 400, 'learning_rate': 0.025337310505522726, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:03,656] Trial 402 finished with value: 0.9109358129609534 and parameters: {'n_estimators': 400, 'learning_rate': 0.17383736310273176, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:06,340] Trial 403 finished with value: 0.9154372871467917 and parameters: {'n_estimators': 450, 'learning_rate': 0.022562225952847365, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:09,271] Trial 404 finished with value: 0.9109908668614066 and parameters: {'n_estimators': 400, 'learning_rate': 0.023173692224494523, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:11,960] Trial 405 finished with value: 0.9116058767744853 and parameters: {'n_estimators': 450, 'learning_rate': 0.021586479899877165, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:14,620] Trial 406 finished with value: 0.9078776029954685 and parameters: {'n_estimators': 450, 'learning_rate': 0.0198252769062141, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:16,701] Trial 407 finished with value: 0.9152486815001881 and parameters: {'n_estimators': 350, 'learning_rate': 0.02278615581533421, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:19,377] Trial 408 finished with value: 0.9056444413960513 and parameters: {'n_estimators': 450, 'learning_rate': 0.026747031865731203, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:21,214] Trial 409 finished with value: 0.9051426612839656 and parameters: {'n_estimators': 400, 'learning_rate': 0.0236513742060409, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:25,156] Trial 410 finished with value: 0.9025617657196605 and parameters: {'n_estimators': 450, 'learning_rate': 0.02483389782324859, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:27,218] Trial 411 finished with value: 0.9147790000187402 and parameters: {'n_estimators': 450, 'learning_rate': 0.019198241571843827, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:29,611] Trial 412 finished with value: 0.9187773506685863 and parameters: {'n_estimators': 400, 'learning_rate': 0.02123381812918545, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:31,980] Trial 413 finished with value: 0.9122946557621103 and parameters: {'n_estimators': 400, 'learning_rate': 0.022190616618497264, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:34,345] Trial 414 finished with value: 0.9138734620642517 and parameters: {'n_estimators': 400, 'learning_rate': 0.0215686797851211, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:36,720] Trial 415 finished with value: 0.9174115219357757 and parameters: {'n_estimators': 400, 'learning_rate': 0.0209776506934921, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:39,092] Trial 416 finished with value: 0.9066330052858168 and parameters: {'n_estimators': 400, 'learning_rate': 0.01883864239231333, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:42,033] Trial 417 finished with value: 0.9084008178391937 and parameters: {'n_estimators': 400, 'learning_rate': 0.02061298573325867, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:44,408] Trial 418 finished with value: 0.9033399051213007 and parameters: {'n_estimators': 400, 'learning_rate': 0.020503352850691544, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:46,808] Trial 419 finished with value: 0.9040492225852939 and parameters: {'n_estimators': 400, 'learning_rate': 0.0193602942913834, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:49,208] Trial 420 finished with value: 0.9013525176733562 and parameters: {'n_estimators': 400, 'learning_rate': 0.02405700342132908, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:51,583] Trial 421 finished with value: 0.9134905675977161 and parameters: {'n_estimators': 400, 'learning_rate': 0.01808732517245254, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:54,524] Trial 422 finished with value: 0.9083465396388046 and parameters: {'n_estimators': 400, 'learning_rate': 0.021009542433286156, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:56,904] Trial 423 finished with value: 0.9057172618385287 and parameters: {'n_estimators': 400, 'learning_rate': 0.02638543893615742, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:03:58,744] Trial 424 finished with value: 0.9150427249276113 and parameters: {'n_estimators': 400, 'learning_rate': 0.021934199444275947, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:01,113] Trial 425 finished with value: 0.9091771657485195 and parameters: {'n_estimators': 400, 'learning_rate': 0.02383513804519992, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:02,946] Trial 426 finished with value: 0.9112101013765569 and parameters: {'n_estimators': 400, 'learning_rate': 0.017284727197129562, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:05,607] Trial 427 finished with value: 0.9039111714556329 and parameters: {'n_estimators': 450, 'learning_rate': 0.020220722236653648, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:07,669] Trial 428 finished with value: 0.9133495614880737 and parameters: {'n_estimators': 450, 'learning_rate': 0.025292540947943563, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:09,503] Trial 429 finished with value: 0.9164304535392664 and parameters: {'n_estimators': 400, 'learning_rate': 0.02290997995111592, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:11,906] Trial 430 finished with value: 0.9137488184479141 and parameters: {'n_estimators': 400, 'learning_rate': 0.019167673169376218, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:13,739] Trial 431 finished with value: 0.9093725369535346 and parameters: {'n_estimators': 400, 'learning_rate': 0.021500262050933666, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:15,596] Trial 432 finished with value: 0.9076571817682535 and parameters: {'n_estimators': 400, 'learning_rate': 0.02301649938989143, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:17,967] Trial 433 finished with value: 0.9095545647452422 and parameters: {'n_estimators': 400, 'learning_rate': 0.020933911282978557, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:19,812] Trial 434 finished with value: 0.911936759900323 and parameters: {'n_estimators': 400, 'learning_rate': 0.022723480615535512, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:21,893] Trial 435 finished with value: 0.9057890907223888 and parameters: {'n_estimators': 350, 'learning_rate': 0.02739755248244171, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:23,733] Trial 436 finished with value: 0.9084492287655446 and parameters: {'n_estimators': 400, 'learning_rate': 0.018740157254827496, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:25,372] Trial 437 finished with value: 0.9104321266352124 and parameters: {'n_estimators': 350, 'learning_rate': 0.023826580035470665, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:28,347] Trial 438 finished with value: 0.9031608384135883 and parameters: {'n_estimators': 400, 'learning_rate': 0.020498923308831917, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:29,288] Trial 439 finished with value: 0.8911711596314348 and parameters: {'n_estimators': 200, 'learning_rate': 0.015470446289361638, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:30,001] Trial 440 finished with value: 0.8896360606119907 and parameters: {'n_estimators': 150, 'learning_rate': 0.022214778416609512, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:34,100] Trial 441 finished with value: 0.893731336214552 and parameters: {'n_estimators': 400, 'learning_rate': 0.026068958341423597, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:36,473] Trial 442 finished with value: 0.9093276030961039 and parameters: {'n_estimators': 400, 'learning_rate': 0.01629535766831772, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:38,314] Trial 443 finished with value: 0.9091799685757309 and parameters: {'n_estimators': 400, 'learning_rate': 0.017591725746302134, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:40,681] Trial 444 finished with value: 0.9078553401533238 and parameters: {'n_estimators': 400, 'learning_rate': 0.024156223921736733, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:42,514] Trial 445 finished with value: 0.908738253647735 and parameters: {'n_estimators': 400, 'learning_rate': 0.027525592804606838, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:44,351] Trial 446 finished with value: 0.9133243612956443 and parameters: {'n_estimators': 400, 'learning_rate': 0.019989316838423775, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:46,138] Trial 447 finished with value: 0.912039666825434 and parameters: {'n_estimators': 300, 'learning_rate': 0.022072151166205537, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:48,199] Trial 448 finished with value: 0.9095632693948517 and parameters: {'n_estimators': 450, 'learning_rate': 0.025653228297326323, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:50,294] Trial 449 finished with value: 0.9110458802978926 and parameters: {'n_estimators': 450, 'learning_rate': 0.021570218827564554, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:53,242] Trial 450 finished with value: 0.9112735175323141 and parameters: {'n_estimators': 500, 'learning_rate': 0.024972244753670065, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:56,242] Trial 451 finished with value: 0.9117969749548698 and parameters: {'n_estimators': 400, 'learning_rate': 0.02308799607438458, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:04:58,081] Trial 452 finished with value: 0.9065022464950789 and parameters: {'n_estimators': 400, 'learning_rate': 0.028676545643119368, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:01,037] Trial 453 finished with value: 0.9137980257113302 and parameters: {'n_estimators': 500, 'learning_rate': 0.01946507082870255, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:03,102] Trial 454 finished with value: 0.916061548250784 and parameters: {'n_estimators': 450, 'learning_rate': 0.023807704568704968, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:04,040] Trial 455 finished with value: 0.8957959430536582 and parameters: {'n_estimators': 200, 'learning_rate': 0.02339929648564828, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:06,430] Trial 456 finished with value: 0.9132437608014948 and parameters: {'n_estimators': 400, 'learning_rate': 0.0209989366024252, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:08,495] Trial 457 finished with value: 0.9080677552373577 and parameters: {'n_estimators': 450, 'learning_rate': 0.024288714910299537, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:10,778] Trial 458 finished with value: 0.9050815245913846 and parameters: {'n_estimators': 500, 'learning_rate': 0.022758345700200126, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:12,891] Trial 459 finished with value: 0.910869316640094 and parameters: {'n_estimators': 350, 'learning_rate': 0.012580570099806149, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:14,733] Trial 460 finished with value: 0.9055212134157701 and parameters: {'n_estimators': 400, 'learning_rate': 0.025911859142310853, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:17,397] Trial 461 finished with value: 0.9186859193438142 and parameters: {'n_estimators': 450, 'learning_rate': 0.021518101177116094, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:20,079] Trial 462 finished with value: 0.9138683983926523 and parameters: {'n_estimators': 450, 'learning_rate': 0.018872273079339627, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:22,758] Trial 463 finished with value: 0.9125852998951982 and parameters: {'n_estimators': 450, 'learning_rate': 0.020871427858251884, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:25,430] Trial 464 finished with value: 0.9062192684146172 and parameters: {'n_estimators': 450, 'learning_rate': 0.019818461376912466, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:28,100] Trial 465 finished with value: 0.9123200538194982 and parameters: {'n_estimators': 450, 'learning_rate': 0.02189929361771624, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:31,400] Trial 466 finished with value: 0.9140665967911079 and parameters: {'n_estimators': 450, 'learning_rate': 0.018362203890514087, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:34,089] Trial 467 finished with value: 0.9064832420215632 and parameters: {'n_estimators': 450, 'learning_rate': 0.021715460819978237, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:36,762] Trial 468 finished with value: 0.908067131543206 and parameters: {'n_estimators': 450, 'learning_rate': 0.02005899154521961, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:39,441] Trial 469 finished with value: 0.911417907135722 and parameters: {'n_estimators': 450, 'learning_rate': 0.017318220304261302, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:42,403] Trial 470 finished with value: 0.909093899147774 and parameters: {'n_estimators': 500, 'learning_rate': 0.023099970834388726, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:44,820] Trial 471 finished with value: 0.902457039945412 and parameters: {'n_estimators': 400, 'learning_rate': 0.021007498171040927, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:47,479] Trial 472 finished with value: 0.9096063496132569 and parameters: {'n_estimators': 450, 'learning_rate': 0.0237038292735807, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:49,865] Trial 473 finished with value: 0.9106897211163311 and parameters: {'n_estimators': 400, 'learning_rate': 0.016106897909407735, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:52,534] Trial 474 finished with value: 0.9068552395862797 and parameters: {'n_estimators': 450, 'learning_rate': 0.022098626433725416, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:54,820] Trial 475 finished with value: 0.9066593506094496 and parameters: {'n_estimators': 500, 'learning_rate': 0.010498849874293536, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:05:58,232] Trial 476 finished with value: 0.8981015829626907 and parameters: {'n_estimators': 450, 'learning_rate': 0.02461837313810396, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:00,102] Trial 477 finished with value: 0.914331581706721 and parameters: {'n_estimators': 400, 'learning_rate': 0.020313041607101425, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:03,069] Trial 478 finished with value: 0.9071924735110821 and parameters: {'n_estimators': 500, 'learning_rate': 0.01331341164731722, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:04,677] Trial 479 finished with value: 0.9087321637565537 and parameters: {'n_estimators': 350, 'learning_rate': 0.01792692907201033, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:08,735] Trial 480 finished with value: 0.9128238600239673 and parameters: {'n_estimators': 450, 'learning_rate': 0.014593331180090876, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:11,119] Trial 481 finished with value: 0.9070936952219395 and parameters: {'n_estimators': 400, 'learning_rate': 0.0229911312177291, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:13,177] Trial 482 finished with value: 0.9037012840045607 and parameters: {'n_estimators': 450, 'learning_rate': 0.0266766428712887, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:15,016] Trial 483 finished with value: 0.9049466665858169 and parameters: {'n_estimators': 400, 'learning_rate': 0.019298518985916165, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:17,980] Trial 484 finished with value: 0.9022026447298505 and parameters: {'n_estimators': 500, 'learning_rate': 0.02156031332536334, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:20,057] Trial 485 finished with value: 0.9117598140977451 and parameters: {'n_estimators': 450, 'learning_rate': 0.02429652838048072, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:21,897] Trial 486 finished with value: 0.914484284015818 and parameters: {'n_estimators': 400, 'learning_rate': 0.02262040745368413, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:23,140] Trial 487 finished with value: 0.9106334586466165 and parameters: {'n_estimators': 200, 'learning_rate': 0.024689815133839756, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:25,433] Trial 488 finished with value: 0.9070024670180455 and parameters: {'n_estimators': 500, 'learning_rate': 0.020934654045348944, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:28,779] Trial 489 finished with value: 0.9014603302313103 and parameters: {'n_estimators': 450, 'learning_rate': 0.025934759273806354, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:31,153] Trial 490 finished with value: 0.9018086108491022 and parameters: {'n_estimators': 400, 'learning_rate': 0.022868791440483482, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:31,866] Trial 491 finished with value: 0.8831728155373483 and parameters: {'n_estimators': 150, 'learning_rate': 0.015541010609981072, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:33,702] Trial 492 finished with value: 0.9160519724083965 and parameters: {'n_estimators': 400, 'learning_rate': 0.01944799747563016, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:36,075] Trial 493 finished with value: 0.9106758964501502 and parameters: {'n_estimators': 400, 'learning_rate': 0.020402284035006275, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:42,029] Trial 494 finished with value: 0.9044297010817786 and parameters: {'n_estimators': 400, 'learning_rate': 0.018315609386152464, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:46,865] Trial 495 finished with value: 0.9012491820378228 and parameters: {'n_estimators': 400, 'learning_rate': 0.01160769198391623, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:48,709] Trial 496 finished with value: 0.9189425834702188 and parameters: {'n_estimators': 400, 'learning_rate': 0.01943094893877719, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:50,574] Trial 497 finished with value: 0.9052996224663319 and parameters: {'n_estimators': 400, 'learning_rate': 0.01904992664300917, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:52,409] Trial 498 finished with value: 0.9079094233423433 and parameters: {'n_estimators': 400, 'learning_rate': 0.02127961904950361, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n",
      "[I 2025-03-17 09:06:54,496] Trial 499 finished with value: 0.907956347427912 and parameters: {'n_estimators': 350, 'learning_rate': 0.023267223847580627, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 277 with value: 0.9220933035533637.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 450, 'learning_rate': 0.023948831838671292, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 2}\n",
      "SMOTE: Original Fall count: 328, Augmented Fall count: 688\n",
      "SMOTE: Original No Fall count: 688, Augmented No Fall count: 688\n",
      "Model trained with accuracy: 0.9528\n",
      "Precision: 0.9375, Recall: 0.9146, F1-score: 0.9259, ROC-AUC: 0.9885\n",
      "Confusion Matrix:\n",
      "[[167   7]\n",
      " [  5  75]]\n",
      "Activity: CD, X shape: (4, 5), y shape: (4,)\n",
      "Activity CD: 4 correct, 0 incorrect\n",
      "Activity: FCF, X shape: (12, 5), y shape: (12,)\n",
      "Activity FCF: 11 correct, 1 incorrect\n",
      "Activity: FCS, X shape: (10, 5), y shape: (10,)\n",
      "Activity FCS: 7 correct, 3 incorrect\n",
      "Activity: FOB, X shape: (12, 5), y shape: (12,)\n",
      "Activity FOB: 12 correct, 0 incorrect\n",
      "Activity: FOL, X shape: (12, 5), y shape: (12,)\n",
      "Activity FOL: 12 correct, 0 incorrect\n",
      "Activity: FR, X shape: (12, 5), y shape: (12,)\n",
      "Activity FR: 9 correct, 3 incorrect\n",
      "Activity: K, X shape: (24, 5), y shape: (24,)\n",
      "Activity K: 23 correct, 1 incorrect\n",
      "Activity: KD, X shape: (2, 5), y shape: (2,)\n",
      "Activity KD: 2 correct, 0 incorrect\n",
      "Activity: KID, X shape: (4, 5), y shape: (4,)\n",
      "Activity KID: 4 correct, 0 incorrect\n",
      "Activity: LAF, X shape: (12, 5), y shape: (12,)\n",
      "Activity LAF: 9 correct, 3 incorrect\n",
      "Activity: LC, X shape: (12, 5), y shape: (12,)\n",
      "Activity LC: 12 correct, 0 incorrect\n",
      "Activity: LSF, X shape: (12, 5), y shape: (12,)\n",
      "Activity LSF: 12 correct, 0 incorrect\n",
      "Activity: MA, X shape: (9, 5), y shape: (9,)\n",
      "Activity MA: 9 correct, 0 incorrect\n",
      "Activity: PUF, X shape: (12, 5), y shape: (12,)\n",
      "Activity PUF: 12 correct, 0 incorrect\n",
      "Activity: RBS, X shape: (18, 5), y shape: (18,)\n",
      "Activity RBS: 17 correct, 1 incorrect\n",
      "Activity: S, X shape: (9, 5), y shape: (9,)\n",
      "Activity S: 9 correct, 0 incorrect\n",
      "Activity: SC, X shape: (12, 5), y shape: (12,)\n",
      "Activity SC: 12 correct, 0 incorrect\n",
      "Activity: SFB, X shape: (12, 5), y shape: (12,)\n",
      "Activity SFB: 12 correct, 0 incorrect\n",
      "Activity: SLB, X shape: (12, 5), y shape: (12,)\n",
      "Activity SLB: 12 correct, 0 incorrect\n",
      "Activity: STC, X shape: (12, 5), y shape: (12,)\n",
      "Activity STC: 12 correct, 0 incorrect\n",
      "Activity: TF, X shape: (12, 5), y shape: (12,)\n",
      "Activity TF: 12 correct, 0 incorrect\n",
      "Activity: WBS, X shape: (18, 5), y shape: (18,)\n",
      "Activity WBS: 18 correct, 0 incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Per-Activity Results:\n",
      "                               activity Actual Fall  correct  incorrect  \\\n",
      "0                            Close Door     No Fall        4          0   \n",
      "1                 Chair - Fall to Front        Fall       11          1   \n",
      "2                  Chair - Fall to side        Fall        7          3   \n",
      "3             Fall of object (Backpack)     No Fall       12          0   \n",
      "4         Fall of object (FaszienRolle)     No Fall       12          0   \n",
      "5                         Fall Recovery     No Fall        9          3   \n",
      "6        Kneeling down then standing up     No Fall       23          1   \n",
      "7                            Knock Door     No Fall        2          0   \n",
      "8                          Kids Running     No Fall        4          0   \n",
      "9                    Lying - Awake Fall        Fall        9          3   \n",
      "10                 Laying down on couch     No Fall       12          0   \n",
      "11                  Lying - Asleep Fall        Fall       12          0   \n",
      "12  Minor Ambience (Sitting and Eating)     No Fall        9          0   \n",
      "13      Picking something up from floor     No Fall       12          0   \n",
      "14                       Rush by Sensor     No Fall       17          1   \n",
      "15                                Still     No Fall        9          0   \n",
      "16                Sitting down on chair     No Fall       12          0   \n",
      "17            Slip and Fall - Backwards        Fall       12          0   \n",
      "18                Standing Lost Balance        Fall       12          0   \n",
      "19                  Stand up from Chair     No Fall       12          0   \n",
      "20             Trip and Fall - Forwards        Fall       12          0   \n",
      "21                       Walk by Sensor     No Fall       18          0   \n",
      "\n",
      "    total  accuracy  \n",
      "0       4  1.000000  \n",
      "1      12  0.916667  \n",
      "2      10  0.700000  \n",
      "3      12  1.000000  \n",
      "4      12  1.000000  \n",
      "5      12  0.750000  \n",
      "6      24  0.958333  \n",
      "7       2  1.000000  \n",
      "8       4  1.000000  \n",
      "9      12  0.750000  \n",
      "10     12  1.000000  \n",
      "11     12  1.000000  \n",
      "12      9  1.000000  \n",
      "13     12  1.000000  \n",
      "14     18  0.944444  \n",
      "15      9  1.000000  \n",
      "16     12  1.000000  \n",
      "17     12  1.000000  \n",
      "18     12  1.000000  \n",
      "19     12  1.000000  \n",
      "20     12  1.000000  \n",
      "21     18  1.000000  \n",
      "Distance: 0, X shape: (13, 5), y shape: (13,)\n",
      "Distance 0: 13 correct, 0 incorrect\n",
      "Distance: 1, X shape: (64, 5), y shape: (64,)\n",
      "Distance 1: 62 correct, 2 incorrect\n",
      "Distance: 2, X shape: (92, 5), y shape: (92,)\n",
      "Distance 2: 87 correct, 5 incorrect\n",
      "Distance: 3, X shape: (85, 5), y shape: (85,)\n",
      "Distance 3: 80 correct, 5 incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Per-Distance Results:\n",
      "   distance  correct  incorrect  total  accuracy\n",
      "0         0       13          0     13  1.000000\n",
      "1         1       62          2     64  0.968750\n",
      "2         2       87          5     92  0.945652\n",
      "3         3       80          5     85  0.941176\n",
      "🏃 View run sweet_nerve_2qj20l07 at: https://northeurope.api.azureml.ms/mlflow/v2.0/subscriptions/716d3e14-e009-4f92-89c9-01fa8347272a/resourceGroups/adda23ac-rg/providers/Microsoft.MachineLearningServices/workspaces/fall/#/experiments/d26258ba-da47-4538-9d29-dc17a3480b45/runs/315dae46-6507-4da2-a8a6-ce77543d4d29\n",
      "🧪 View experiment at: https://northeurope.api.azureml.ms/mlflow/v2.0/subscriptions/716d3e14-e009-4f92-89c9-01fa8347272a/resourceGroups/adda23ac-rg/providers/Microsoft.MachineLearningServices/workspaces/fall/#/experiments/d26258ba-da47-4538-9d29-dc17a3480b45\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trained_model = train_pipe(\n",
    "    model=model,\n",
    "    dataset_name=\"MPU_features.csv\",\n",
    "    save_name=\"MF_VIF_SMO_GBM_KFoldOptuna_Final\",\n",
    "    feature_columns=[\"median\", \"max\", \"mean\", \"p2p\", \"impulse\"],\n",
    "    target_column=\"fall_binary\",\n",
    "    experiment_name=\"Classic Models MPU\",\n",
    "    use_early_stopping=False,\n",
    "    if_optuna=True,\n",
    "    n_trials=500,\n",
    "    augment_data=\"SMOTE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model does not support feature importance.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Usage (after training a model)\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mplot_feature_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmedian\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mp2p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimpulse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 14\u001b[0m, in \u001b[0;36mplot_feature_importance\u001b[0;34m(model, feature_columns)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_importances_\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# Ensure model supports feature importance\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     importances \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[0;32m---> 14\u001b[0m     feature_importance_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFeature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mImportance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimportances\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     feature_importance_df \u001b[38;5;241m=\u001b[39m feature_importance_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[0;32m~/Desktop/Master These/master/.venv/lib/python3.10/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/Desktop/Master These/master/.venv/lib/python3.10/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Master These/master/.venv/lib/python3.10/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/Desktop/Master These/master/.venv/lib/python3.10/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "def plot_feature_importance(model, feature_columns):\n",
    "    \"\"\"\n",
    "    Plots feature importance for tree-based models.\n",
    "\n",
    "    Args:\n",
    "        model: Trained XGBoost, RandomForest, or GradientBoosting model.\n",
    "        feature_columns: List of feature names.\n",
    "\n",
    "    Returns:\n",
    "        None (Displays feature importance plot)\n",
    "    \"\"\"\n",
    "    if hasattr(model, \"feature_importances_\"):  # Ensure model supports feature importance\n",
    "        importances = model.feature_importances_\n",
    "        feature_importance_df = pd.DataFrame({\"Feature\": feature_columns, \"Importance\": importances})\n",
    "        feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.barplot(x=\"Importance\", y=\"Feature\", data=feature_importance_df[:15])  # Top 15 features\n",
    "        plt.title(\"Feature Importance\")\n",
    "        plt.show()\n",
    "\n",
    "        return feature_importance_df\n",
    "    else:\n",
    "        raise ValueError(\"This model does not support feature importance.\")\n",
    "\n",
    "# Usage (after training a model)\n",
    "plot_feature_importance(trained_model, [\"median\", \"max\", \"mean\", \"p2p\", \"impulse\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def ensemble_predict(models_with_features, dataset_name, target_column):\n",
    "    \"\"\"\n",
    "    Loads a dataset, splits it, loads an ensemble of models (with different feature sets),\n",
    "    and predicts on the test set.\n",
    "\n",
    "    Args:\n",
    "        models_with_features: A list of tuples (model_path, feature_columns) specifying each model's file path\n",
    "                              and the corresponding feature columns used for training.\n",
    "        dataset_name: The name of the dataset CSV file.\n",
    "        target_column: The name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    # ✅ Load dataset\n",
    "    df = load_data(dataset_name)\n",
    "\n",
    "    # ✅ Ensure target column exists\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' not found in dataset.\")\n",
    "\n",
    "    # ✅ Train-test split\n",
    "    data_train, data_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    y_test = data_test[target_column].values  # Target remains the same for all models\n",
    "\n",
    "    # ✅ Load models and their feature columns\n",
    "    models = []\n",
    "    y_preds = []\n",
    "\n",
    "    for model_path, feature_columns in models_with_features:\n",
    "        model = joblib.load(model_path)  # Load model\n",
    "        models.append(model)\n",
    "\n",
    "        # ✅ Extract the correct feature set for this model\n",
    "        X_test = data_test[feature_columns].values  # Select only the features it was trained on\n",
    "\n",
    "        # ✅ Predict (check if the model has `predict_proba` for probability averaging)\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]  # Get probability of the positive class\n",
    "        else:\n",
    "            y_pred_proba = model.predict(X_test)  # Some models might not have `predict_proba`\n",
    "\n",
    "        y_preds.append(y_pred_proba)\n",
    "\n",
    "    # ✅ Ensemble predictions (Average probabilities and threshold at 0.5)\n",
    "    y_pred = np.mean(y_preds, axis=0) > 0.5\n",
    "\n",
    "    # ✅ Compute metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    # ✅ Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # ✅ Print metrics\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    # ✅ Plot confusion matrix\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=[\"No Fall\", \"Fall\"], yticklabels=[\"No Fall\", \"Fall\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9764\n",
      "Precision: 0.9615\n",
      "Recall: 0.9615\n",
      "F1 Score: 0.9615\n",
      "ROC AUC: 0.9722\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ensemble_predict(\n",
    "    models_with_features=[\n",
    "        (\"models/MF_XGB_Optuna.pkl\", [\"max\", \"min\", \"mean\", \"std\", \"median\", \"peak\", \"p2p\", \"energy\", \"rms\", \"crest\", \"shape\", \"impulse\", \"margin\"]),  \n",
    "        (\"models/MF_XGB_RD40_Optuna.pkl\", [\"median\", \"max\", \"peak\", \"mean\", \"p2p\"]),\n",
    "        (\"models/MF_XGB_RD41_Optuna.pkl\", [\"median\", \"max\", \"peak\", \"mean\", \"p2p\"])    \n",
    "    ],\n",
    "    dataset_name=\"MPU_features_pca.csv\",\n",
    "    target_column=\"fall_binary\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
