{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "\n",
    "# Data Handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning & Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "import optuna\n",
    "\n",
    "# Model Saving & Experiment Tracking\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow ui --port 5000\n"
     ]
    }
   ],
   "source": [
    "print(\"mlflow ui --port 5000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACKING_URI = \"azureml://northeurope.api.azureml.ms/mlflow/v1.0/subscriptions/716d3e14-e009-4f92-89c9-01fa8347272a/resourceGroups/adda23ac-rg/providers/Microsoft.MachineLearningServices/workspaces/fall\"\n",
    "mlflow.set_tracking_uri(TRACKING_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    '''\n",
    "    Load data from a csv file into a pandas dataframe.\n",
    "    \n",
    "    Args:\n",
    "    file_name: The name of the csv file to load\n",
    "    \n",
    "    Returns:\n",
    "    df: A pandas dataframe containing the data from the csv file\n",
    "    '''\n",
    "    folder = \"datasets\"\n",
    "\n",
    "    df = pd.read_csv(f\"{folder}/{file_name}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratify Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_activity_split(df, target_column=\"fall_binary\", test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the dataset while ensuring 20% of each 'activity' is in the test set.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The full dataset containing 'activity' and the target variable.\n",
    "        target_column (str): The column representing the target labels.\n",
    "        test_size (float): The fraction of each activity to be in the test set.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        data_train (pd.DataFrame): Training set.\n",
    "        data_test (pd.DataFrame): Test set.\n",
    "    \"\"\"\n",
    "\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "\n",
    "    # âœ… Loop through each activity and apply train-test split\n",
    "    for activity, group in df.groupby(\"activity\"):\n",
    "        train, test = train_test_split(group, test_size=test_size, random_state=random_state, stratify=group[target_column])\n",
    "        train_list.append(train)\n",
    "        test_list.append(test)\n",
    "\n",
    "    # âœ… Concatenate results into train & test datasets\n",
    "    data_train = pd.concat(train_list).reset_index(drop=True)\n",
    "    data_test = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "    return data_train, data_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Per Activity / Distance Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_per_activity(model, test_X, test_y, feature_columns=None):\n",
    "    \"\"\"\n",
    "    Evaluates model performance per activity type and logs the results in MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model (LSTM or Tree-based).\n",
    "        test_X: Test feature data (DataFrame).\n",
    "        test_y: Test target labels (Series).\n",
    "        target_column: The name of the target column.\n",
    "        feature_columns: The feature columns used for training.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame containing classification results per activity.\n",
    "    \"\"\"\n",
    "    \n",
    "    # âœ… Ensure X_test is a DataFrame\n",
    "    if not isinstance(test_X, pd.DataFrame):\n",
    "        test_X = pd.DataFrame(test_X, columns=feature_columns)\n",
    "\n",
    "    # âœ… Ensure y_test is a Series\n",
    "    if isinstance(test_y, pd.DataFrame):\n",
    "        test_y = test_y.squeeze()  # Convert to Series if needed\n",
    "\n",
    "    # âœ… Ensure 'activity' column exists\n",
    "    if \"activity\" not in test_X.columns:\n",
    "        raise ValueError(\"Dataset does not contain an 'activity' column.\")\n",
    "\n",
    "    is_lstm = isinstance(model, tf.keras.Model)\n",
    "    results = []\n",
    "\n",
    "    # âœ… Loop through each unique activity and evaluate model performance\n",
    "    for activity in test_X[\"activity\"].unique():\n",
    "        # Filter test data for the current activity\n",
    "        X_test_activity = test_X[test_X[\"activity\"] == activity].copy()\n",
    "\n",
    "        # Extract the actual labels\n",
    "        y_test_activity = test_y.loc[X_test_activity.index].values.flatten()  # Ensure correct shape\n",
    "\n",
    "        # âœ… Check for missing values\n",
    "        if np.isnan(y_test_activity).any():\n",
    "            print(f\"Warning: NaN values found in y_test_activity for activity {activity}!\")\n",
    "            y_test_activity = np.nan_to_num(y_test_activity, nan=0)  # Replace NaN with 0 (No Fall)\n",
    "\n",
    "        # âœ… Ensure y_test_activity is integer\n",
    "        try:\n",
    "            y_test_activity = y_test_activity.astype(int)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error converting y_test_activity to integer for activity {activity}: {e}\")\n",
    "            continue  # Skip this activity if conversion fails\n",
    "\n",
    "        # âœ… Select feature columns\n",
    "        if is_lstm:\n",
    "            feature_columns = [col for col in X_test_activity.columns if col.startswith(\"value\")]\n",
    "\n",
    "        X_test_activity = X_test_activity[feature_columns].values  # Extract feature values\n",
    "\n",
    "        print(f\"Activity: {activity}, X shape: {X_test_activity.shape}, y shape: {y_test_activity.shape}\")\n",
    "\n",
    "        # âœ… Reshape X for LSTM input\n",
    "        if is_lstm:\n",
    "            X_test_activity = X_test_activity.reshape(-1, 500, 1)\n",
    "\n",
    "        # âœ… Predict fall_binary values\n",
    "        y_pred = model.predict(X_test_activity).round().astype(int).flatten()\n",
    "\n",
    "        # âœ… Compute correct and incorrect counts\n",
    "        correct = np.sum(y_pred == y_test_activity)\n",
    "        incorrect = len(y_pred) - correct\n",
    "\n",
    "        # âœ… Determine if the first sample of the activity is a fall or not\n",
    "        actual_fall = \"Fall\" if y_test_activity[0] == 1 else \"No Fall\"\n",
    "\n",
    "        print(f\"Activity {activity}: {correct} correct, {incorrect} incorrect\")\n",
    "\n",
    "        # âœ… Store results\n",
    "        results.append({\n",
    "            \"activity\": activity,\n",
    "            \"Actual Fall\": actual_fall,  # âœ… Single column for actual fall status\n",
    "            \"correct\": correct,\n",
    "            \"incorrect\": incorrect,\n",
    "            \"total\": len(y_pred),\n",
    "            \"accuracy\": correct / len(y_pred) if len(y_pred) > 0 else 0\n",
    "        })\n",
    "\n",
    "    # âœ… Convert results into a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # âœ… Mapping dictionary from abbreviations to full names\n",
    "    activity_mapping = {\n",
    "        \"S\": \"Still\",\n",
    "        \"CD\": \"Close Door\",\n",
    "        \"KD\": \"Knock Door\",\n",
    "        \"MA\": \"Minor Ambience (Sitting and Eating)\",\n",
    "        \"FOB\": \"Fall of object (Backpack)\",\n",
    "        \"FOL\": \"Fall of object (FaszienRolle)\",\n",
    "        \"WBS\": \"Walk by Sensor\",\n",
    "        \"RBS\": \"Rush by Sensor\",\n",
    "        \"SC\": \"Sitting down on chair\",\n",
    "        \"LC\": \"Laying down on couch\",\n",
    "        \"STC\": \"Stand up from Chair\",\n",
    "        \"PUF\": \"Picking something up from floor\",\n",
    "        \"K\": \"Kneeling down then standing up\",\n",
    "        \"SLB\": \"Standing Lost Balance\",\n",
    "        \"TF\": \"Trip and Fall - Forwards\",\n",
    "        \"SFB\": \"Slip and Fall - Backwards\",\n",
    "        \"FCS\": \"Chair - Fall to side\",\n",
    "        \"FCF\": \"Chair - Fall to Front\",\n",
    "        \"LAF\": \"Lying - Awake Fall\",\n",
    "        \"LSF\": \"Lying - Asleep Fall\",\n",
    "        \"FR\": \"Fall Recovery\",\n",
    "        \"KID\": \"Kids Running\"\n",
    "    }\n",
    "\n",
    "    # âœ… Function to extract the relevant part before the first '_'\n",
    "    def get_activity_name(code):\n",
    "        key = code.split('_')[0]  # Extract first part of activity code\n",
    "        return activity_mapping.get(key, code)  # Replace with full name if exists\n",
    "\n",
    "    # âœ… Apply the mapping to the results dataframe\n",
    "    results_df[\"activity\"] = results_df[\"activity\"].apply(get_activity_name)\n",
    "\n",
    "    # âœ… Save the results as a CSV file\n",
    "    results_path = \"activity_results.csv\"\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "\n",
    "    # âœ… Log results in MLflow\n",
    "    mlflow.log_artifact(results_path)\n",
    "\n",
    "    print(\"\\nðŸ“Š Per-Activity Results:\")\n",
    "    print(results_df)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_per_distance(model, test_X, test_y, feature_columns=None):\n",
    "    \"\"\"\n",
    "    Evaluates model performance per distance type and logs the results in MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model (LSTM or Tree-based).\n",
    "        test_X: Test feature data (DataFrame).\n",
    "        test_y: Test target labels (Series).\n",
    "        feature_columns: The feature columns used for training.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame containing classification results per distance.\n",
    "    \"\"\"\n",
    "\n",
    "    X_test = test_X.copy()\n",
    "    y_test = test_y.copy()\n",
    "\n",
    "    # âœ… Ensure X_test is a DataFrame\n",
    "    if not isinstance(X_test, pd.DataFrame):\n",
    "        X_test = pd.DataFrame(X_test, columns=feature_columns)\n",
    "\n",
    "    # âœ… Ensure y_test is a Series\n",
    "    if isinstance(y_test, pd.DataFrame):\n",
    "        y_test = y_test.squeeze()  # Convert to Series if needed\n",
    "\n",
    "    is_lstm = isinstance(model, tf.keras.Model)\n",
    "\n",
    "    # âœ… Ensure 'distance_m' column exists\n",
    "    if \"distance_m\" not in X_test.columns:\n",
    "        raise ValueError(\"Dataset does not contain a 'distance_m' column.\")\n",
    "\n",
    "    # âœ… Get unique distances and setup subplots dynamically\n",
    "    unique_distances = sorted(X_test[\"distance_m\"].unique())\n",
    "    fig, axes = plt.subplots(len(unique_distances), 1, figsize=(6, 4 * len(unique_distances))) \n",
    "\n",
    "    results = []\n",
    "    confusion_matrices = {}\n",
    "\n",
    "    # âœ… Loop through each unique distance and evaluate model performance\n",
    "    for i, distance in enumerate(unique_distances):\n",
    "        X_test_distance = X_test[X_test[\"distance_m\"] == distance].copy()\n",
    "        y_test_distance = y_test.loc[X_test_distance.index].values.flatten()  # Ensure correct shape\n",
    "\n",
    "        # âœ… Select feature columns\n",
    "        if is_lstm:\n",
    "            feature_columns = [col for col in X_test_distance.columns if col.startswith(\"value\")]\n",
    "\n",
    "        X_test_distance = X_test_distance[feature_columns].values  # Extract feature values\n",
    "\n",
    "        print(f\"Distance: {distance}, X shape: {X_test_distance.shape}, y shape: {y_test_distance.shape}\")\n",
    "\n",
    "        # âœ… Reshape X for LSTM input\n",
    "        if is_lstm:\n",
    "            X_test_distance = X_test_distance.reshape(-1, 500, 1)\n",
    "\n",
    "        # âœ… Predict fall_binary values\n",
    "        y_pred = model.predict(X_test_distance).round().astype(int).flatten()\n",
    "\n",
    "        # âœ… Compute correct and incorrect counts\n",
    "        correct = np.sum(y_pred == y_test_distance)\n",
    "        incorrect = len(y_pred) - correct\n",
    "\n",
    "        # âœ… Compute confusion matrix, ensuring both classes appear\n",
    "        cm = confusion_matrix(y_test_distance, y_pred, labels=[1, 0])\n",
    "\n",
    "        # âœ… Ensure confusion matrix always has shape (2,2)\n",
    "        if cm.shape == (1, 1):  \n",
    "            cm_fixed = np.array([[cm[0, 0], 0], [0, 0]])  \n",
    "        elif cm.shape == (1, 2):  \n",
    "            cm_fixed = np.vstack([cm, [0, 0]])  \n",
    "        elif cm.shape == (2, 1):  \n",
    "            cm_fixed = np.hstack([cm, [[0], [0]]])  \n",
    "        else:\n",
    "            cm_fixed = cm  \n",
    "\n",
    "        # âœ… Correct confusion matrix order:\n",
    "        # TP | FN\n",
    "        # FP | TN\n",
    "        cm_corrected = np.array([\n",
    "            [cm_fixed[0, 0], cm_fixed[1, 0]],  # True Positives, False Negatives\n",
    "            [cm_fixed[0, 1], cm_fixed[1, 1]]   # False Positives, True Negatives\n",
    "        ])\n",
    "\n",
    "        confusion_matrices[distance] = cm_corrected\n",
    "\n",
    "        # âœ… Plot confusion matrix with **correct** labels\n",
    "        sns.heatmap(cm_corrected, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=[\"Actual Fall\", \"Actual No Fall\"], \n",
    "                    yticklabels=[\"Predicted Fall\", \"Predicted No Fall\"],\n",
    "                    ax=axes[i] if len(unique_distances) > 1 else axes)\n",
    "        axes[i].set_title(f\"Confusion Matrix - Distance {distance}\")\n",
    "        axes[i].set_xlabel(\" \")\n",
    "        axes[i].set_ylabel(\" \")\n",
    "\n",
    "        print(f\"Distance {distance}: {correct} correct, {incorrect} incorrect\")\n",
    "\n",
    "        # âœ… Store results\n",
    "        results.append({\n",
    "            \"distance\": distance,\n",
    "            \"correct\": correct,\n",
    "            \"incorrect\": incorrect,\n",
    "            \"total\": len(y_pred),\n",
    "            \"accuracy\": correct / len(y_pred) if len(y_pred) > 0 else 0\n",
    "        })\n",
    "\n",
    "    # âœ… Save and log confusion matrix plot\n",
    "    confusion_matrix_path = \"confusion_matrices_distance.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(confusion_matrix_path)\n",
    "    plt.close()\n",
    "\n",
    "    # âœ… Convert results into a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # âœ… Save results as CSV\n",
    "    results_path = \"distance_results.csv\"\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "\n",
    "    # âœ… Log results in MLflow\n",
    "    mlflow.log_artifact(results_path)\n",
    "    mlflow.log_artifact(confusion_matrix_path)\n",
    "\n",
    "    print(\"\\nðŸ“Š Per-Distance Results:\")\n",
    "    print(results_df)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classical Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, model_class, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Defines the Optuna optimization objective with K-Fold Cross-Validation.\n",
    "    \n",
    "    Args:\n",
    "        trial: Optuna trial object.\n",
    "        model_class: The model class (e.g., XGBClassifier, RandomForestClassifier, GradientBoostingClassifier, SVC).\n",
    "        X_train, y_train: Training data (without separate test split).\n",
    "\n",
    "    Returns:\n",
    "        The average F1-score across all folds.\n",
    "    \"\"\"\n",
    "\n",
    "    # Suggest hyperparameters based on model type\n",
    "    if model_class == XGBClassifier:\n",
    "        num_no_falls = sum(y_train == 0)\n",
    "        num_falls = sum(y_train == 1)\n",
    "        default_scale_pos_weight = num_no_falls / num_falls\n",
    "\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0, 10),\n",
    "            \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", default_scale_pos_weight * 0.5, default_scale_pos_weight * 1.5)\n",
    "        }\n",
    "        model = XGBClassifier(**params, objective=\"binary:logistic\", random_state=42)\n",
    "\n",
    "    elif model_class == RandomForestClassifier:\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        }\n",
    "        model = RandomForestClassifier(**params, random_state=42)\n",
    "\n",
    "    elif model_class == GradientBoostingClassifier:\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        }\n",
    "        model = GradientBoostingClassifier(**params, random_state=42)\n",
    "\n",
    "    elif model_class == SVC:\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.1, 100, log=True),\n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"]),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0.001, 10, log=True),\n",
    "        }\n",
    "        model = SVC(**params, probability=True, random_state=42)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model class: {model_class.__name__}\")\n",
    "\n",
    "    # K-Fold Cross-Validation (Stratified to preserve class balance)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    f1_scores = []\n",
    "\n",
    "    ## Loop through each fold\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]  \n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        ## Train and evaluate the model\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "        y_pred = model.predict(X_fold_val)\n",
    "        f1_scores.append(f1_score(y_fold_val, y_pred))\n",
    "\n",
    "    ## Return average F1-score across folds\n",
    "    return np.mean(f1_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_log_classical_model(\n",
    "    model, \n",
    "    X_train, X_test, y_train, y_test, X_test_full,\n",
    "    save_name=\"classification_model\", \n",
    "    experiment_name=\"classical_models_experiment\",\n",
    "    target_column=\"fall_binary\",\n",
    "    feature_columns=None,\n",
    "    if_optuna=True,\n",
    "    n_trials=250,  # Number of hyperparameter tuning trials\n",
    "    dataset_name = \"fall_data.csv\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains a classical ML model (RandomForest, XGBoost, GradientBoosting, or SVM) with optional hyperparameter tuning\n",
    "    and logs everything to MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: A classical ML model (RandomForest, XGBoost, GradientBoosting, or SVM).\n",
    "        X_train, X_test, y_train, y_test: Pre-split training and testing datasets.\n",
    "        save_name: Name to save the trained model.\n",
    "        experiment_name: Name of the MLflow experiment.\n",
    "        n_trials: Number of hyperparameter tuning trials.\n",
    "\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Start MLflow experiment\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        # Identify model class\n",
    "        model_class = type(model)\n",
    "\n",
    "        if if_optuna:\n",
    "            # âœ… Perform hyperparameter optimization\n",
    "            study = optuna.create_study(direction=\"maximize\")\n",
    "            study.optimize(lambda trial: objective(trial, model_class, X_train, y_train), n_trials=n_trials)\n",
    "        \n",
    "            best_params = study.best_params\n",
    "            print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "            # âœ… Train final model with best params\n",
    "            if model_class == XGBClassifier:\n",
    "                best_model = XGBClassifier(**best_params, objective=\"binary:logistic\", use_label_encoder=False)\n",
    "            elif model_class.__name__ == \"GradientBoostingClassifier\":\n",
    "                best_model = model_class(**best_params, random_state=42)\n",
    "            elif model_class.__name__ == \"RandomForestClassifier\":\n",
    "                best_model = model_class(**best_params, random_state=42)\n",
    "            elif model_class == SVC:\n",
    "                best_model = SVC(**best_params, probability=True, random_state=42)  # âœ… Enable probability for ROC AUC\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported model class: {model_class.__name__}\")\n",
    "        else:\n",
    "            best_model = model\n",
    "\n",
    "        best_model.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "        # SVM needs probability predictions for AUC\n",
    "        if hasattr(best_model, \"predict_proba\"):\n",
    "            roc_auc = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "        # âœ… Log model parameters\n",
    "        mlflow.log_param(\"model_type\", best_model.__class__.__name__)\n",
    "        if if_optuna:\n",
    "            for param, value in best_params.items():\n",
    "                mlflow.log_param(param, value)\n",
    "        mlflow.log_param(\"num_features\", X_train.shape[1])\n",
    "\n",
    "        # Log features used for training as list\n",
    "        if feature_columns is not None:\n",
    "            mlflow.log_param(\"features\", feature_columns)\n",
    "        \n",
    "        # Log target column\n",
    "        mlflow.log_param(\"target_column\", target_column)\n",
    "        \n",
    "        mlflow.log_param(\"dataset\", dataset_name)\n",
    "            \n",
    "        # âœ… Log metrics\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "        # âœ… Save best model\n",
    "        models_folder = \"models\"\n",
    "        if not os.path.exists(models_folder):\n",
    "            os.makedirs(models_folder)\n",
    "        save_path = os.path.join(models_folder, f\"{save_name}.pkl\")\n",
    "        joblib.dump(best_model, save_path)\n",
    "        mlflow.log_artifact(save_path)\n",
    "\n",
    "        # Generate and save confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        conf_matrix = np.array([\n",
    "            [conf_matrix[0, 0], conf_matrix[1, 0]],  # True Positives, False Positives\n",
    "            [conf_matrix[0, 1], conf_matrix[1, 1]]   # False Negatives, True Negatives\n",
    "        ])\n",
    "\n",
    "        # Flip the order of labels for visualization\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(\n",
    "            conf_matrix[::-1, ::-1],  # Reverse rows and keep columns the same\n",
    "            annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Actual Fall\", \"Actual No Fall\"], \n",
    "            yticklabels=[\"Predicted Fall\", \"Predicted No Fall\"],\n",
    "        )\n",
    "        plt.xlabel(\" \")\n",
    "        plt.ylabel(\" \")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        conf_matrix_path = \"confusion_matrix.png\"\n",
    "        plt.savefig(conf_matrix_path)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(conf_matrix_path)\n",
    "\n",
    "        print(f\"Model trained with accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "        # âœ… After training and evaluation, call the per-activity evaluation\n",
    "        evaluate_per_activity(best_model, X_test_full, y_test, feature_columns)\n",
    "\n",
    "        # âœ… After training and evaluation, call the per-distance evaluation\n",
    "        evaluate_per_distance(best_model, X_test_full, y_test, feature_columns)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipe(\n",
    "    model, \n",
    "    dataset_name, \n",
    "    save_name=\"fall_model\", \n",
    "    feature_columns=None, \n",
    "    target_column=\"fall_binary\", \n",
    "    experiment_name=\"default_experiment\",\n",
    "    use_early_stopping=True,\n",
    "    if_optuna=True,\n",
    "    n_trials=250\n",
    "):\n",
    "    \"\"\"\n",
    "    General training pipeline for both classical models (XGBoost, RF, SVM) and deep learning models.\n",
    "\n",
    "    Args:\n",
    "        model: The initialized model (LSTM, RNN, RF, XGB, etc.).\n",
    "        dataset_name: The dataset CSV file.\n",
    "        save_name: Name to save the trained model.\n",
    "        feature_columns: List of feature column names.\n",
    "        target_column: The name of the target column.\n",
    "        experiment_name: MLflow experiment name.\n",
    "        use_early_stopping: Whether to use early stopping (for neural networks).\n",
    "        if_optuna: Whether to perform hyperparameter tuning (for tree-based models).\n",
    "\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    # âœ… Prevent overwriting existing models unless explicitly handled\n",
    "    if os.path.exists(f\"models/{save_name}.pkl\") or os.path.exists(f\"models/{save_name}.keras\"):\n",
    "        raise ValueError(f\"Model name '{save_name}' already exists. Choose a new name or delete the existing model.\")\n",
    "\n",
    "    # âœ… Load dataset\n",
    "    df = load_data(dataset_name)\n",
    "\n",
    "    # âœ… Auto-detect feature columns if not explicitly provided\n",
    "    value_columns = [col for col in df.columns if col.startswith(\"value\")]\n",
    "    if value_columns:\n",
    "        feature_columns = value_columns  \n",
    "    elif feature_columns is None:\n",
    "        raise ValueError(\"Feature columns must be specified.\")\n",
    "\n",
    "    # âœ… Ensure target column exists\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' not found in dataset.\")\n",
    "\n",
    "    data_train, data_test = stratified_activity_split(df, target_column=target_column, test_size=0.2, random_state=42)\n",
    "    print(f\"Train shape: {data_train.shape}, Test shape: {data_test.shape}\")\n",
    "\n",
    "    # âœ… Keep full test data (including metadata like 'activity' or 'distance_m')\n",
    "    X_test_full = data_test.copy()  \n",
    "\n",
    "    # âœ… Keep `X_train`, `X_test` as DataFrames & `y_train`, `y_test` as Series\n",
    "    X_train = data_train[feature_columns]  \n",
    "    X_test = data_test[feature_columns]    \n",
    "    y_train = data_train[target_column]  \n",
    "    y_test = data_test[target_column]    \n",
    "\n",
    "    # âœ… Check model type\n",
    "    is_tree = isinstance(model, (XGBClassifier, RandomForestClassifier, GradientBoostingClassifier))\n",
    "    is_svm = isinstance(model, SVC)\n",
    "\n",
    "    if is_svm:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        X_test_full[feature_columns] = scaler.transform(X_test_full[feature_columns])\n",
    "\n",
    "        # âœ… Convert X_train back to DataFrame\n",
    "        X_train = pd.DataFrame(X_train, columns=feature_columns, index=data_train.index)\n",
    "        X_test = pd.DataFrame(X_test, columns=feature_columns, index=data_test.index)\n",
    "        X_test_full[feature_columns] = pd.DataFrame(X_test_full[feature_columns], columns=feature_columns, index=data_test.index)\n",
    "\n",
    "    # âœ… Train tree-based models with optional Optuna hyperparameter tuning\n",
    "    if is_tree or is_svm:\n",
    "        model = train_and_log_classical_model(\n",
    "            model, X_train, X_test, y_train, y_test, X_test_full,\n",
    "            save_name=save_name,\n",
    "            experiment_name=experiment_name,\n",
    "            target_column=target_column,\n",
    "            feature_columns=feature_columns,\n",
    "            if_optuna=if_optuna,\n",
    "            n_trials=n_trials,\n",
    "            dataset_name=dataset_name\n",
    "        )\n",
    "    \n",
    "    # Delete the files activity_results.csv and distance_results.csv\n",
    "    os.remove(\"activity_results.csv\")\n",
    "    os.remove(\"distance_results.csv\")\n",
    "    os.remove(\"confusion_matrices_distance.png\")\n",
    "    os.remove(\"confusion_matrix.png\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mlflow.tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "def train_model(\n",
    "    model, \n",
    "    dataset_name, \n",
    "    save_name=\"lstm_fall_model\", \n",
    "    feature_columns=None, \n",
    "    target_column=\"fall_binary\", \n",
    "    experiment_name=\"default_experiment\",\n",
    "    use_early_stopping=True  # âœ… Option to enable/disable early stopping\n",
    "):\n",
    "    \"\"\"\n",
    "    Loads the dataset, reshapes it for RNN, trains the model, and logs everything to MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: The RNN model (already defined).\n",
    "        dataset_name: The name of the dataset CSV file.\n",
    "        save_name: Name to save the trained model.\n",
    "        feature_columns: List of feature column names (overwritten if 'value' columns exist).\n",
    "        target_column: The name of the target column.\n",
    "        experiment_name: Name of the MLflow experiment.\n",
    "        use_early_stopping: Whether to enable early stopping based on validation loss.\n",
    "\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load dataset\n",
    "    df = load_data(dataset_name)\n",
    "\n",
    "    # Auto-detect feature columns if they start with \"value\"\n",
    "    value_columns = [col for col in df.columns if col.startswith(\"value\")]\n",
    "    if value_columns:\n",
    "        feature_columns = value_columns  # Override feature selection\n",
    "    elif feature_columns is None:\n",
    "        raise ValueError(\"Feature columns must be specified if no 'value' columns exist.\")\n",
    "\n",
    "    # Ensure target column exists\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' not found in dataset.\")\n",
    "\n",
    "    # Train-test split but keep the full dataset for evaluation\n",
    "    data_train, data_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    print(f\"Train shape: {data_train.shape}, Test shape: {data_test.shape}\")\n",
    "\n",
    "    X_train = data_train[feature_columns].values\n",
    "    X_test = data_test[feature_columns].values\n",
    "\n",
    "    y_train = data_train[target_column].values\n",
    "    y_test = data_test[target_column].values\n",
    "    \n",
    "    X_test_full = X_test.copy()  # Keep a copy of the test data for evaluation\n",
    "    y_test_full = y_test.copy()\n",
    "\n",
    "    X_train = X_train[feature_columns].values\n",
    "    X_test = X_test[feature_columns].values\n",
    "\n",
    "    # Reshape X: (num_samples, timesteps=500, num_features)\n",
    "    if value_columns:\n",
    "        num_features = len(feature_columns) // 500  # Calculate how many features per timestep\n",
    "        X_test = X_test.reshape(-1, 500, num_features)\n",
    "        X_train = X_train.reshape(-1, 500, num_features)\n",
    "    else:\n",
    "        num_features = len(feature_columns)\n",
    "\n",
    "    # Print shapes\n",
    "    print(f\"X_test_full shape: {X_test_full.shape}\")\n",
    "    print(f\"y_test_full shape: {y_test_full.shape}\")\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "    is_lstm = isinstance(model, tf.keras.Model)\n",
    "\n",
    "    if is_lstm:\n",
    "        # âœ… Set up Early Stopping (if enabled)\n",
    "        callbacks = []\n",
    "        if use_early_stopping:\n",
    "            early_stopping = EarlyStopping(\n",
    "                monitor=\"val_loss\", patience=3, restore_best_weights=True, verbose=1\n",
    "            )\n",
    "            callbacks.append(early_stopping)\n",
    "\n",
    "    # Start MLflow experiment\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        print(f\"X_train shape: {X_train.shape}\")  # Should be (num_samples, timesteps, num_features)\n",
    "        print(f\"y_train shape: {y_train.shape}\")  # Should be (num_samples,)\n",
    "\n",
    "        # âœ… Log dataset name\n",
    "        mlflow.log_param(\"dataset_name\", dataset_name)  \n",
    "\n",
    "        if is_lstm:\n",
    "            # Train the model and log history\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                validation_data=(X_test, y_test),\n",
    "                callbacks=callbacks  # âœ… Apply Early Stopping if enabled\n",
    "            )\n",
    "        else:\n",
    "            model.fit(X_train, y_train)  # No need for epochs, batch size, or callbacks\n",
    "            \n",
    "        if is_lstm:\n",
    "            # Evaluate model\n",
    "            loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        else:\n",
    "            y_pred = model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # âœ… After training and evaluation, call the per-activity evaluation\n",
    "        results_df = evaluate_per_activity(model, X_test_full, y_test_full, target_column, feature_columns)\n",
    "        \n",
    "        # âœ… After training and evaluation, call the per-distance evaluation\n",
    "        evaluate_per_distance(model, X_test_full, y_test_full, target_column, feature_columns)\n",
    "\n",
    "        # âœ… Log per-activity accuracy in MLflow\n",
    "        mlflow.log_artifact(\"activity_results.csv\")\n",
    "\n",
    "        # âœ… Log model parameters\n",
    "        mlflow.log_param(\"num_features_used\", len(feature_columns))\n",
    "        mlflow.log_param(\"model_type\", model.__class__.__name__)\n",
    "\n",
    "        if is_lstm:\n",
    "            mlflow.log_param(\"epochs\", EPOCHS)\n",
    "            mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "            mlflow.log_param(\"optimizer\", model.optimizer.__class__.__name__)\n",
    "            mlflow.log_param(\"loss_function\", model.loss)\n",
    "            mlflow.log_param(\"early_stopping\", use_early_stopping)  # âœ… Log whether early stopping was used\n",
    "            mlflow.log_metric(\"final_loss\", loss)\n",
    "\n",
    "        # âœ… Log metrics\n",
    "        mlflow.log_metric(\"final_accuracy\", accuracy)\n",
    "\n",
    "        if is_lstm:\n",
    "            # âœ… Log accuracy and loss per epoch\n",
    "            for epoch, (train_acc, val_acc, train_loss, val_loss) in enumerate(zip(history.history['accuracy'], history.history['val_accuracy'], history.history['loss'], history.history['val_loss'])):\n",
    "                mlflow.log_metric(\"train_accuracy_epoch\", train_acc, step=epoch)\n",
    "                mlflow.log_metric(\"val_accuracy_epoch\", val_acc, step=epoch)\n",
    "                mlflow.log_metric(\"train_loss_epoch\", train_loss, step=epoch)\n",
    "                mlflow.log_metric(\"val_loss_epoch\", val_loss, step=epoch)\n",
    "\n",
    "        # âœ… Ensure models folder exists\n",
    "        models_folder = \"models\"\n",
    "        if not os.path.exists(models_folder):\n",
    "            os.makedirs(models_folder)\n",
    "\n",
    "        save_path = os.path.join(models_folder, save_name)\n",
    "\n",
    "        if is_lstm:\n",
    "            model.save(save_path + \".keras\")  # âœ… Save Keras model\n",
    "            mlflow.log_artifact(save_path + \".keras\")\n",
    "        else:\n",
    "            import joblib\n",
    "            joblib.dump(model, save_path + \".pkl\")  # âœ… Save tree-based model\n",
    "            mlflow.log_artifact(save_path + \".pkl\")\n",
    "\n",
    "        # âœ… Log the saved model file as an artifact in MLflow\n",
    "        mlflow.log_artifact(save_path + \".pkl\")\n",
    "\n",
    "        # âœ… Save confusion matrix\n",
    "        y_pred = model.predict(X_test).round()\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # Compute additional metrics\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "\n",
    "        # Log additional metrics\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "        # âœ… Save and log confusion matrix\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"No Fall\", \"Fall\"], yticklabels=[\"No Fall\", \"Fall\"])\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        conf_matrix_path = \"confusion_matrix.png\"\n",
    "        plt.savefig(conf_matrix_path)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(conf_matrix_path)\n",
    "\n",
    "        print(f\"Model trained with accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "        # Delete the files activity_results.csv and distance_results.csv\n",
    "        os.remove(\"activity_results.csv\")\n",
    "        os.remove(\"distance_results.csv\")\n",
    "        os.remove(\"confusion_matrices_distance.png\")\n",
    "        os.remove(\"confusion_matrix.png\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# XGBoost Model\n",
    "# ==========================\n",
    "\n",
    "def build_xgboost_model():\n",
    "    \"\"\"\n",
    "    Builds an XGBoost model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A compiled XGBoost model.\n",
    "    \"\"\"\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.11,\n",
    "        objective=\"binary:logistic\",\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ==========================\n",
    "# Random Forest Model\n",
    "# ==========================\n",
    "\n",
    "def build_random_forest_model():\n",
    "    \"\"\"\n",
    "    Builds a Random Forest model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Random Forest model.\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ==========================\n",
    "# GBM Model\n",
    "# ==========================\n",
    "def build_gradient_boosting_model():\n",
    "    \"\"\"\n",
    "    Builds a Gradient Boosting (GBM) model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Gradient Boosting model.\n",
    "    \"\"\"\n",
    "    return GradientBoostingClassifier(\n",
    "        n_estimators=200,  # Number of boosting stages\n",
    "        learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n",
    "        max_depth=5,  # Maximum depth of the trees\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "# ==========================\n",
    "# SVM Model\n",
    "# ==========================\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def build_svm_model():\n",
    "    \"\"\"\n",
    "    Builds an SVM model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A configured SVM model.\n",
    "    \"\"\"\n",
    "    model = SVC(\n",
    "        kernel=\"rbf\",  # Radial Basis Function (RBF) kernel (default)\n",
    "        C=1.0,         # Regularization parameter\n",
    "        gamma=\"scale\",  # Kernel coefficient\n",
    "        probability=True,  # Enable probability estimates (needed for ROC AUC)\n",
    "        random_state=42\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# RNN Model\n",
    "# ==========================\n",
    "def build_rnn_model():\n",
    "    \"\"\"\n",
    "    Builds a simple RNN model using Keras.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        SimpleRNN(RNN_UNITS, input_shape=INPUT_SHAPE, return_sequences=True),\n",
    "        SimpleRNN(RNN_UNITS),\n",
    "        Dense(DENSE_UNITS, activation=\"relu\"),\n",
    "        Dropout(DROPOUT_RATE),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNCTION, metrics=METRICS)\n",
    "    return model\n",
    "\n",
    "# ==========================\n",
    "# LSTM Model\n",
    "# ==========================\n",
    "def build_lstm_model(l2_lambda=0.001, dropout_rate=0.2, clipnorm=1.0):\n",
    "    \"\"\"\n",
    "    Builds an LSTM-based model with L2 regularization, dropout, and gradient clipping.\n",
    "\n",
    "    Args:\n",
    "        l2_lambda: Strength of L2 regularization (default: 0.001).\n",
    "        dropout_rate: Dropout rate to reduce overfitting (default: 0.2).\n",
    "        clipnorm: Gradient clipping norm (default: 1.0).\n",
    "\n",
    "    Returns:\n",
    "        A compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(RNN_UNITS, input_shape=INPUT_SHAPE, return_sequences=True, \n",
    "             kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),  # Dropout after first LSTM layer\n",
    "        LSTM(RNN_UNITS, kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),  # Dropout after second LSTM layer\n",
    "        Dense(DENSE_UNITS, activation=\"relu\", kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),  # Dropout before final layer\n",
    "        Dense(1, activation=\"sigmoid\")  # Output layer for binary classification\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(clipnorm=clipnorm)\n",
    "    model.compile(optimizer=optimizer, loss=LOSS_FUNCTION, metrics=METRICS)\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Bidirectional LSTM Model (Optional)\n",
    "# ==========================\n",
    "def build_bidirectional_lstm():\n",
    "    \"\"\"\n",
    "    Builds a Bidirectional LSTM model for improved sequence learning.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(RNN_UNITS, return_sequences=True), input_shape=INPUT_SHAPE),\n",
    "        Bidirectional(LSTM(RNN_UNITS)),\n",
    "        Dense(DENSE_UNITS, activation=\"relu\"),\n",
    "        Dropout(DROPOUT_RATE),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNCTION, metrics=METRICS)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# CONFIGURABLE VARIABLES\n",
    "# ==========================\n",
    "RNN_UNITS = 128           # Number of RNN/LSTM units\n",
    "DENSE_UNITS = 64         # Number of neurons in the dense layer\n",
    "DROPOUT_RATE = 0.1      # Dropout rate for regularization\n",
    "OPTIMIZER = \"adam\"       # Optimizer: \"adam\", \"sgd\", \"rmsprop\", etc.\n",
    "LOSS_FUNCTION = \"binary_crossentropy\"  # \"binary_crossentropy\" for classification\n",
    "METRICS = [\"accuracy\"]   # Metrics to monitor\n",
    "EPOCHS = 10              # Number of training epochs\n",
    "BATCH_SIZE = 16          # Batch size for training\n",
    "INPUT_SHAPE = (500, 1)   # (Time steps, Features) - Adjust based on your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(max_depth=5, n_estimators=200, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Initialize the Model\n",
    "# ==========================\n",
    "model = build_gradient_boosting_model()  # Change this to your desired model\n",
    "# print(model.summary())  # Print model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1016, 19), Test shape: (254, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 20:22:59,982] A new study created in memory with name: no-name-5010a74e-2a75-4100-9daa-ae3b80dbcd20\n",
      "[I 2025-03-15 20:23:04,161] Trial 0 finished with value: 0.9059165527152983 and parameters: {'n_estimators': 350, 'learning_rate': 0.18548777161277327, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.9059165527152983.\n",
      "[I 2025-03-15 20:23:11,791] Trial 1 finished with value: 0.9135044201345291 and parameters: {'n_estimators': 350, 'learning_rate': 0.019560233413501035, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.9135044201345291.\n",
      "[I 2025-03-15 20:23:15,070] Trial 2 finished with value: 0.913216958014383 and parameters: {'n_estimators': 400, 'learning_rate': 0.21892187900771626, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.9135044201345291.\n",
      "[I 2025-03-15 20:23:20,438] Trial 3 finished with value: 0.9189996174269506 and parameters: {'n_estimators': 350, 'learning_rate': 0.012940767851063382, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:23:27,026] Trial 4 finished with value: 0.9101636030073829 and parameters: {'n_estimators': 500, 'learning_rate': 0.09109144770588902, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:23:32,053] Trial 5 finished with value: 0.9071842503524292 and parameters: {'n_estimators': 450, 'learning_rate': 0.10783156063108454, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:23:32,727] Trial 6 finished with value: 0.9110169767942622 and parameters: {'n_estimators': 50, 'learning_rate': 0.02892800146365604, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:23:37,839] Trial 7 finished with value: 0.9114964475081777 and parameters: {'n_estimators': 300, 'learning_rate': 0.12431646529643428, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:23:42,450] Trial 8 finished with value: 0.9001704745125068 and parameters: {'n_estimators': 250, 'learning_rate': 0.017846632489443355, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:23:44,893] Trial 9 finished with value: 0.9120371924939656 and parameters: {'n_estimators': 150, 'learning_rate': 0.2939851321845714, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:23:49,566] Trial 10 finished with value: 0.9055103903736533 and parameters: {'n_estimators': 200, 'learning_rate': 0.04376007823208191, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:23:52,042] Trial 11 finished with value: 0.8937267029731129 and parameters: {'n_estimators': 350, 'learning_rate': 0.01080970299049976, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:24:01,343] Trial 12 finished with value: 0.9073466841350053 and parameters: {'n_estimators': 400, 'learning_rate': 0.0109746502458625, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:24:08,060] Trial 13 finished with value: 0.8995018325459666 and parameters: {'n_estimators': 300, 'learning_rate': 0.022174381280321176, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:24:14,839] Trial 14 finished with value: 0.9031466741144161 and parameters: {'n_estimators': 500, 'learning_rate': 0.04247624551013893, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:24:16,684] Trial 15 finished with value: 0.9042809872061781 and parameters: {'n_estimators': 200, 'learning_rate': 0.01794457767182823, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:24:27,340] Trial 16 finished with value: 0.9031950964347665 and parameters: {'n_estimators': 400, 'learning_rate': 0.02810154090560775, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:24:34,537] Trial 17 finished with value: 0.9055928299079403 and parameters: {'n_estimators': 350, 'learning_rate': 0.014164431261373496, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:24:38,494] Trial 18 finished with value: 0.9114056014259215 and parameters: {'n_estimators': 250, 'learning_rate': 0.03331957896286562, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:24:40,068] Trial 19 finished with value: 0.9178334657268223 and parameters: {'n_estimators': 100, 'learning_rate': 0.06510342753552238, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:24:40,855] Trial 20 finished with value: 0.9091987607249212 and parameters: {'n_estimators': 50, 'learning_rate': 0.06908711352414558, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:24:42,830] Trial 21 finished with value: 0.9095447331473115 and parameters: {'n_estimators': 100, 'learning_rate': 0.06902785554904693, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:24:45,151] Trial 22 finished with value: 0.9107455032529659 and parameters: {'n_estimators': 200, 'learning_rate': 0.015300292080022381, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:24:49,797] Trial 23 finished with value: 0.9125536773560773 and parameters: {'n_estimators': 300, 'learning_rate': 0.055022247287701574, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:24:52,711] Trial 24 finished with value: 0.9045241314532653 and parameters: {'n_estimators': 150, 'learning_rate': 0.010213814992195275, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:24:57,856] Trial 25 finished with value: 0.9097509797556942 and parameters: {'n_estimators': 450, 'learning_rate': 0.020923854828857058, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:05,907] Trial 26 finished with value: 0.9074136373647284 and parameters: {'n_estimators': 350, 'learning_rate': 0.03577655067439655, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:09,768] Trial 27 finished with value: 0.9080763310212531 and parameters: {'n_estimators': 250, 'learning_rate': 0.024370168509124924, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:11,593] Trial 28 finished with value: 0.9132487722251502 and parameters: {'n_estimators': 100, 'learning_rate': 0.01326978218111513, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:16,293] Trial 29 finished with value: 0.9125170117341241 and parameters: {'n_estimators': 450, 'learning_rate': 0.14527751605689113, 'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:21,499] Trial 30 finished with value: 0.9097476409169613 and parameters: {'n_estimators': 300, 'learning_rate': 0.07528218831649128, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:24,287] Trial 31 finished with value: 0.9176627980206927 and parameters: {'n_estimators': 150, 'learning_rate': 0.01566111255730195, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:26,284] Trial 32 finished with value: 0.9109021866654949 and parameters: {'n_estimators': 100, 'learning_rate': 0.016778762328433238, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:28,863] Trial 33 finished with value: 0.9140125320158472 and parameters: {'n_estimators': 150, 'learning_rate': 0.05250129919519839, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:31,438] Trial 34 finished with value: 0.9152615460219176 and parameters: {'n_estimators': 150, 'learning_rate': 0.05637739265650984, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:32,787] Trial 35 finished with value: 0.911768017858709 and parameters: {'n_estimators': 100, 'learning_rate': 0.09684226142612018, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:33,560] Trial 36 finished with value: 0.9121522950757498 and parameters: {'n_estimators': 50, 'learning_rate': 0.060038560210923866, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:35,563] Trial 37 finished with value: 0.9073513476286956 and parameters: {'n_estimators': 150, 'learning_rate': 0.045681037540757995, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:39,050] Trial 38 finished with value: 0.9166289737133286 and parameters: {'n_estimators': 200, 'learning_rate': 0.1608970668664466, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:42,824] Trial 39 finished with value: 0.9092917252480796 and parameters: {'n_estimators': 200, 'learning_rate': 0.18078291551829578, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:45,315] Trial 40 finished with value: 0.9145072001963499 and parameters: {'n_estimators': 250, 'learning_rate': 0.2910770094948507, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:47,899] Trial 41 finished with value: 0.9155210565975065 and parameters: {'n_estimators': 150, 'learning_rate': 0.21104418886672613, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:49,640] Trial 42 finished with value: 0.912778966029177 and parameters: {'n_estimators': 100, 'learning_rate': 0.22553440312633868, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:52,712] Trial 43 finished with value: 0.9108359726295209 and parameters: {'n_estimators': 200, 'learning_rate': 0.1433066085363708, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:55,552] Trial 44 finished with value: 0.9124643723981855 and parameters: {'n_estimators': 150, 'learning_rate': 0.21202039432210573, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:25:56,242] Trial 45 finished with value: 0.9151948096953705 and parameters: {'n_estimators': 50, 'learning_rate': 0.1231763294885769, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:00,016] Trial 46 finished with value: 0.9124225140867175 and parameters: {'n_estimators': 200, 'learning_rate': 0.17945098894582295, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:01,901] Trial 47 finished with value: 0.9100712038416956 and parameters: {'n_estimators': 100, 'learning_rate': 0.2433705965482315, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:04,643] Trial 48 finished with value: 0.912752879770333 and parameters: {'n_estimators': 150, 'learning_rate': 0.01227834096400769, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:09,936] Trial 49 finished with value: 0.9062399612262209 and parameters: {'n_estimators': 400, 'learning_rate': 0.08890838379647113, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:12,767] Trial 50 finished with value: 0.898728722258134 and parameters: {'n_estimators': 250, 'learning_rate': 0.1532257274839327, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:15,353] Trial 51 finished with value: 0.9043612460277078 and parameters: {'n_estimators': 150, 'learning_rate': 0.1151846696803295, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:17,653] Trial 52 finished with value: 0.9177067386864646 and parameters: {'n_estimators': 150, 'learning_rate': 0.035939412033354094, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:20,727] Trial 53 finished with value: 0.914626685321911 and parameters: {'n_estimators': 200, 'learning_rate': 0.027009082055412956, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:22,284] Trial 54 finished with value: 0.913818782249742 and parameters: {'n_estimators': 100, 'learning_rate': 0.01823942254678973, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:24,581] Trial 55 finished with value: 0.915763522819416 and parameters: {'n_estimators': 150, 'learning_rate': 0.033620527362042, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:27,631] Trial 56 finished with value: 0.9188365546615895 and parameters: {'n_estimators': 200, 'learning_rate': 0.037068901571074585, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:30,313] Trial 57 finished with value: 0.9115566796233002 and parameters: {'n_estimators': 200, 'learning_rate': 0.039407133276213833, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:34,377] Trial 58 finished with value: 0.9137945585110847 and parameters: {'n_estimators': 300, 'learning_rate': 0.023504149592329198, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:36,674] Trial 59 finished with value: 0.9110228696741853 and parameters: {'n_estimators': 250, 'learning_rate': 0.08070296147907609, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:42,026] Trial 60 finished with value: 0.9046468522665997 and parameters: {'n_estimators': 350, 'learning_rate': 0.015354292190831226, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:44,337] Trial 61 finished with value: 0.9140715942106652 and parameters: {'n_estimators': 150, 'learning_rate': 0.029777052711024134, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:47,391] Trial 62 finished with value: 0.9135943857053892 and parameters: {'n_estimators': 200, 'learning_rate': 0.048079575470180935, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:49,127] Trial 63 finished with value: 0.9123112937203673 and parameters: {'n_estimators': 100, 'learning_rate': 0.035459732179539724, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:51,388] Trial 64 finished with value: 0.9116035253669613 and parameters: {'n_estimators': 150, 'learning_rate': 0.011954255451309995, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:54,453] Trial 65 finished with value: 0.9144706440789303 and parameters: {'n_estimators': 200, 'learning_rate': 0.03165044249773789, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:55,385] Trial 66 finished with value: 0.9027494441025281 and parameters: {'n_estimators': 50, 'learning_rate': 0.026795751549901554, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:26:56,744] Trial 67 finished with value: 0.9154370439487742 and parameters: {'n_estimators': 100, 'learning_rate': 0.039447487563846015, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:00,166] Trial 68 finished with value: 0.9136422571343645 and parameters: {'n_estimators': 200, 'learning_rate': 0.02098546567751784, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:01,889] Trial 69 finished with value: 0.9133905589912306 and parameters: {'n_estimators': 150, 'learning_rate': 0.040446559416781366, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:06,776] Trial 70 finished with value: 0.9110485002135918 and parameters: {'n_estimators': 250, 'learning_rate': 0.06495757645609432, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:09,346] Trial 71 finished with value: 0.9159454597269739 and parameters: {'n_estimators': 150, 'learning_rate': 0.050028796379749725, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:11,167] Trial 72 finished with value: 0.9120541889483066 and parameters: {'n_estimators': 100, 'learning_rate': 0.03446253729315021, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:13,466] Trial 73 finished with value: 0.9110270979207101 and parameters: {'n_estimators': 150, 'learning_rate': 0.049102341216896946, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:21,200] Trial 74 finished with value: 0.9059697949590912 and parameters: {'n_estimators': 450, 'learning_rate': 0.044845550680948525, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:23,492] Trial 75 finished with value: 0.9163304672537855 and parameters: {'n_estimators': 150, 'learning_rate': 0.014090131257653625, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:27,148] Trial 76 finished with value: 0.9125545122132716 and parameters: {'n_estimators': 200, 'learning_rate': 0.014442065671990786, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:28,829] Trial 77 finished with value: 0.9106729451382428 and parameters: {'n_estimators': 100, 'learning_rate': 0.013020524484575658, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:34,178] Trial 78 finished with value: 0.9136787059055521 and parameters: {'n_estimators': 400, 'learning_rate': 0.01091899039773956, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:36,501] Trial 79 finished with value: 0.9130133398907467 and parameters: {'n_estimators': 150, 'learning_rate': 0.01622586368310279, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:42,231] Trial 80 finished with value: 0.9124174018283415 and parameters: {'n_estimators': 300, 'learning_rate': 0.018088083277270874, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:44,528] Trial 81 finished with value: 0.9106852927471962 and parameters: {'n_estimators': 150, 'learning_rate': 0.06186174258803675, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:46,834] Trial 82 finished with value: 0.913634173121839 and parameters: {'n_estimators': 150, 'learning_rate': 0.019900607101057812, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:50,275] Trial 83 finished with value: 0.9152394508922377 and parameters: {'n_estimators': 200, 'learning_rate': 0.03153731778133996, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:52,273] Trial 84 finished with value: 0.911422943049548 and parameters: {'n_estimators': 150, 'learning_rate': 0.010058530129542689, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:53,822] Trial 85 finished with value: 0.9139728892106007 and parameters: {'n_estimators': 100, 'learning_rate': 0.05213196495968071, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:57,240] Trial 86 finished with value: 0.9155844458666718 and parameters: {'n_estimators': 200, 'learning_rate': 0.025191346821824053, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:57,939] Trial 87 finished with value: 0.9056799625054358 and parameters: {'n_estimators': 50, 'learning_rate': 0.09728515470124453, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:27:59,487] Trial 88 finished with value: 0.9015840684648582 and parameters: {'n_estimators': 100, 'learning_rate': 0.01168482430020527, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:28:03,367] Trial 89 finished with value: 0.911428829790626 and parameters: {'n_estimators': 250, 'learning_rate': 0.013878212142197614, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:28:05,932] Trial 90 finished with value: 0.904445103816216 and parameters: {'n_estimators': 150, 'learning_rate': 0.03829148684574119, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:28:09,359] Trial 91 finished with value: 0.9173170153087744 and parameters: {'n_estimators': 200, 'learning_rate': 0.024437181672667375, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:28:12,786] Trial 92 finished with value: 0.9120134105848579 and parameters: {'n_estimators': 200, 'learning_rate': 0.04239133290267034, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:28:15,845] Trial 93 finished with value: 0.9144280501618745 and parameters: {'n_estimators': 200, 'learning_rate': 0.0224914621778844, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:28:18,169] Trial 94 finished with value: 0.9169399582458061 and parameters: {'n_estimators': 150, 'learning_rate': 0.028711221980896467, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:28:23,328] Trial 95 finished with value: 0.9187643220526432 and parameters: {'n_estimators': 250, 'learning_rate': 0.030393466383200528, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:28:33,712] Trial 96 finished with value: 0.9121939110893365 and parameters: {'n_estimators': 500, 'learning_rate': 0.02564922354345756, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:28:40,766] Trial 97 finished with value: 0.9143703874924014 and parameters: {'n_estimators': 300, 'learning_rate': 0.02866913347996928, 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:28:46,021] Trial 98 finished with value: 0.9093346310337832 and parameters: {'n_estimators': 250, 'learning_rate': 0.030952064521064717, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:28:51,392] Trial 99 finished with value: 0.9020076122493286 and parameters: {'n_estimators': 250, 'learning_rate': 0.016731954141691846, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:28:55,504] Trial 100 finished with value: 0.9158135715782707 and parameters: {'n_estimators': 200, 'learning_rate': 0.023175844695394642, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:28:58,081] Trial 101 finished with value: 0.9158029317688954 and parameters: {'n_estimators': 150, 'learning_rate': 0.036204091529639326, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:29:01,830] Trial 102 finished with value: 0.9147858728991668 and parameters: {'n_estimators': 200, 'learning_rate': 0.015125926059302344, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.9189996174269506.\n",
      "[I 2025-03-15 20:29:07,162] Trial 103 finished with value: 0.9203113703096335 and parameters: {'n_estimators': 350, 'learning_rate': 0.019922118453420692, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 103 with value: 0.9203113703096335.\n",
      "[I 2025-03-15 20:29:12,585] Trial 104 finished with value: 0.9113898491596334 and parameters: {'n_estimators': 350, 'learning_rate': 0.019179992914816438, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 103 with value: 0.9203113703096335.\n",
      "[I 2025-03-15 20:29:17,952] Trial 105 finished with value: 0.9142989953272938 and parameters: {'n_estimators': 350, 'learning_rate': 0.019539649978292495, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 103 with value: 0.9203113703096335.\n",
      "[I 2025-03-15 20:29:27,336] Trial 106 finished with value: 0.9078081961672424 and parameters: {'n_estimators': 400, 'learning_rate': 0.020854396873221333, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 103 with value: 0.9203113703096335.\n",
      "[I 2025-03-15 20:29:31,992] Trial 107 finished with value: 0.9142430062744925 and parameters: {'n_estimators': 350, 'learning_rate': 0.028223818266575735, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 103 with value: 0.9203113703096335.\n",
      "[I 2025-03-15 20:29:35,970] Trial 108 finished with value: 0.9123900614756841 and parameters: {'n_estimators': 300, 'learning_rate': 0.02152829771233758, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 103 with value: 0.9203113703096335.\n",
      "[I 2025-03-15 20:29:39,821] Trial 109 finished with value: 0.9140290002936098 and parameters: {'n_estimators': 250, 'learning_rate': 0.012769943316966577, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 103 with value: 0.9203113703096335.\n",
      "[I 2025-03-15 20:29:45,181] Trial 110 finished with value: 0.9117444633811935 and parameters: {'n_estimators': 350, 'learning_rate': 0.02451849868294959, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 103 with value: 0.9203113703096335.\n",
      "[I 2025-03-15 20:29:47,735] Trial 111 finished with value: 0.9211106252390117 and parameters: {'n_estimators': 150, 'learning_rate': 0.017269146185219582, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:29:50,289] Trial 112 finished with value: 0.9194955906579267 and parameters: {'n_estimators': 150, 'learning_rate': 0.01579104816522204, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:29:54,028] Trial 113 finished with value: 0.9135609225791044 and parameters: {'n_estimators': 200, 'learning_rate': 0.01740758107918262, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:29:55,722] Trial 114 finished with value: 0.9159195862634049 and parameters: {'n_estimators': 100, 'learning_rate': 0.01622120953581874, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:29:58,302] Trial 115 finished with value: 0.9120588356416703 and parameters: {'n_estimators': 150, 'learning_rate': 0.027044729132321112, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:03,462] Trial 116 finished with value: 0.9113604102248759 and parameters: {'n_estimators': 300, 'learning_rate': 0.03279428881839631, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:07,194] Trial 117 finished with value: 0.9129974973402994 and parameters: {'n_estimators': 200, 'learning_rate': 0.015347291981141056, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:09,861] Trial 118 finished with value: 0.9130345017747779 and parameters: {'n_estimators': 150, 'learning_rate': 0.030301159862200833, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:11,401] Trial 119 finished with value: 0.9123086778860848 and parameters: {'n_estimators': 100, 'learning_rate': 0.017878726033142535, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:14,260] Trial 120 finished with value: 0.9140359726295209 and parameters: {'n_estimators': 150, 'learning_rate': 0.16415457575247885, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:16,571] Trial 121 finished with value: 0.9161222496801443 and parameters: {'n_estimators': 150, 'learning_rate': 0.013417915723846303, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:19,640] Trial 122 finished with value: 0.9158396075910508 and parameters: {'n_estimators': 200, 'learning_rate': 0.011667640122818792, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:22,210] Trial 123 finished with value: 0.9180589404263759 and parameters: {'n_estimators': 150, 'learning_rate': 0.014086301777280603, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:24,802] Trial 124 finished with value: 0.913743300540564 and parameters: {'n_estimators': 150, 'learning_rate': 0.01893231882792982, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:25,524] Trial 125 finished with value: 0.8885985558889722 and parameters: {'n_estimators': 100, 'learning_rate': 0.014896492225853286, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:28,081] Trial 126 finished with value: 0.9211106252390117 and parameters: {'n_estimators': 150, 'learning_rate': 0.016401482747746658, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:30,786] Trial 127 finished with value: 0.9164335637828174 and parameters: {'n_estimators': 150, 'learning_rate': 0.01611717162741148, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:33,753] Trial 128 finished with value: 0.919288357091132 and parameters: {'n_estimators': 150, 'learning_rate': 0.012519752140094207, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:36,710] Trial 129 finished with value: 0.9170166828231858 and parameters: {'n_estimators': 150, 'learning_rate': 0.012313145044666905, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:38,663] Trial 130 finished with value: 0.9113234137968057 and parameters: {'n_estimators': 100, 'learning_rate': 0.01388825103640814, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:41,634] Trial 131 finished with value: 0.9150406524768773 and parameters: {'n_estimators': 150, 'learning_rate': 0.012784946493455128, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:44,774] Trial 132 finished with value: 0.9141890005817631 and parameters: {'n_estimators': 150, 'learning_rate': 0.011093024363042686, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:47,929] Trial 133 finished with value: 0.9051958688784616 and parameters: {'n_estimators': 150, 'learning_rate': 0.012110014944411364, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:50,948] Trial 134 finished with value: 0.9193678245770511 and parameters: {'n_estimators': 150, 'learning_rate': 0.014448948320140884, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:52,821] Trial 135 finished with value: 0.9179282222806767 and parameters: {'n_estimators': 100, 'learning_rate': 0.016925058985032396, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:54,880] Trial 136 finished with value: 0.910621912885588 and parameters: {'n_estimators': 100, 'learning_rate': 0.07224864530857818, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:56,728] Trial 137 finished with value: 0.9166071874100357 and parameters: {'n_estimators': 100, 'learning_rate': 0.017082726897398134, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:30:57,655] Trial 138 finished with value: 0.8930947599803296 and parameters: {'n_estimators': 50, 'learning_rate': 0.015907175566872746, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:31:05,915] Trial 139 finished with value: 0.915973860622465 and parameters: {'n_estimators': 400, 'learning_rate': 0.014248261358581895, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:31:07,877] Trial 140 finished with value: 0.9091296266419262 and parameters: {'n_estimators': 100, 'learning_rate': 0.014546807365249001, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:31:10,444] Trial 141 finished with value: 0.9199101289283108 and parameters: {'n_estimators': 150, 'learning_rate': 0.020467146220731126, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 111 with value: 0.9211106252390117.\n",
      "[I 2025-03-15 20:31:13,249] Trial 142 finished with value: 0.9226524888134728 and parameters: {'n_estimators': 150, 'learning_rate': 0.01821520337454717, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 142 with value: 0.9226524888134728.\n",
      "[I 2025-03-15 20:31:16,503] Trial 143 finished with value: 0.920022516840606 and parameters: {'n_estimators': 150, 'learning_rate': 0.02016048566812533, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 142 with value: 0.9226524888134728.\n",
      "[I 2025-03-15 20:31:19,738] Trial 144 finished with value: 0.9126309964125108 and parameters: {'n_estimators': 150, 'learning_rate': 0.018814277978071527, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 142 with value: 0.9226524888134728.\n",
      "[I 2025-03-15 20:31:23,181] Trial 145 finished with value: 0.9150995907523777 and parameters: {'n_estimators': 150, 'learning_rate': 0.020512056598217747, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 142 with value: 0.9226524888134728.\n",
      "[I 2025-03-15 20:31:26,486] Trial 146 finished with value: 0.9182236730686265 and parameters: {'n_estimators': 150, 'learning_rate': 0.017141967161873488, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 142 with value: 0.9226524888134728.\n",
      "[I 2025-03-15 20:31:29,686] Trial 147 finished with value: 0.9193336416396283 and parameters: {'n_estimators': 150, 'learning_rate': 0.01721417881686206, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 142 with value: 0.9226524888134728.\n",
      "[I 2025-03-15 20:31:32,914] Trial 148 finished with value: 0.9142301142924592 and parameters: {'n_estimators': 150, 'learning_rate': 0.018206063047747353, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 142 with value: 0.9226524888134728.\n",
      "[I 2025-03-15 20:31:36,169] Trial 149 finished with value: 0.9160040122855267 and parameters: {'n_estimators': 150, 'learning_rate': 0.021941400844872488, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 142 with value: 0.9226524888134728.\n",
      "[I 2025-03-15 20:31:39,402] Trial 150 finished with value: 0.9140472041229749 and parameters: {'n_estimators': 150, 'learning_rate': 0.019585695711983542, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 142 with value: 0.9226524888134728.\n",
      "[I 2025-03-15 20:31:42,597] Trial 151 finished with value: 0.9144120512000173 and parameters: {'n_estimators': 150, 'learning_rate': 0.017079261455661607, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 142 with value: 0.9226524888134728.\n",
      "[I 2025-03-15 20:31:45,782] Trial 152 finished with value: 0.9183274868392172 and parameters: {'n_estimators': 150, 'learning_rate': 0.01685584957296635, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 142 with value: 0.9226524888134728.\n",
      "[I 2025-03-15 20:31:48,948] Trial 153 finished with value: 0.9155418671751419 and parameters: {'n_estimators': 150, 'learning_rate': 0.0150718923307881, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 142 with value: 0.9226524888134728.\n",
      "[I 2025-03-15 20:31:52,286] Trial 154 finished with value: 0.9182664589284902 and parameters: {'n_estimators': 150, 'learning_rate': 0.01573703349885736, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 142 with value: 0.9226524888134728.\n",
      "[I 2025-03-15 20:31:55,660] Trial 155 finished with value: 0.9138420796485827 and parameters: {'n_estimators': 150, 'learning_rate': 0.01792605966214596, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 142 with value: 0.9226524888134728.\n",
      "[I 2025-03-15 20:31:59,022] Trial 156 finished with value: 0.9198969014150832 and parameters: {'n_estimators': 150, 'learning_rate': 0.01591747162920907, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 142 with value: 0.9226524888134728.\n",
      "[I 2025-03-15 20:32:02,401] Trial 157 finished with value: 0.9196172214557233 and parameters: {'n_estimators': 150, 'learning_rate': 0.0199520290903205, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 142 with value: 0.9226524888134728.\n",
      "[I 2025-03-15 20:32:05,815] Trial 158 finished with value: 0.9133998032258184 and parameters: {'n_estimators': 150, 'learning_rate': 0.02048711307177652, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 142 with value: 0.9226524888134728.\n",
      "[I 2025-03-15 20:32:13,500] Trial 159 finished with value: 0.912152160919284 and parameters: {'n_estimators': 350, 'learning_rate': 0.01893623391389718, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 142 with value: 0.9226524888134728.\n",
      "[I 2025-03-15 20:32:16,903] Trial 160 finished with value: 0.9151731230148341 and parameters: {'n_estimators': 150, 'learning_rate': 0.023217663539909606, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 142 with value: 0.9226524888134728.\n",
      "[I 2025-03-15 20:32:20,243] Trial 161 finished with value: 0.9242440150532417 and parameters: {'n_estimators': 150, 'learning_rate': 0.01590104855939572, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:32:23,570] Trial 162 finished with value: 0.9208872239957284 and parameters: {'n_estimators': 150, 'learning_rate': 0.013512301682233921, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:32:26,879] Trial 163 finished with value: 0.9182054181022437 and parameters: {'n_estimators': 150, 'learning_rate': 0.013207014041249595, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:32:30,215] Trial 164 finished with value: 0.9179969014150832 and parameters: {'n_estimators': 150, 'learning_rate': 0.015550057026187017, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:32:34,796] Trial 165 finished with value: 0.9187485040485555 and parameters: {'n_estimators': 200, 'learning_rate': 0.02192650906817704, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:32:38,047] Trial 166 finished with value: 0.9138016944434056 and parameters: {'n_estimators': 150, 'learning_rate': 0.010588307307714527, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:32:42,561] Trial 167 finished with value: 0.9120098215840665 and parameters: {'n_estimators': 200, 'learning_rate': 0.014791468178202654, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:32:45,877] Trial 168 finished with value: 0.919541021303323 and parameters: {'n_estimators': 150, 'learning_rate': 0.013121337981392221, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:32:49,176] Trial 169 finished with value: 0.9165666714019309 and parameters: {'n_estimators': 150, 'learning_rate': 0.01356532242762438, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:32:52,474] Trial 170 finished with value: 0.9134622020855312 and parameters: {'n_estimators': 150, 'learning_rate': 0.01282295505980679, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:32:55,736] Trial 171 finished with value: 0.9090670505721867 and parameters: {'n_estimators': 150, 'learning_rate': 0.011571145432443095, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:32:59,076] Trial 172 finished with value: 0.9186914734743544 and parameters: {'n_estimators': 150, 'learning_rate': 0.01621019291227618, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:33:02,459] Trial 173 finished with value: 0.9126309964125108 and parameters: {'n_estimators': 150, 'learning_rate': 0.019842981317333027, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:33:05,835] Trial 174 finished with value: 0.9179174339291641 and parameters: {'n_estimators': 150, 'learning_rate': 0.017732754748457515, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:33:09,148] Trial 175 finished with value: 0.9186914734743544 and parameters: {'n_estimators': 150, 'learning_rate': 0.01396296293179092, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:33:16,257] Trial 176 finished with value: 0.9138388796223396 and parameters: {'n_estimators': 350, 'learning_rate': 0.012486101951053966, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:33:20,763] Trial 177 finished with value: 0.9159033426389158 and parameters: {'n_estimators': 200, 'learning_rate': 0.015017966298673722, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:33:24,133] Trial 178 finished with value: 0.9138420796485827 and parameters: {'n_estimators': 150, 'learning_rate': 0.01910287817210963, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:33:27,143] Trial 179 finished with value: 0.9170166828231858 and parameters: {'n_estimators': 150, 'learning_rate': 0.0160862938017484, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:33:30,105] Trial 180 finished with value: 0.9016173662086706 and parameters: {'n_estimators': 150, 'learning_rate': 0.01344184546772997, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:33:34,705] Trial 181 finished with value: 0.9137694905781316 and parameters: {'n_estimators': 200, 'learning_rate': 0.021678598909147456, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:33:39,290] Trial 182 finished with value: 0.9138838291934667 and parameters: {'n_estimators': 200, 'learning_rate': 0.022486808921335255, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:33:45,068] Trial 183 finished with value: 0.9135943857053892 and parameters: {'n_estimators': 250, 'learning_rate': 0.020541352602990805, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:33:48,461] Trial 184 finished with value: 0.9170166828231858 and parameters: {'n_estimators': 150, 'learning_rate': 0.018207119776947906, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:33:51,846] Trial 185 finished with value: 0.9165238855420673 and parameters: {'n_estimators': 150, 'learning_rate': 0.01766214146666355, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:33:56,266] Trial 186 finished with value: 0.9152356280356795 and parameters: {'n_estimators': 200, 'learning_rate': 0.020635031687448596, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:33:59,257] Trial 187 finished with value: 0.9193678245770511 and parameters: {'n_estimators': 150, 'learning_rate': 0.014746612324998023, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:34:02,277] Trial 188 finished with value: 0.9181732793678391 and parameters: {'n_estimators': 150, 'learning_rate': 0.014607154045105899, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:34:05,240] Trial 189 finished with value: 0.9150995907523777 and parameters: {'n_estimators': 150, 'learning_rate': 0.011654241842779172, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:34:08,268] Trial 190 finished with value: 0.913538305505741 and parameters: {'n_estimators': 150, 'learning_rate': 0.016358038581825583, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:34:10,836] Trial 191 finished with value: 0.9123964039149117 and parameters: {'n_estimators': 150, 'learning_rate': 0.019032304699796044, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:34:13,838] Trial 192 finished with value: 0.9179969014150832 and parameters: {'n_estimators': 150, 'learning_rate': 0.015507981165522707, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:34:19,484] Trial 193 finished with value: 0.9153890969210646 and parameters: {'n_estimators': 300, 'learning_rate': 0.01411037609160762, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:34:27,598] Trial 194 finished with value: 0.9116788254696374 and parameters: {'n_estimators': 350, 'learning_rate': 0.016900426891120566, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:34:30,573] Trial 195 finished with value: 0.9193678245770511 and parameters: {'n_estimators': 150, 'learning_rate': 0.01330356838534234, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:34:33,535] Trial 196 finished with value: 0.9133408649503181 and parameters: {'n_estimators': 150, 'learning_rate': 0.01309145625764212, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:34:36,497] Trial 197 finished with value: 0.9137233042421808 and parameters: {'n_estimators': 150, 'learning_rate': 0.012423383838669227, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:34:39,480] Trial 198 finished with value: 0.9182236730686265 and parameters: {'n_estimators': 150, 'learning_rate': 0.014777864254794784, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:34:42,600] Trial 199 finished with value: 0.9123604291531917 and parameters: {'n_estimators': 150, 'learning_rate': 0.010739761138732002, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:34:44,285] Trial 200 finished with value: 0.9162884454191682 and parameters: {'n_estimators': 100, 'learning_rate': 0.013971861787430501, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:34:47,291] Trial 201 finished with value: 0.9179969014150832 and parameters: {'n_estimators': 150, 'learning_rate': 0.01828639329525888, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:34:50,902] Trial 202 finished with value: 0.9073765221133643 and parameters: {'n_estimators': 150, 'learning_rate': 0.015715570969947846, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:34:53,933] Trial 203 finished with value: 0.9110129172008004 and parameters: {'n_estimators': 150, 'learning_rate': 0.024322684850179823, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:34:57,148] Trial 204 finished with value: 0.9186086439086953 and parameters: {'n_estimators': 150, 'learning_rate': 0.022103901569827326, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:01,609] Trial 205 finished with value: 0.917554624992319 and parameters: {'n_estimators': 200, 'learning_rate': 0.011432140172503692, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:04,148] Trial 206 finished with value: 0.9206859458579126 and parameters: {'n_estimators': 150, 'learning_rate': 0.013018721394760705, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:06,686] Trial 207 finished with value: 0.9196108127155773 and parameters: {'n_estimators': 150, 'learning_rate': 0.013140645845034528, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:09,224] Trial 208 finished with value: 0.9181545590455832 and parameters: {'n_estimators': 150, 'learning_rate': 0.013225671302472956, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:11,782] Trial 209 finished with value: 0.9172889325336054 and parameters: {'n_estimators': 150, 'learning_rate': 0.012348632955056985, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:14,321] Trial 210 finished with value: 0.9211526762900382 and parameters: {'n_estimators': 150, 'learning_rate': 0.013363908738421111, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:16,860] Trial 211 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.01351266634834894, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:19,400] Trial 212 finished with value: 0.9206859458579126 and parameters: {'n_estimators': 150, 'learning_rate': 0.013446518778453615, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:21,941] Trial 213 finished with value: 0.9181545590455832 and parameters: {'n_estimators': 150, 'learning_rate': 0.013251941811757578, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:24,483] Trial 214 finished with value: 0.9148653403850859 and parameters: {'n_estimators': 150, 'learning_rate': 0.0121355402140997, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:27,028] Trial 215 finished with value: 0.9210043611026739 and parameters: {'n_estimators': 150, 'learning_rate': 0.013918824087417115, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:29,576] Trial 216 finished with value: 0.9194344347628214 and parameters: {'n_estimators': 150, 'learning_rate': 0.014818354269504055, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:32,138] Trial 217 finished with value: 0.9240215831912082 and parameters: {'n_estimators': 150, 'learning_rate': 0.014552325914920696, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:34,685] Trial 218 finished with value: 0.9194534316295082 and parameters: {'n_estimators': 150, 'learning_rate': 0.014727842719885604, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:37,232] Trial 219 finished with value: 0.9195481074326798 and parameters: {'n_estimators': 150, 'learning_rate': 0.014146450420731893, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:39,775] Trial 220 finished with value: 0.9224205688131383 and parameters: {'n_estimators': 150, 'learning_rate': 0.014051824586343397, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:42,329] Trial 221 finished with value: 0.9194344347628214 and parameters: {'n_estimators': 150, 'learning_rate': 0.014212754420902357, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:45,033] Trial 222 finished with value: 0.9136156226018821 and parameters: {'n_estimators': 150, 'learning_rate': 0.015724536855133215, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:47,575] Trial 223 finished with value: 0.920642166908566 and parameters: {'n_estimators': 150, 'learning_rate': 0.013626652011531692, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:50,116] Trial 224 finished with value: 0.9225217706677735 and parameters: {'n_estimators': 150, 'learning_rate': 0.013573331816544666, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:52,655] Trial 225 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.013301104901003464, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:55,222] Trial 226 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.013494524212754894, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:35:57,762] Trial 227 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.013696645189551701, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:00,294] Trial 228 finished with value: 0.9225217706677735 and parameters: {'n_estimators': 150, 'learning_rate': 0.011880812955997935, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:02,838] Trial 229 finished with value: 0.9179282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.011094547825214405, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:05,374] Trial 230 finished with value: 0.9177785546510611 and parameters: {'n_estimators': 150, 'learning_rate': 0.012249379068547497, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:07,921] Trial 231 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.013511544310998784, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:10,465] Trial 232 finished with value: 0.9225217706677735 and parameters: {'n_estimators': 150, 'learning_rate': 0.013600732486195265, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:13,017] Trial 233 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.013560919960237661, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:15,557] Trial 234 finished with value: 0.9210043611026739 and parameters: {'n_estimators': 150, 'learning_rate': 0.013623393330740379, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:18,104] Trial 235 finished with value: 0.9174163604569532 and parameters: {'n_estimators': 150, 'learning_rate': 0.01176553259537303, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:20,649] Trial 236 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.013473684361942493, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:23,190] Trial 237 finished with value: 0.9211526762900382 and parameters: {'n_estimators': 150, 'learning_rate': 0.013579235062647762, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:25,727] Trial 238 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.013467583557024557, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:28,261] Trial 239 finished with value: 0.9177994419150777 and parameters: {'n_estimators': 150, 'learning_rate': 0.012540905786576132, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:30,798] Trial 240 finished with value: 0.9192296921879185 and parameters: {'n_estimators': 150, 'learning_rate': 0.013445241012008885, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:33,343] Trial 241 finished with value: 0.9196108127155773 and parameters: {'n_estimators': 150, 'learning_rate': 0.013691778680046868, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:35,884] Trial 242 finished with value: 0.9181545590455832 and parameters: {'n_estimators': 150, 'learning_rate': 0.012785789835627177, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:38,460] Trial 243 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.013783715007159808, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:41,031] Trial 244 finished with value: 0.917336381784599 and parameters: {'n_estimators': 150, 'learning_rate': 0.011997401463192208, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:43,603] Trial 245 finished with value: 0.9177312089563697 and parameters: {'n_estimators': 150, 'learning_rate': 0.013879523580383532, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:46,139] Trial 246 finished with value: 0.9172889325336054 and parameters: {'n_estimators': 150, 'learning_rate': 0.012849163432568839, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:48,663] Trial 247 finished with value: 0.9159901790921937 and parameters: {'n_estimators': 150, 'learning_rate': 0.011298467075128158, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:51,178] Trial 248 finished with value: 0.9162520791872566 and parameters: {'n_estimators': 150, 'learning_rate': 0.01011700568019275, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:53,755] Trial 249 finished with value: 0.9210043611026739 and parameters: {'n_estimators': 150, 'learning_rate': 0.013728110984832918, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:56,329] Trial 250 finished with value: 0.9225217706677735 and parameters: {'n_estimators': 150, 'learning_rate': 0.014473829719451393, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:36:58,040] Trial 251 finished with value: 0.9179282222806767 and parameters: {'n_estimators': 100, 'learning_rate': 0.014230394502780994, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:00,643] Trial 252 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.014770568676334426, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:03,206] Trial 253 finished with value: 0.9208279831499182 and parameters: {'n_estimators': 150, 'learning_rate': 0.015067369471182973, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:05,758] Trial 254 finished with value: 0.9179360220644085 and parameters: {'n_estimators': 150, 'learning_rate': 0.014759486181892413, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:08,295] Trial 255 finished with value: 0.9192959642161608 and parameters: {'n_estimators': 150, 'learning_rate': 0.012173136652263735, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:10,839] Trial 256 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.014130052005183373, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:13,393] Trial 257 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.01517798421725743, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:15,962] Trial 258 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.015498453542881208, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:18,508] Trial 259 finished with value: 0.9225041736261085 and parameters: {'n_estimators': 150, 'learning_rate': 0.015185405154519379, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:21,053] Trial 260 finished with value: 0.9196108127155773 and parameters: {'n_estimators': 150, 'learning_rate': 0.01524338318431096, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:22,746] Trial 261 finished with value: 0.9157053700827771 and parameters: {'n_estimators': 100, 'learning_rate': 0.015392776986572468, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:25,300] Trial 262 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.014907671347949254, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:27,849] Trial 263 finished with value: 0.9225217706677735 and parameters: {'n_estimators': 150, 'learning_rate': 0.014298286114766846, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:30,386] Trial 264 finished with value: 0.9192959642161608 and parameters: {'n_estimators': 150, 'learning_rate': 0.012394054190452579, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:32,927] Trial 265 finished with value: 0.9178224371567099 and parameters: {'n_estimators': 150, 'learning_rate': 0.014339215321629295, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:35,470] Trial 266 finished with value: 0.9196108127155773 and parameters: {'n_estimators': 150, 'learning_rate': 0.012704449354155987, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:37,179] Trial 267 finished with value: 0.9129476465055412 and parameters: {'n_estimators': 100, 'learning_rate': 0.014430129056420661, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:39,729] Trial 268 finished with value: 0.9195481074326798 and parameters: {'n_estimators': 150, 'learning_rate': 0.01571680962961056, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:42,498] Trial 269 finished with value: 0.9145897821476769 and parameters: {'n_estimators': 150, 'learning_rate': 0.011457921860752026, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:45,046] Trial 270 finished with value: 0.9196108127155773 and parameters: {'n_estimators': 150, 'learning_rate': 0.01422994838904282, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:47,734] Trial 271 finished with value: 0.9043968918772691 and parameters: {'n_estimators': 150, 'learning_rate': 0.012846232704153237, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:50,280] Trial 272 finished with value: 0.9196108127155773 and parameters: {'n_estimators': 150, 'learning_rate': 0.015445438071679436, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:52,829] Trial 273 finished with value: 0.9178224371567099 and parameters: {'n_estimators': 150, 'learning_rate': 0.014250115963102673, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:54,512] Trial 274 finished with value: 0.9143698974103975 and parameters: {'n_estimators': 100, 'learning_rate': 0.013201026216019552, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:57,270] Trial 275 finished with value: 0.9159612107191055 and parameters: {'n_estimators': 150, 'learning_rate': 0.012095153089909003, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:37:59,863] Trial 276 finished with value: 0.9211106252390117 and parameters: {'n_estimators': 150, 'learning_rate': 0.01498064215677146, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:02,475] Trial 277 finished with value: 0.9196108127155773 and parameters: {'n_estimators': 150, 'learning_rate': 0.01609274115856065, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:05,025] Trial 278 finished with value: 0.9225217706677735 and parameters: {'n_estimators': 150, 'learning_rate': 0.013665887930364455, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:07,601] Trial 279 finished with value: 0.9225217706677735 and parameters: {'n_estimators': 150, 'learning_rate': 0.013529746584968246, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:10,160] Trial 280 finished with value: 0.9179268698384254 and parameters: {'n_estimators': 150, 'learning_rate': 0.011013456262641323, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:11,575] Trial 281 finished with value: 0.8928502856874221 and parameters: {'n_estimators': 150, 'learning_rate': 0.012946558205225703, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:14,164] Trial 282 finished with value: 0.9182393841441486 and parameters: {'n_estimators': 150, 'learning_rate': 0.01185455803918691, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:16,746] Trial 283 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.013703713084944051, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:19,323] Trial 284 finished with value: 0.9206859458579126 and parameters: {'n_estimators': 150, 'learning_rate': 0.013033854074026022, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:22,135] Trial 285 finished with value: 0.9194534316295082 and parameters: {'n_estimators': 150, 'learning_rate': 0.013861144884667822, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:24,715] Trial 286 finished with value: 0.9206859458579126 and parameters: {'n_estimators': 150, 'learning_rate': 0.012372788409804773, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:27,288] Trial 287 finished with value: 0.9223453927150176 and parameters: {'n_estimators': 150, 'learning_rate': 0.014217575129144202, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:29,843] Trial 288 finished with value: 0.9164108127155772 and parameters: {'n_estimators': 150, 'learning_rate': 0.01154913907016571, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:33,280] Trial 289 finished with value: 0.9180820030580795 and parameters: {'n_estimators': 200, 'learning_rate': 0.01277814305326467, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:35,978] Trial 290 finished with value: 0.9094786589437506 and parameters: {'n_estimators': 150, 'learning_rate': 0.013649144726329488, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:37,665] Trial 291 finished with value: 0.9146224371567099 and parameters: {'n_estimators': 100, 'learning_rate': 0.014433148838608297, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:40,201] Trial 292 finished with value: 0.919168536292813 and parameters: {'n_estimators': 150, 'learning_rate': 0.012211967555694727, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:42,747] Trial 293 finished with value: 0.9193907263466109 and parameters: {'n_estimators': 150, 'learning_rate': 0.013218964776145705, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:45,276] Trial 294 finished with value: 0.9179282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.01046888606035601, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:47,832] Trial 295 finished with value: 0.9179360220644085 and parameters: {'n_estimators': 150, 'learning_rate': 0.0164107240817588, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:49,789] Trial 296 finished with value: 0.9032199975949975 and parameters: {'n_estimators': 100, 'learning_rate': 0.014551707660794196, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:52,333] Trial 297 finished with value: 0.9196108127155773 and parameters: {'n_estimators': 150, 'learning_rate': 0.013616187806566081, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:54,891] Trial 298 finished with value: 0.9177518443279208 and parameters: {'n_estimators': 150, 'learning_rate': 0.011911916403051477, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:38:57,436] Trial 299 finished with value: 0.9211526762900382 and parameters: {'n_estimators': 150, 'learning_rate': 0.012664883959217742, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:00,187] Trial 300 finished with value: 0.9193375886718613 and parameters: {'n_estimators': 150, 'learning_rate': 0.011123729086437118, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:03,583] Trial 301 finished with value: 0.913743300540564 and parameters: {'n_estimators': 200, 'learning_rate': 0.012605054669761175, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:06,118] Trial 302 finished with value: 0.9181545590455832 and parameters: {'n_estimators': 150, 'learning_rate': 0.012780409344310387, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:08,429] Trial 303 finished with value: 0.9179106252390117 and parameters: {'n_estimators': 150, 'learning_rate': 0.01355938293395859, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:10,987] Trial 304 finished with value: 0.9182393841441486 and parameters: {'n_estimators': 150, 'learning_rate': 0.011706529750373201, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:13,533] Trial 305 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.013895978711535608, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:16,926] Trial 306 finished with value: 0.9225041736261085 and parameters: {'n_estimators': 200, 'learning_rate': 0.012654146984929579, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:20,313] Trial 307 finished with value: 0.9210043611026739 and parameters: {'n_estimators': 200, 'learning_rate': 0.011019059488217986, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:21,958] Trial 308 finished with value: 0.8942232654533171 and parameters: {'n_estimators': 100, 'learning_rate': 0.012310097171263228, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:25,361] Trial 309 finished with value: 0.9164612064163646 and parameters: {'n_estimators': 200, 'learning_rate': 0.01291289775563518, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:29,087] Trial 310 finished with value: 0.9166095216037288 and parameters: {'n_estimators': 200, 'learning_rate': 0.014984034167993645, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:31,618] Trial 311 finished with value: 0.9111417439872287 and parameters: {'n_estimators': 150, 'learning_rate': 0.011827491788846657, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:34,168] Trial 312 finished with value: 0.9183927193632112 and parameters: {'n_estimators': 150, 'learning_rate': 0.016270252398038924, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:35,869] Trial 313 finished with value: 0.9105221238735017 and parameters: {'n_estimators': 100, 'learning_rate': 0.013172547615584604, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:38,170] Trial 314 finished with value: 0.9144426972218594 and parameters: {'n_estimators': 150, 'learning_rate': 0.014486066278481346, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:40,708] Trial 315 finished with value: 0.9206859458579126 and parameters: {'n_estimators': 150, 'learning_rate': 0.012537175790290938, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:42,422] Trial 316 finished with value: 0.9128772984881056 and parameters: {'n_estimators': 150, 'learning_rate': 0.015455287406764408, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:45,198] Trial 317 finished with value: 0.9144254895631923 and parameters: {'n_estimators': 150, 'learning_rate': 0.013417881585870317, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:47,748] Trial 318 finished with value: 0.920846980016605 and parameters: {'n_estimators': 150, 'learning_rate': 0.01438544856673878, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:50,303] Trial 319 finished with value: 0.9206859458579126 and parameters: {'n_estimators': 150, 'learning_rate': 0.011487131181248033, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:52,844] Trial 320 finished with value: 0.919168536292813 and parameters: {'n_estimators': 150, 'learning_rate': 0.012498071808391664, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:55,442] Trial 321 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.013743930963286218, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:56,966] Trial 322 finished with value: 0.905337606906141 and parameters: {'n_estimators': 100, 'learning_rate': 0.010818526268186338, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:39:59,524] Trial 323 finished with value: 0.9209518443279208 and parameters: {'n_estimators': 150, 'learning_rate': 0.015068716411136083, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:40:02,132] Trial 324 finished with value: 0.9178547548034613 and parameters: {'n_estimators': 150, 'learning_rate': 0.016589298463451297, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:40:04,674] Trial 325 finished with value: 0.9206859458579126 and parameters: {'n_estimators': 150, 'learning_rate': 0.013017830505587902, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:40:08,388] Trial 326 finished with value: 0.9150921120386293 and parameters: {'n_estimators': 200, 'learning_rate': 0.011895354862727425, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:40:10,933] Trial 327 finished with value: 0.9210043611026739 and parameters: {'n_estimators': 150, 'learning_rate': 0.013893409194827741, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:40:13,490] Trial 328 finished with value: 0.9179360220644085 and parameters: {'n_estimators': 150, 'learning_rate': 0.014582907941547596, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:40:16,026] Trial 329 finished with value: 0.919168536292813 and parameters: {'n_estimators': 150, 'learning_rate': 0.012830982083047057, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:40:18,605] Trial 330 finished with value: 0.9183028742329473 and parameters: {'n_estimators': 150, 'learning_rate': 0.01599938433352485, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:40:21,182] Trial 331 finished with value: 0.9098565102875952 and parameters: {'n_estimators': 150, 'learning_rate': 0.10980985767032189, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:40:28,862] Trial 332 finished with value: 0.9183701852507526 and parameters: {'n_estimators': 450, 'learning_rate': 0.013430173156421142, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:40:31,158] Trial 333 finished with value: 0.9106174140067104 and parameters: {'n_estimators': 150, 'learning_rate': 0.08374816227254517, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:40:34,556] Trial 334 finished with value: 0.9194344347628214 and parameters: {'n_estimators': 200, 'learning_rate': 0.01207793165491609, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:40:44,009] Trial 335 finished with value: 0.9166767133702617 and parameters: {'n_estimators': 500, 'learning_rate': 0.015246355585539707, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:40:46,555] Trial 336 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.014258711802071349, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:40:48,326] Trial 337 finished with value: 0.9033585963665622 and parameters: {'n_estimators': 100, 'learning_rate': 0.013022294744260332, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:40:50,863] Trial 338 finished with value: 0.9177785546510611 and parameters: {'n_estimators': 150, 'learning_rate': 0.01137357963680601, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:40:53,434] Trial 339 finished with value: 0.9149073998834764 and parameters: {'n_estimators': 150, 'learning_rate': 0.013720306722790539, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:40:56,214] Trial 340 finished with value: 0.9178856647284668 and parameters: {'n_estimators': 150, 'learning_rate': 0.015273729351615268, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:40:58,741] Trial 341 finished with value: 0.9192959642161608 and parameters: {'n_estimators': 150, 'learning_rate': 0.010294679752833373, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:01,315] Trial 342 finished with value: 0.9207457781619695 and parameters: {'n_estimators': 150, 'learning_rate': 0.016679356545668274, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:03,683] Trial 343 finished with value: 0.9108997455470739 and parameters: {'n_estimators': 150, 'learning_rate': 0.1370508473155004, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:07,079] Trial 344 finished with value: 0.9193295704515053 and parameters: {'n_estimators': 200, 'learning_rate': 0.012404679260082369, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:09,625] Trial 345 finished with value: 0.9179360220644085 and parameters: {'n_estimators': 150, 'learning_rate': 0.014372576576450798, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:12,172] Trial 346 finished with value: 0.9225217706677735 and parameters: {'n_estimators': 150, 'learning_rate': 0.013196752914880075, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:14,717] Trial 347 finished with value: 0.9196108127155773 and parameters: {'n_estimators': 150, 'learning_rate': 0.011978812272699382, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:17,258] Trial 348 finished with value: 0.9188063420987052 and parameters: {'n_estimators': 150, 'learning_rate': 0.013054522871867607, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:18,944] Trial 349 finished with value: 0.9161362362296099 and parameters: {'n_estimators': 100, 'learning_rate': 0.014342475146990604, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:21,273] Trial 350 finished with value: 0.9144705132133154 and parameters: {'n_estimators': 150, 'learning_rate': 0.01564744437192634, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:22,948] Trial 351 finished with value: 0.9077141509210348 and parameters: {'n_estimators': 100, 'learning_rate': 0.011106857765326859, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:25,592] Trial 352 finished with value: 0.9050656247347423 and parameters: {'n_estimators': 150, 'learning_rate': 0.012383235295634816, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:28,136] Trial 353 finished with value: 0.9225217706677735 and parameters: {'n_estimators': 150, 'learning_rate': 0.013788841106840241, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:30,685] Trial 354 finished with value: 0.9225217706677735 and parameters: {'n_estimators': 150, 'learning_rate': 0.014763714009683295, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:34,130] Trial 355 finished with value: 0.9150985108043587 and parameters: {'n_estimators': 200, 'learning_rate': 0.016662516602302186, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:35,204] Trial 356 finished with value: 0.893743023824138 and parameters: {'n_estimators': 150, 'learning_rate': 0.014988383754450073, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:37,996] Trial 357 finished with value: 0.9180843372517729 and parameters: {'n_estimators': 150, 'learning_rate': 0.015847056967376677, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:40,536] Trial 358 finished with value: 0.9116865161004979 and parameters: {'n_estimators': 150, 'learning_rate': 0.014474465114867252, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:43,102] Trial 359 finished with value: 0.9193295704515053 and parameters: {'n_estimators': 150, 'learning_rate': 0.017276038029508736, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:45,647] Trial 360 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.014244644641985608, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:48,184] Trial 361 finished with value: 0.9179268698384254 and parameters: {'n_estimators': 150, 'learning_rate': 0.01268028796031522, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:50,488] Trial 362 finished with value: 0.915827877385772 and parameters: {'n_estimators': 150, 'learning_rate': 0.015749037432020014, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:52,215] Trial 363 finished with value: 0.9175106991965294 and parameters: {'n_estimators': 100, 'learning_rate': 0.2720337702526181, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:54,968] Trial 364 finished with value: 0.9163804157564923 and parameters: {'n_estimators': 150, 'learning_rate': 0.011736390133369717, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:56,811] Trial 365 finished with value: 0.8951157078434351 and parameters: {'n_estimators': 200, 'learning_rate': 0.013361847576038404, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:41:59,386] Trial 366 finished with value: 0.9179360220644085 and parameters: {'n_estimators': 150, 'learning_rate': 0.015122029587795127, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:01,932] Trial 367 finished with value: 0.9225217706677735 and parameters: {'n_estimators': 150, 'learning_rate': 0.014044769985447157, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:04,481] Trial 368 finished with value: 0.9179360220644085 and parameters: {'n_estimators': 150, 'learning_rate': 0.014234253553354448, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:07,021] Trial 369 finished with value: 0.9210043611026739 and parameters: {'n_estimators': 150, 'learning_rate': 0.012725243688387265, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:09,594] Trial 370 finished with value: 0.9180820030580795 and parameters: {'n_estimators': 150, 'learning_rate': 0.01499939677138298, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:12,161] Trial 371 finished with value: 0.9179360220644085 and parameters: {'n_estimators': 150, 'learning_rate': 0.017245086368314882, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:14,707] Trial 372 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.014091572732977977, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:18,119] Trial 373 finished with value: 0.9151610873652857 and parameters: {'n_estimators': 200, 'learning_rate': 0.015971144387910953, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:20,904] Trial 374 finished with value: 0.9177312089563697 and parameters: {'n_estimators': 150, 'learning_rate': 0.01205396790240093, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:22,435] Trial 375 finished with value: 0.9085016290508827 and parameters: {'n_estimators': 100, 'learning_rate': 0.013337079692417778, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:24,980] Trial 376 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.01474685531743845, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:27,577] Trial 377 finished with value: 0.91723833846746 and parameters: {'n_estimators': 150, 'learning_rate': 0.056724633083316406, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:30,116] Trial 378 finished with value: 0.9181790130549444 and parameters: {'n_estimators': 150, 'learning_rate': 0.012733300749315734, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:32,872] Trial 379 finished with value: 0.9144460592039539 and parameters: {'n_estimators': 150, 'learning_rate': 0.011433859984118883, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:35,426] Trial 380 finished with value: 0.920642166908566 and parameters: {'n_estimators': 150, 'learning_rate': 0.01387371338658484, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:38,837] Trial 381 finished with value: 0.9117281533281533 and parameters: {'n_estimators': 200, 'learning_rate': 0.015323730406716906, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:40,521] Trial 382 finished with value: 0.9134032939185847 and parameters: {'n_estimators': 100, 'learning_rate': 0.013057998124700017, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:43,083] Trial 383 finished with value: 0.9177785546510611 and parameters: {'n_estimators': 150, 'learning_rate': 0.01080169729683008, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:45,385] Trial 384 finished with value: 0.9224251645944278 and parameters: {'n_estimators': 150, 'learning_rate': 0.016459173470060255, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:47,696] Trial 385 finished with value: 0.9138891401537496 and parameters: {'n_estimators': 150, 'learning_rate': 0.017834502069465286, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:50,100] Trial 386 finished with value: 0.9118524257941363 and parameters: {'n_estimators': 150, 'learning_rate': 0.01679178799677893, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:52,409] Trial 387 finished with value: 0.9158346884034543 and parameters: {'n_estimators': 150, 'learning_rate': 0.016184025194861954, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:54,724] Trial 388 finished with value: 0.9108762992037537 and parameters: {'n_estimators': 150, 'learning_rate': 0.010014047500177129, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:57,074] Trial 389 finished with value: 0.9158138011394378 and parameters: {'n_estimators': 150, 'learning_rate': 0.016034300193633364, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:42:59,472] Trial 390 finished with value: 0.9069507841968122 and parameters: {'n_estimators': 150, 'learning_rate': 0.01468625257850449, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:02,050] Trial 391 finished with value: 0.9181545590455832 and parameters: {'n_estimators': 150, 'learning_rate': 0.017603693806653237, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:03,778] Trial 392 finished with value: 0.9162520791872566 and parameters: {'n_estimators': 100, 'learning_rate': 0.014834508318874253, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:07,200] Trial 393 finished with value: 0.9194534316295082 and parameters: {'n_estimators': 200, 'learning_rate': 0.012290614930726874, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:09,744] Trial 394 finished with value: 0.9210043611026739 and parameters: {'n_estimators': 150, 'learning_rate': 0.01387008805713954, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:12,541] Trial 395 finished with value: 0.9209518443279208 and parameters: {'n_estimators': 150, 'learning_rate': 0.015832756339884606, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:14,542] Trial 396 finished with value: 0.9205702342159338 and parameters: {'n_estimators': 150, 'learning_rate': 0.012877164384844172, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:17,108] Trial 397 finished with value: 0.9210043611026739 and parameters: {'n_estimators': 150, 'learning_rate': 0.014149869639669922, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:19,644] Trial 398 finished with value: 0.9196108127155773 and parameters: {'n_estimators': 150, 'learning_rate': 0.012015505283653588, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:22,196] Trial 399 finished with value: 0.9226280348041114 and parameters: {'n_estimators': 150, 'learning_rate': 0.016463379223834902, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:24,755] Trial 400 finished with value: 0.9194534316295082 and parameters: {'n_estimators': 150, 'learning_rate': 0.017460147831939457, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:28,587] Trial 401 finished with value: 0.9127194253687492 and parameters: {'n_estimators': 250, 'learning_rate': 0.018447066360286722, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:32,200] Trial 402 finished with value: 0.910682760376878 and parameters: {'n_estimators': 200, 'learning_rate': 0.016697566894396765, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:34,752] Trial 403 finished with value: 0.9164797683944144 and parameters: {'n_estimators': 150, 'learning_rate': 0.015248841060332566, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:37,328] Trial 404 finished with value: 0.9184505212915977 and parameters: {'n_estimators': 150, 'learning_rate': 0.016101113797336423, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:39,898] Trial 405 finished with value: 0.9211106252390117 and parameters: {'n_estimators': 150, 'learning_rate': 0.014900657333931611, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:41,705] Trial 406 finished with value: 0.9080477908167761 and parameters: {'n_estimators': 100, 'learning_rate': 0.01668744657520479, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:44,253] Trial 407 finished with value: 0.9196108127155773 and parameters: {'n_estimators': 150, 'learning_rate': 0.01419409693027055, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:46,552] Trial 408 finished with value: 0.9091525691699605 and parameters: {'n_estimators': 150, 'learning_rate': 0.09823903393553045, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:49,105] Trial 409 finished with value: 0.9194534316295082 and parameters: {'n_estimators': 150, 'learning_rate': 0.015710472629302582, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:52,507] Trial 410 finished with value: 0.9165042224037758 and parameters: {'n_estimators': 200, 'learning_rate': 0.013532877377900281, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:55,058] Trial 411 finished with value: 0.9208279831499182 and parameters: {'n_estimators': 150, 'learning_rate': 0.014942012212310472, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:43:57,589] Trial 412 finished with value: 0.9164108127155772 and parameters: {'n_estimators': 150, 'learning_rate': 0.011698734119620847, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:00,149] Trial 413 finished with value: 0.9188063420987052 and parameters: {'n_estimators': 150, 'learning_rate': 0.013050673096767757, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:02,705] Trial 414 finished with value: 0.9196108127155773 and parameters: {'n_estimators': 150, 'learning_rate': 0.018061781560437626, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:05,253] Trial 415 finished with value: 0.9196108127155773 and parameters: {'n_estimators': 150, 'learning_rate': 0.014082937075841292, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:08,048] Trial 416 finished with value: 0.9147684942941259 and parameters: {'n_estimators': 150, 'learning_rate': 0.012613240349874351, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:10,581] Trial 417 finished with value: 0.9173095679051567 and parameters: {'n_estimators': 150, 'learning_rate': 0.010952457879291019, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:12,311] Trial 418 finished with value: 0.9105308342010876 and parameters: {'n_estimators': 150, 'learning_rate': 0.016926500595173026, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:14,315] Trial 419 finished with value: 0.9074933097043484 and parameters: {'n_estimators': 150, 'learning_rate': 0.015838227844358482, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:16,007] Trial 420 finished with value: 0.9179268698384254 and parameters: {'n_estimators': 100, 'learning_rate': 0.014651721033055337, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:16,841] Trial 421 finished with value: 0.8962928987399656 and parameters: {'n_estimators': 50, 'learning_rate': 0.013378065733322616, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:19,910] Trial 422 finished with value: 0.9130769648262186 and parameters: {'n_estimators': 200, 'learning_rate': 0.012455263633564206, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:22,461] Trial 423 finished with value: 0.9193295704515053 and parameters: {'n_estimators': 150, 'learning_rate': 0.015385904526491119, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:24,999] Trial 424 finished with value: 0.9194344347628214 and parameters: {'n_estimators': 150, 'learning_rate': 0.013613031515561936, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:27,531] Trial 425 finished with value: 0.9182393841441486 and parameters: {'n_estimators': 150, 'learning_rate': 0.011700656513642533, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:30,099] Trial 426 finished with value: 0.9198003525626886 and parameters: {'n_estimators': 150, 'learning_rate': 0.014363951716218258, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:32,414] Trial 427 finished with value: 0.9153856009630079 and parameters: {'n_estimators': 150, 'learning_rate': 0.01276324783552895, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:34,252] Trial 428 finished with value: 0.9177518443279208 and parameters: {'n_estimators': 100, 'learning_rate': 0.016576749557019925, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:36,799] Trial 429 finished with value: 0.9225217706677735 and parameters: {'n_estimators': 150, 'learning_rate': 0.015269581031680336, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:39,355] Trial 430 finished with value: 0.9194588887721828 and parameters: {'n_estimators': 150, 'learning_rate': 0.0180959478325745, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:41,911] Trial 431 finished with value: 0.9209518443279208 and parameters: {'n_estimators': 150, 'learning_rate': 0.01560375346797097, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:45,330] Trial 432 finished with value: 0.9105466185106588 and parameters: {'n_estimators': 200, 'learning_rate': 0.016892152200364406, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:48,107] Trial 433 finished with value: 0.9194534316295082 and parameters: {'n_estimators': 150, 'learning_rate': 0.015034730490521446, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:50,656] Trial 434 finished with value: 0.9196719686106827 and parameters: {'n_estimators': 150, 'learning_rate': 0.014590418385215013, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:53,275] Trial 435 finished with value: 0.9140652245983538 and parameters: {'n_estimators': 150, 'learning_rate': 0.015904887136638148, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:55,843] Trial 436 finished with value: 0.9208279831499182 and parameters: {'n_estimators': 150, 'learning_rate': 0.013993478484226213, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:44:58,912] Trial 437 finished with value: 0.9139502960488551 and parameters: {'n_estimators': 200, 'learning_rate': 0.014976102565337506, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:00,603] Trial 438 finished with value: 0.9162534316295081 and parameters: {'n_estimators': 100, 'learning_rate': 0.013862298472282828, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:03,159] Trial 439 finished with value: 0.9194344347628214 and parameters: {'n_estimators': 150, 'learning_rate': 0.016223281800065395, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:05,701] Trial 440 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.012647306791739102, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:08,250] Trial 441 finished with value: 0.912752879770333 and parameters: {'n_estimators': 150, 'learning_rate': 0.011427048491330633, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:10,556] Trial 442 finished with value: 0.9148653403850859 and parameters: {'n_estimators': 150, 'learning_rate': 0.017140008675715582, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:13,103] Trial 443 finished with value: 0.918241718337842 and parameters: {'n_estimators': 150, 'learning_rate': 0.013344187592786433, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:15,651] Trial 444 finished with value: 0.9179360220644085 and parameters: {'n_estimators': 150, 'learning_rate': 0.014626350461308281, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:18,234] Trial 445 finished with value: 0.9174121148382095 and parameters: {'n_estimators': 150, 'learning_rate': 0.1960295179702091, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:20,122] Trial 446 finished with value: 0.9123178775555889 and parameters: {'n_estimators': 100, 'learning_rate': 0.042014331841646414, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:22,684] Trial 447 finished with value: 0.9211282222806767 and parameters: {'n_estimators': 150, 'learning_rate': 0.018401847433143003, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:25,159] Trial 448 finished with value: 0.9059168831168831 and parameters: {'n_estimators': 150, 'learning_rate': 0.012039221137432624, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:27,748] Trial 449 finished with value: 0.9112446037715503 and parameters: {'n_estimators': 150, 'learning_rate': 0.0470081681578864, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:30,052] Trial 450 finished with value: 0.914573739019767 and parameters: {'n_estimators': 150, 'learning_rate': 0.01568815915830347, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:33,460] Trial 451 finished with value: 0.9152607101056637 and parameters: {'n_estimators': 200, 'learning_rate': 0.014122766461477247, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:36,006] Trial 452 finished with value: 0.9191247573434664 and parameters: {'n_estimators': 150, 'learning_rate': 0.0131745125136377, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:38,553] Trial 453 finished with value: 0.9193295704515053 and parameters: {'n_estimators': 150, 'learning_rate': 0.01538141505056038, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:40,238] Trial 454 finished with value: 0.9114552792237003 and parameters: {'n_estimators': 100, 'learning_rate': 0.012536017059386093, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:43,001] Trial 455 finished with value: 0.9176627980206927 and parameters: {'n_estimators': 150, 'learning_rate': 0.01065628391747492, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:45,573] Trial 456 finished with value: 0.9212566062326827 and parameters: {'n_estimators': 150, 'learning_rate': 0.013983487494036322, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:48,153] Trial 457 finished with value: 0.9179360220644085 and parameters: {'n_estimators': 150, 'learning_rate': 0.01654895745232635, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:50,752] Trial 458 finished with value: 0.9184069624381571 and parameters: {'n_estimators': 150, 'learning_rate': 0.014424278216834027, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:53,877] Trial 459 finished with value: 0.914155984420594 and parameters: {'n_estimators': 200, 'learning_rate': 0.015382045038962398, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:56,453] Trial 460 finished with value: 0.9165821905346452 and parameters: {'n_estimators': 150, 'learning_rate': 0.013911897612590105, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:45:59,081] Trial 461 finished with value: 0.9223453927150176 and parameters: {'n_estimators': 150, 'learning_rate': 0.019071890105748404, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:01,664] Trial 462 finished with value: 0.9180630061913927 and parameters: {'n_estimators': 150, 'learning_rate': 0.017365155376891216, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:04,318] Trial 463 finished with value: 0.9127001656392368 and parameters: {'n_estimators': 150, 'learning_rate': 0.018170651738844027, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:06,922] Trial 464 finished with value: 0.9240215831912082 and parameters: {'n_estimators': 150, 'learning_rate': 0.01676673501829749, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:09,505] Trial 465 finished with value: 0.9198038647919731 and parameters: {'n_estimators': 150, 'learning_rate': 0.019177460775481905, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:11,888] Trial 466 finished with value: 0.9135344323372117 and parameters: {'n_estimators': 150, 'learning_rate': 0.018945690296463678, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:20,443] Trial 467 finished with value: 0.9111275691699603 and parameters: {'n_estimators': 450, 'learning_rate': 0.019659928040712052, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:23,024] Trial 468 finished with value: 0.9166071874100357 and parameters: {'n_estimators': 150, 'learning_rate': 0.017592382217213792, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:26,470] Trial 469 finished with value: 0.9125788674774264 and parameters: {'n_estimators': 200, 'learning_rate': 0.0167394292781772, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:28,810] Trial 470 finished with value: 0.9197751268647988 and parameters: {'n_estimators': 150, 'learning_rate': 0.017999808898734603, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:31,427] Trial 471 finished with value: 0.9186785604967422 and parameters: {'n_estimators': 150, 'learning_rate': 0.015299749251345229, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:33,444] Trial 472 finished with value: 0.9169970689645044 and parameters: {'n_estimators': 150, 'learning_rate': 0.01634349043289766, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:36,021] Trial 473 finished with value: 0.9211717811341172 and parameters: {'n_estimators': 150, 'learning_rate': 0.016882736130433715, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:41,198] Trial 474 finished with value: 0.9172541564715477 and parameters: {'n_estimators': 300, 'learning_rate': 0.01899195520570915, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:42,937] Trial 475 finished with value: 0.9138882617612092 and parameters: {'n_estimators': 100, 'learning_rate': 0.017606841382424538, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:45,515] Trial 476 finished with value: 0.9226280348041114 and parameters: {'n_estimators': 150, 'learning_rate': 0.016799547122976745, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:48,330] Trial 477 finished with value: 0.9124429002370178 and parameters: {'n_estimators': 150, 'learning_rate': 0.016610999807049574, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:51,787] Trial 478 finished with value: 0.9199399361581179 and parameters: {'n_estimators': 200, 'learning_rate': 0.018492903839963163, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:53,522] Trial 479 finished with value: 0.9100749982608625 and parameters: {'n_estimators': 100, 'learning_rate': 0.016116339832671595, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:56,109] Trial 480 finished with value: 0.9151126271003827 and parameters: {'n_estimators': 150, 'learning_rate': 0.01968041524354597, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:46:58,686] Trial 481 finished with value: 0.9212566062326827 and parameters: {'n_estimators': 150, 'learning_rate': 0.017711193478553357, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:47:01,003] Trial 482 finished with value: 0.9170606252390117 and parameters: {'n_estimators': 150, 'learning_rate': 0.015770074085149625, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:47:03,598] Trial 483 finished with value: 0.9212566062326827 and parameters: {'n_estimators': 150, 'learning_rate': 0.015172120641306635, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:47:06,177] Trial 484 finished with value: 0.9211717811341172 and parameters: {'n_estimators': 150, 'learning_rate': 0.016770299945227173, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:47:09,042] Trial 485 finished with value: 0.9174011479630249 and parameters: {'n_estimators': 150, 'learning_rate': 0.06820164436550373, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:47:11,664] Trial 486 finished with value: 0.9198675247794327 and parameters: {'n_estimators': 150, 'learning_rate': 0.015220745170010649, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:47:14,255] Trial 487 finished with value: 0.9212566062326827 and parameters: {'n_estimators': 150, 'learning_rate': 0.016188122510840744, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:47:17,364] Trial 488 finished with value: 0.9181003362136302 and parameters: {'n_estimators': 200, 'learning_rate': 0.014602183858240544, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:47:19,943] Trial 489 finished with value: 0.9152607101056637 and parameters: {'n_estimators': 150, 'learning_rate': 0.017765114604122435, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:47:24,252] Trial 490 finished with value: 0.9139728892106007 and parameters: {'n_estimators': 250, 'learning_rate': 0.020710347094410282, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:47:25,947] Trial 491 finished with value: 0.9165591279029414 and parameters: {'n_estimators': 100, 'learning_rate': 0.015028959632634063, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:47:28,733] Trial 492 finished with value: 0.914140482427789 and parameters: {'n_estimators': 150, 'learning_rate': 0.016078749213729104, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:47:31,310] Trial 493 finished with value: 0.9210043611026739 and parameters: {'n_estimators': 150, 'learning_rate': 0.017228961515209588, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:47:33,865] Trial 494 finished with value: 0.9194344347628214 and parameters: {'n_estimators': 150, 'learning_rate': 0.014753730474638724, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:47:36,453] Trial 495 finished with value: 0.9168000981059459 and parameters: {'n_estimators': 150, 'learning_rate': 0.018973061545093605, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:47:39,106] Trial 496 finished with value: 0.9108691961633137 and parameters: {'n_estimators': 150, 'learning_rate': 0.014128184420798323, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:47:41,421] Trial 497 finished with value: 0.9190396075910507 and parameters: {'n_estimators': 150, 'learning_rate': 0.01578161758286829, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:47:43,971] Trial 498 finished with value: 0.9225217706677735 and parameters: {'n_estimators': 150, 'learning_rate': 0.014149930433937308, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n",
      "[I 2025-03-15 20:47:46,531] Trial 499 finished with value: 0.9178547548034613 and parameters: {'n_estimators': 150, 'learning_rate': 0.016676336059831563, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 161 with value: 0.9242440150532417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 150, 'learning_rate': 0.01590104855939572, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}\n",
      "Model trained with accuracy: 0.9606\n",
      "Precision: 0.9737, Recall: 0.9024, F1-score: 0.9367, ROC-AUC: 0.9810\n",
      "Confusion Matrix:\n",
      "[[170   8]\n",
      " [  2  74]]\n",
      "Activity: CD, X shape: (4, 13), y shape: (4,)\n",
      "Activity CD: 4 correct, 0 incorrect\n",
      "Activity: FCF, X shape: (12, 13), y shape: (12,)\n",
      "Activity FCF: 11 correct, 1 incorrect\n",
      "Activity: FCS, X shape: (10, 13), y shape: (10,)\n",
      "Activity FCS: 7 correct, 3 incorrect\n",
      "Activity: FOB, X shape: (12, 13), y shape: (12,)\n",
      "Activity FOB: 12 correct, 0 incorrect\n",
      "Activity: FOL, X shape: (12, 13), y shape: (12,)\n",
      "Activity FOL: 12 correct, 0 incorrect\n",
      "Activity: FR, X shape: (12, 13), y shape: (12,)\n",
      "Activity FR: 11 correct, 1 incorrect\n",
      "Activity: K, X shape: (24, 13), y shape: (24,)\n",
      "Activity K: 23 correct, 1 incorrect\n",
      "Activity: KD, X shape: (2, 13), y shape: (2,)\n",
      "Activity KD: 2 correct, 0 incorrect\n",
      "Activity: KID, X shape: (4, 13), y shape: (4,)\n",
      "Activity KID: 4 correct, 0 incorrect\n",
      "Activity: LAF, X shape: (12, 13), y shape: (12,)\n",
      "Activity LAF: 9 correct, 3 incorrect\n",
      "Activity: LC, X shape: (12, 13), y shape: (12,)\n",
      "Activity LC: 12 correct, 0 incorrect\n",
      "Activity: LSF, X shape: (12, 13), y shape: (12,)\n",
      "Activity LSF: 12 correct, 0 incorrect\n",
      "Activity: MA, X shape: (9, 13), y shape: (9,)\n",
      "Activity MA: 9 correct, 0 incorrect\n",
      "Activity: PUF, X shape: (12, 13), y shape: (12,)\n",
      "Activity PUF: 12 correct, 0 incorrect\n",
      "Activity: RBS, X shape: (18, 13), y shape: (18,)\n",
      "Activity RBS: 18 correct, 0 incorrect\n",
      "Activity: S, X shape: (9, 13), y shape: (9,)\n",
      "Activity S: 9 correct, 0 incorrect\n",
      "Activity: SC, X shape: (12, 13), y shape: (12,)\n",
      "Activity SC: 12 correct, 0 incorrect\n",
      "Activity: SFB, X shape: (12, 13), y shape: (12,)\n",
      "Activity SFB: 12 correct, 0 incorrect\n",
      "Activity: SLB, X shape: (12, 13), y shape: (12,)\n",
      "Activity SLB: 11 correct, 1 incorrect\n",
      "Activity: STC, X shape: (12, 13), y shape: (12,)\n",
      "Activity STC: 12 correct, 0 incorrect\n",
      "Activity: TF, X shape: (12, 13), y shape: (12,)\n",
      "Activity TF: 12 correct, 0 incorrect\n",
      "Activity: WBS, X shape: (18, 13), y shape: (18,)\n",
      "Activity WBS: 18 correct, 0 incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Per-Activity Results:\n",
      "                               activity Actual Fall  correct  incorrect  \\\n",
      "0                            Close Door     No Fall        4          0   \n",
      "1                 Chair - Fall to Front        Fall       11          1   \n",
      "2                  Chair - Fall to side        Fall        7          3   \n",
      "3             Fall of object (Backpack)     No Fall       12          0   \n",
      "4         Fall of object (FaszienRolle)     No Fall       12          0   \n",
      "5                         Fall Recovery     No Fall       11          1   \n",
      "6        Kneeling down then standing up     No Fall       23          1   \n",
      "7                            Knock Door     No Fall        2          0   \n",
      "8                          Kids Running     No Fall        4          0   \n",
      "9                    Lying - Awake Fall        Fall        9          3   \n",
      "10                 Laying down on couch     No Fall       12          0   \n",
      "11                  Lying - Asleep Fall        Fall       12          0   \n",
      "12  Minor Ambience (Sitting and Eating)     No Fall        9          0   \n",
      "13      Picking something up from floor     No Fall       12          0   \n",
      "14                       Rush by Sensor     No Fall       18          0   \n",
      "15                                Still     No Fall        9          0   \n",
      "16                Sitting down on chair     No Fall       12          0   \n",
      "17            Slip and Fall - Backwards        Fall       12          0   \n",
      "18                Standing Lost Balance        Fall       11          1   \n",
      "19                  Stand up from Chair     No Fall       12          0   \n",
      "20             Trip and Fall - Forwards        Fall       12          0   \n",
      "21                       Walk by Sensor     No Fall       18          0   \n",
      "\n",
      "    total  accuracy  \n",
      "0       4  1.000000  \n",
      "1      12  0.916667  \n",
      "2      10  0.700000  \n",
      "3      12  1.000000  \n",
      "4      12  1.000000  \n",
      "5      12  0.916667  \n",
      "6      24  0.958333  \n",
      "7       2  1.000000  \n",
      "8       4  1.000000  \n",
      "9      12  0.750000  \n",
      "10     12  1.000000  \n",
      "11     12  1.000000  \n",
      "12      9  1.000000  \n",
      "13     12  1.000000  \n",
      "14     18  1.000000  \n",
      "15      9  1.000000  \n",
      "16     12  1.000000  \n",
      "17     12  1.000000  \n",
      "18     12  0.916667  \n",
      "19     12  1.000000  \n",
      "20     12  1.000000  \n",
      "21     18  1.000000  \n",
      "Distance: 0, X shape: (13, 13), y shape: (13,)\n",
      "Distance 0: 13 correct, 0 incorrect\n",
      "Distance: 1, X shape: (64, 13), y shape: (64,)\n",
      "Distance 1: 63 correct, 1 incorrect\n",
      "Distance: 2, X shape: (92, 13), y shape: (92,)\n",
      "Distance 2: 88 correct, 4 incorrect\n",
      "Distance: 3, X shape: (85, 13), y shape: (85,)\n",
      "Distance 3: 80 correct, 5 incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Per-Distance Results:\n",
      "   distance  correct  incorrect  total  accuracy\n",
      "0         0       13          0     13  1.000000\n",
      "1         1       63          1     64  0.984375\n",
      "2         2       88          4     92  0.956522\n",
      "3         3       80          5     85  0.941176\n",
      "ðŸƒ View run red_rose_5qylr954 at: https://northeurope.api.azureml.ms/mlflow/v2.0/subscriptions/716d3e14-e009-4f92-89c9-01fa8347272a/resourceGroups/adda23ac-rg/providers/Microsoft.MachineLearningServices/workspaces/fall/#/experiments/d26258ba-da47-4538-9d29-dc17a3480b45/runs/091295cc-c314-4682-97a7-9dec27653b9a\n",
      "ðŸ§ª View experiment at: https://northeurope.api.azureml.ms/mlflow/v2.0/subscriptions/716d3e14-e009-4f92-89c9-01fa8347272a/resourceGroups/adda23ac-rg/providers/Microsoft.MachineLearningServices/workspaces/fall/#/experiments/d26258ba-da47-4538-9d29-dc17a3480b45\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trained_model = train_pipe(\n",
    "    model=model,\n",
    "    dataset_name=\"MPU_features.csv\",\n",
    "    save_name=\"MF_All_GBM_KFoldOptuna_Final\",\n",
    "    feature_columns=[\"max\", \"min\", \"mean\", \"std\", \"median\", \"peak\", \"p2p\", \"energy\", \"rms\", \"crest\", \"shape\", \"impulse\", \"margin\"],\n",
    "    target_column=\"fall_binary\",\n",
    "    experiment_name=\"Classic Models MPU\",\n",
    "    use_early_stopping=False,\n",
    "    if_optuna=True,\n",
    "    n_trials=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model does not support feature importance.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Usage (after training a model)\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mplot_feature_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmedian\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mp2p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimpulse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 14\u001b[0m, in \u001b[0;36mplot_feature_importance\u001b[0;34m(model, feature_columns)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_importances_\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# Ensure model supports feature importance\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     importances \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[0;32m---> 14\u001b[0m     feature_importance_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFeature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mImportance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimportances\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     feature_importance_df \u001b[38;5;241m=\u001b[39m feature_importance_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[0;32m~/Desktop/Master These/master/.venv/lib/python3.10/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/Desktop/Master These/master/.venv/lib/python3.10/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Master These/master/.venv/lib/python3.10/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/Desktop/Master These/master/.venv/lib/python3.10/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "def plot_feature_importance(model, feature_columns):\n",
    "    \"\"\"\n",
    "    Plots feature importance for tree-based models.\n",
    "\n",
    "    Args:\n",
    "        model: Trained XGBoost, RandomForest, or GradientBoosting model.\n",
    "        feature_columns: List of feature names.\n",
    "\n",
    "    Returns:\n",
    "        None (Displays feature importance plot)\n",
    "    \"\"\"\n",
    "    if hasattr(model, \"feature_importances_\"):  # Ensure model supports feature importance\n",
    "        importances = model.feature_importances_\n",
    "        feature_importance_df = pd.DataFrame({\"Feature\": feature_columns, \"Importance\": importances})\n",
    "        feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.barplot(x=\"Importance\", y=\"Feature\", data=feature_importance_df[:15])  # Top 15 features\n",
    "        plt.title(\"Feature Importance\")\n",
    "        plt.show()\n",
    "\n",
    "        return feature_importance_df\n",
    "    else:\n",
    "        raise ValueError(\"This model does not support feature importance.\")\n",
    "\n",
    "# Usage (after training a model)\n",
    "plot_feature_importance(trained_model, [\"median\", \"max\", \"mean\", \"p2p\", \"impulse\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def ensemble_predict(models_with_features, dataset_name, target_column):\n",
    "    \"\"\"\n",
    "    Loads a dataset, splits it, loads an ensemble of models (with different feature sets),\n",
    "    and predicts on the test set.\n",
    "\n",
    "    Args:\n",
    "        models_with_features: A list of tuples (model_path, feature_columns) specifying each model's file path\n",
    "                              and the corresponding feature columns used for training.\n",
    "        dataset_name: The name of the dataset CSV file.\n",
    "        target_column: The name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    # âœ… Load dataset\n",
    "    df = load_data(dataset_name)\n",
    "\n",
    "    # âœ… Ensure target column exists\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' not found in dataset.\")\n",
    "\n",
    "    # âœ… Train-test split\n",
    "    data_train, data_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    y_test = data_test[target_column].values  # Target remains the same for all models\n",
    "\n",
    "    # âœ… Load models and their feature columns\n",
    "    models = []\n",
    "    y_preds = []\n",
    "\n",
    "    for model_path, feature_columns in models_with_features:\n",
    "        model = joblib.load(model_path)  # Load model\n",
    "        models.append(model)\n",
    "\n",
    "        # âœ… Extract the correct feature set for this model\n",
    "        X_test = data_test[feature_columns].values  # Select only the features it was trained on\n",
    "\n",
    "        # âœ… Predict (check if the model has `predict_proba` for probability averaging)\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]  # Get probability of the positive class\n",
    "        else:\n",
    "            y_pred_proba = model.predict(X_test)  # Some models might not have `predict_proba`\n",
    "\n",
    "        y_preds.append(y_pred_proba)\n",
    "\n",
    "    # âœ… Ensemble predictions (Average probabilities and threshold at 0.5)\n",
    "    y_pred = np.mean(y_preds, axis=0) > 0.5\n",
    "\n",
    "    # âœ… Compute metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    # âœ… Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # âœ… Print metrics\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    # âœ… Plot confusion matrix\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=[\"No Fall\", \"Fall\"], yticklabels=[\"No Fall\", \"Fall\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9764\n",
      "Precision: 0.9615\n",
      "Recall: 0.9615\n",
      "F1 Score: 0.9615\n",
      "ROC AUC: 0.9722\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ensemble_predict(\n",
    "    models_with_features=[\n",
    "        (\"models/MF_XGB_Optuna.pkl\", [\"max\", \"min\", \"mean\", \"std\", \"median\", \"peak\", \"p2p\", \"energy\", \"rms\", \"crest\", \"shape\", \"impulse\", \"margin\"]),  \n",
    "        (\"models/MF_XGB_RD40_Optuna.pkl\", [\"median\", \"max\", \"peak\", \"mean\", \"p2p\"]),\n",
    "        (\"models/MF_XGB_RD41_Optuna.pkl\", [\"median\", \"max\", \"peak\", \"mean\", \"p2p\"])    \n",
    "    ],\n",
    "    dataset_name=\"MPU_features_pca.csv\",\n",
    "    target_column=\"fall_binary\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
