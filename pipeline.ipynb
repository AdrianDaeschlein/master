{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "\n",
    "# Data Handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning & Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "import optuna\n",
    "\n",
    "# Model Saving & Experiment Tracking\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow ui --port 5000\n",
      "[2025-03-13 19:32:07 +0100] [86116] [INFO] Starting gunicorn 23.0.0\n",
      "[2025-03-13 19:32:07 +0100] [86116] [ERROR] Connection in use: ('0.0.0.0', 5000)\n",
      "[2025-03-13 19:32:07 +0100] [86116] [ERROR] connection to ('0.0.0.0', 5000) failed: [Errno 48] Address already in use\n",
      "[2025-03-13 19:32:08 +0100] [86116] [ERROR] Connection in use: ('0.0.0.0', 5000)\n",
      "[2025-03-13 19:32:08 +0100] [86116] [ERROR] connection to ('0.0.0.0', 5000) failed: [Errno 48] Address already in use\n",
      "[2025-03-13 19:32:09 +0100] [86116] [ERROR] Connection in use: ('0.0.0.0', 5000)\n",
      "[2025-03-13 19:32:09 +0100] [86116] [ERROR] connection to ('0.0.0.0', 5000) failed: [Errno 48] Address already in use\n",
      "[2025-03-13 19:32:10 +0100] [86116] [ERROR] Connection in use: ('0.0.0.0', 5000)\n",
      "[2025-03-13 19:32:10 +0100] [86116] [ERROR] connection to ('0.0.0.0', 5000) failed: [Errno 48] Address already in use\n",
      "[2025-03-13 19:32:11 +0100] [86116] [ERROR] Connection in use: ('0.0.0.0', 5000)\n",
      "[2025-03-13 19:32:11 +0100] [86116] [ERROR] connection to ('0.0.0.0', 5000) failed: [Errno 48] Address already in use\n",
      "[2025-03-13 19:32:12 +0100] [86116] [ERROR] Can't connect to ('0.0.0.0', 5000)\n",
      "Running the mlflow server failed. Please see the logs above for details.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "print(\"mlflow ui --port 5000\")\n",
    "!mlflow ui --port 5000 --host 0.0.0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    '''\n",
    "    Load data from a csv file into a pandas dataframe.\n",
    "    \n",
    "    Args:\n",
    "    file_name: The name of the csv file to load\n",
    "    \n",
    "    Returns:\n",
    "    df: A pandas dataframe containing the data from the csv file\n",
    "    '''\n",
    "    folder = \"datasets\"\n",
    "\n",
    "    df = pd.read_csv(f\"{folder}/{file_name}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratify Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_activity_split(df, target_column=\"fall_binary\", test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the dataset while ensuring 20% of each 'activity' is in the test set.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The full dataset containing 'activity' and the target variable.\n",
    "        target_column (str): The column representing the target labels.\n",
    "        test_size (float): The fraction of each activity to be in the test set.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        data_train (pd.DataFrame): Training set.\n",
    "        data_test (pd.DataFrame): Test set.\n",
    "    \"\"\"\n",
    "\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "\n",
    "    # âœ… Loop through each activity and apply train-test split\n",
    "    for activity, group in df.groupby(\"activity\"):\n",
    "        train, test = train_test_split(group, test_size=test_size, random_state=random_state, stratify=group[target_column])\n",
    "        train_list.append(train)\n",
    "        test_list.append(test)\n",
    "\n",
    "    # âœ… Concatenate results into train & test datasets\n",
    "    data_train = pd.concat(train_list).reset_index(drop=True)\n",
    "    data_test = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "    return data_train, data_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Per Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_per_activity(model, test_X, test_y, feature_columns=None):\n",
    "    \"\"\"\n",
    "    Evaluates model performance per activity type and logs the results in MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model (LSTM or Tree-based).\n",
    "        test_X: Test feature data (DataFrame).\n",
    "        test_y: Test target labels (Series).\n",
    "        target_column: The name of the target column.\n",
    "        feature_columns: The feature columns used for training.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame containing classification results per activity.\n",
    "    \"\"\"\n",
    "    \n",
    "    # âœ… Ensure X_test is a DataFrame\n",
    "    if not isinstance(test_X, pd.DataFrame):\n",
    "        test_X = pd.DataFrame(test_X, columns=feature_columns)\n",
    "\n",
    "    # âœ… Ensure y_test is a Series\n",
    "    if isinstance(test_y, pd.DataFrame):\n",
    "        test_y = test_y.squeeze()  # Convert to Series if needed\n",
    "\n",
    "    # âœ… Ensure 'activity' column exists\n",
    "    if \"activity\" not in test_X.columns:\n",
    "        raise ValueError(\"Dataset does not contain an 'activity' column.\")\n",
    "\n",
    "    is_lstm = isinstance(model, tf.keras.Model)\n",
    "    results = []\n",
    "\n",
    "    # âœ… Loop through each unique activity and evaluate model performance\n",
    "    for activity in test_X[\"activity\"].unique():\n",
    "        # Filter test data for the current activity\n",
    "        X_test_activity = test_X[test_X[\"activity\"] == activity].copy()\n",
    "\n",
    "        # Extract the actual labels\n",
    "        y_test_activity = test_y.loc[X_test_activity.index].values.flatten()  # Ensure correct shape\n",
    "\n",
    "        # âœ… Check for missing values\n",
    "        if np.isnan(y_test_activity).any():\n",
    "            print(f\"Warning: NaN values found in y_test_activity for activity {activity}!\")\n",
    "            y_test_activity = np.nan_to_num(y_test_activity, nan=0)  # Replace NaN with 0 (No Fall)\n",
    "\n",
    "        # âœ… Ensure y_test_activity is integer\n",
    "        try:\n",
    "            y_test_activity = y_test_activity.astype(int)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error converting y_test_activity to integer for activity {activity}: {e}\")\n",
    "            continue  # Skip this activity if conversion fails\n",
    "\n",
    "        # âœ… Select feature columns\n",
    "        if is_lstm:\n",
    "            feature_columns = [col for col in X_test_activity.columns if col.startswith(\"value\")]\n",
    "\n",
    "        X_test_activity = X_test_activity[feature_columns].values  # Extract feature values\n",
    "\n",
    "        print(f\"Activity: {activity}, X shape: {X_test_activity.shape}, y shape: {y_test_activity.shape}\")\n",
    "\n",
    "        # âœ… Reshape X for LSTM input\n",
    "        if is_lstm:\n",
    "            X_test_activity = X_test_activity.reshape(-1, 500, 1)\n",
    "\n",
    "        # âœ… Predict fall_binary values\n",
    "        y_pred = model.predict(X_test_activity).round().astype(int).flatten()\n",
    "\n",
    "        # âœ… Compute correct and incorrect counts\n",
    "        correct = np.sum(y_pred == y_test_activity)\n",
    "        incorrect = len(y_pred) - correct\n",
    "\n",
    "        # âœ… Determine if the first sample of the activity is a fall or not\n",
    "        actual_fall = \"Fall\" if y_test_activity[0] == 1 else \"No Fall\"\n",
    "\n",
    "        print(f\"Activity {activity}: {correct} correct, {incorrect} incorrect\")\n",
    "\n",
    "        # âœ… Store results\n",
    "        results.append({\n",
    "            \"activity\": activity,\n",
    "            \"Actual Fall\": actual_fall,  # âœ… Single column for actual fall status\n",
    "            \"correct\": correct,\n",
    "            \"incorrect\": incorrect,\n",
    "            \"total\": len(y_pred),\n",
    "            \"accuracy\": correct / len(y_pred) if len(y_pred) > 0 else 0\n",
    "        })\n",
    "\n",
    "    # âœ… Convert results into a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # âœ… Mapping dictionary from abbreviations to full names\n",
    "    activity_mapping = {\n",
    "        \"S\": \"Still\",\n",
    "        \"CD\": \"Close Door\",\n",
    "        \"KD\": \"Knock Door\",\n",
    "        \"MA\": \"Minor Ambience (Sitting and Eating)\",\n",
    "        \"FOB\": \"Fall of object (Backpack)\",\n",
    "        \"FOL\": \"Fall of object (FaszienRolle)\",\n",
    "        \"WBS\": \"Walk by Sensor\",\n",
    "        \"RBS\": \"Rush by Sensor\",\n",
    "        \"SC\": \"Sitting down on chair\",\n",
    "        \"LC\": \"Laying down on couch\",\n",
    "        \"STC\": \"Stand up from Chair\",\n",
    "        \"PUF\": \"Picking something up from floor\",\n",
    "        \"K\": \"Kneeling down then standing up\",\n",
    "        \"SLB\": \"Standing Lost Balance\",\n",
    "        \"TF\": \"Trip and Fall - Forwards\",\n",
    "        \"SFB\": \"Slip and Fall - Backwards\",\n",
    "        \"FCS\": \"Chair - Fall to side\",\n",
    "        \"FCF\": \"Chair - Fall to Front\",\n",
    "        \"LAF\": \"Lying - Awake Fall\",\n",
    "        \"LSF\": \"Lying - Asleep Fall\",\n",
    "        \"FR\": \"Fall Recovery\",\n",
    "        \"KID\": \"Kids Running\"\n",
    "    }\n",
    "\n",
    "    # âœ… Function to extract the relevant part before the first '_'\n",
    "    def get_activity_name(code):\n",
    "        key = code.split('_')[0]  # Extract first part of activity code\n",
    "        return activity_mapping.get(key, code)  # Replace with full name if exists\n",
    "\n",
    "    # âœ… Apply the mapping to the results dataframe\n",
    "    results_df[\"activity\"] = results_df[\"activity\"].apply(get_activity_name)\n",
    "\n",
    "    # âœ… Save the results as a CSV file\n",
    "    results_path = \"activity_results.csv\"\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "\n",
    "    # âœ… Log results in MLflow\n",
    "    mlflow.log_artifact(results_path)\n",
    "\n",
    "    print(\"\\nðŸ“Š Per-Activity Results:\")\n",
    "    print(results_df)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Per Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_per_distance(model, test_X, test_y, feature_columns=None):\n",
    "    \"\"\"\n",
    "    Evaluates model performance per distance type and logs the results in MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model (LSTM or Tree-based).\n",
    "        test_X: Test feature data (DataFrame).\n",
    "        test_y: Test target labels (Series).\n",
    "        feature_columns: The feature columns used for training.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame containing classification results per distance.\n",
    "    \"\"\"\n",
    "\n",
    "    X_test = test_X.copy()\n",
    "    y_test = test_y.copy()\n",
    "\n",
    "    # âœ… Ensure X_test is a DataFrame\n",
    "    if not isinstance(X_test, pd.DataFrame):\n",
    "        X_test = pd.DataFrame(X_test, columns=feature_columns)\n",
    "\n",
    "    # âœ… Ensure y_test is a Series\n",
    "    if isinstance(y_test, pd.DataFrame):\n",
    "        y_test = y_test.squeeze()  # Convert to Series if needed\n",
    "\n",
    "    is_lstm = isinstance(model, tf.keras.Model)\n",
    "\n",
    "    # âœ… Ensure 'distance_m' column exists\n",
    "    if \"distance_m\" not in X_test.columns:\n",
    "        raise ValueError(\"Dataset does not contain a 'distance_m' column.\")\n",
    "\n",
    "    # âœ… Get unique distances and setup subplots dynamically\n",
    "    unique_distances = sorted(X_test[\"distance_m\"].unique())\n",
    "    fig, axes = plt.subplots(len(unique_distances), 1, figsize=(6, 4 * len(unique_distances))) \n",
    "\n",
    "    results = []\n",
    "    confusion_matrices = {}\n",
    "\n",
    "    # âœ… Loop through each unique distance and evaluate model performance\n",
    "    for i, distance in enumerate(unique_distances):\n",
    "        X_test_distance = X_test[X_test[\"distance_m\"] == distance].copy()\n",
    "        y_test_distance = y_test.loc[X_test_distance.index].values.flatten()  # Ensure correct shape\n",
    "\n",
    "        # âœ… Select feature columns\n",
    "        if is_lstm:\n",
    "            feature_columns = [col for col in X_test_distance.columns if col.startswith(\"value\")]\n",
    "\n",
    "        X_test_distance = X_test_distance[feature_columns].values  # Extract feature values\n",
    "\n",
    "        print(f\"Distance: {distance}, X shape: {X_test_distance.shape}, y shape: {y_test_distance.shape}\")\n",
    "\n",
    "        # âœ… Reshape X for LSTM input\n",
    "        if is_lstm:\n",
    "            X_test_distance = X_test_distance.reshape(-1, 500, 1)\n",
    "\n",
    "        # âœ… Predict fall_binary values\n",
    "        y_pred = model.predict(X_test_distance).round().astype(int).flatten()\n",
    "\n",
    "        # âœ… Compute correct and incorrect counts\n",
    "        correct = np.sum(y_pred == y_test_distance)\n",
    "        incorrect = len(y_pred) - correct\n",
    "\n",
    "        # âœ… Compute confusion matrix, ensuring both classes appear\n",
    "        cm = confusion_matrix(y_test_distance, y_pred, labels=[1, 0])\n",
    "\n",
    "        # âœ… Ensure confusion matrix always has shape (2,2)\n",
    "        if cm.shape == (1, 1):  \n",
    "            cm_fixed = np.array([[cm[0, 0], 0], [0, 0]])  \n",
    "        elif cm.shape == (1, 2):  \n",
    "            cm_fixed = np.vstack([cm, [0, 0]])  \n",
    "        elif cm.shape == (2, 1):  \n",
    "            cm_fixed = np.hstack([cm, [[0], [0]]])  \n",
    "        else:\n",
    "            cm_fixed = cm  \n",
    "\n",
    "        # âœ… Correct confusion matrix order:\n",
    "        # TP | FN\n",
    "        # FP | TN\n",
    "        cm_corrected = np.array([\n",
    "            [cm_fixed[0, 0], cm_fixed[1, 0]],  # True Positives, False Negatives\n",
    "            [cm_fixed[0, 1], cm_fixed[1, 1]]   # False Positives, True Negatives\n",
    "        ])\n",
    "\n",
    "        confusion_matrices[distance] = cm_corrected\n",
    "\n",
    "        # âœ… Plot confusion matrix with **correct** labels\n",
    "        sns.heatmap(cm_corrected, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=[\"Actual Fall\", \"Actual No Fall\"], \n",
    "                    yticklabels=[\"Predicted Fall\", \"Predicted No Fall\"],\n",
    "                    ax=axes[i] if len(unique_distances) > 1 else axes)\n",
    "        axes[i].set_title(f\"Confusion Matrix - Distance {distance}\")\n",
    "        axes[i].set_xlabel(\" \")\n",
    "        axes[i].set_ylabel(\" \")\n",
    "\n",
    "        print(f\"Distance {distance}: {correct} correct, {incorrect} incorrect\")\n",
    "\n",
    "        # âœ… Store results\n",
    "        results.append({\n",
    "            \"distance\": distance,\n",
    "            \"correct\": correct,\n",
    "            \"incorrect\": incorrect,\n",
    "            \"total\": len(y_pred),\n",
    "            \"accuracy\": correct / len(y_pred) if len(y_pred) > 0 else 0\n",
    "        })\n",
    "\n",
    "    # âœ… Save and log confusion matrix plot\n",
    "    confusion_matrix_path = \"confusion_matrices_distance.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(confusion_matrix_path)\n",
    "    plt.close()\n",
    "\n",
    "    # âœ… Convert results into a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # âœ… Save results as CSV\n",
    "    results_path = \"distance_results.csv\"\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "\n",
    "    # âœ… Log results in MLflow\n",
    "    mlflow.log_artifact(results_path)\n",
    "    mlflow.log_artifact(confusion_matrix_path)\n",
    "\n",
    "    print(\"\\nðŸ“Š Per-Distance Results:\")\n",
    "    print(results_df)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classical Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, model_class, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Defines the Optuna optimization objective with K-Fold Cross-Validation.\n",
    "    \n",
    "    Args:\n",
    "        trial: Optuna trial object.\n",
    "        model_class: The model class (e.g., XGBClassifier, RandomForestClassifier, GradientBoostingClassifier, SVC).\n",
    "        X_train, y_train: Training data (without separate test split).\n",
    "\n",
    "    Returns:\n",
    "        The average F1-score across all folds.\n",
    "    \"\"\"\n",
    "\n",
    "    # Suggest hyperparameters based on model type\n",
    "    if model_class == XGBClassifier:\n",
    "        num_no_falls = sum(y_train == 0)\n",
    "        num_falls = sum(y_train == 1)\n",
    "        default_scale_pos_weight = num_no_falls / num_falls\n",
    "\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0, 10),\n",
    "            \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", default_scale_pos_weight * 0.5, default_scale_pos_weight * 1.5)\n",
    "        }\n",
    "        model = XGBClassifier(**params, objective=\"binary:logistic\", random_state=42)\n",
    "\n",
    "    elif model_class == RandomForestClassifier:\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        }\n",
    "        model = RandomForestClassifier(**params, random_state=42)\n",
    "\n",
    "    elif model_class == GradientBoostingClassifier:\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        }\n",
    "        model = GradientBoostingClassifier(**params, random_state=42)\n",
    "\n",
    "    elif model_class == SVC:\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.1, 100, log=True),\n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"]),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0.001, 10, log=True),\n",
    "        }\n",
    "        model = SVC(**params, probability=True, random_state=42)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model class: {model_class.__name__}\")\n",
    "\n",
    "    # K-Fold Cross-Validation (Stratified to preserve class balance)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    f1_scores = []\n",
    "\n",
    "    ## Loop through each fold\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]  \n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        ## Train and evaluate the model\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "        y_pred = model.predict(X_fold_val)\n",
    "        f1_scores.append(f1_score(y_fold_val, y_pred))\n",
    "\n",
    "    ## Return average F1-score across folds\n",
    "    return np.mean(f1_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3422155351.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[53], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# def objective(trial, model_class, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Defines the Optuna optimization objective for hyperparameter tuning.\n",
    "    \n",
    "    Args:\n",
    "        trial: Optuna trial object.\n",
    "        model_class: The model class (e.g., XGBClassifier, RandomForestClassifier, GradientBoostingClassifier, SVC).\n",
    "        X_train, X_test, y_train, y_test: Training and testing data.\n",
    "\n",
    "    Returns:\n",
    "        The validation F1-score of the model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Suggest hyperparameters based on model type\n",
    "    if model_class == XGBClassifier:\n",
    "        # Compute default scale_pos_weight (balance classes)\n",
    "        num_no_falls = sum(y_train == 0)\n",
    "        num_falls = sum(y_train == 1)\n",
    "        default_scale_pos_weight = num_no_falls / num_falls\n",
    "\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0, 10),\n",
    "            \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", default_scale_pos_weight * 0.25, default_scale_pos_weight * 2)\n",
    "        }\n",
    "        model = XGBClassifier(**params, objective=\"binary:logistic\", use_label_encoder=False, random_state=42)\n",
    "\n",
    "    elif model_class == RandomForestClassifier:\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        }\n",
    "        model = RandomForestClassifier(**params, random_state=42)\n",
    "\n",
    "    elif model_class == GradientBoostingClassifier:\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        }\n",
    "        model = GradientBoostingClassifier(**params, random_state=42)\n",
    "\n",
    "    elif model_class == SVC:\n",
    "        params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 0.1, 100, log=True),  # Adjusted range\n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"]),  # Removed \"poly\"\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0.001, 10, log=True),  # Avoid too small values\n",
    "        }\n",
    "        model = SVC(**params, probability=True, random_state=42)  # Keep probability only if needed\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model class: {model_class.__name__}\")\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate F1-score\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_log_classical_model(\n",
    "    model, \n",
    "    X_train, X_test, y_train, y_test, X_test_full,\n",
    "    save_name=\"classification_model\", \n",
    "    experiment_name=\"classical_models_experiment\",\n",
    "    target_column=\"fall_binary\",\n",
    "    feature_columns=None,\n",
    "    if_optuna=True,\n",
    "    n_trials=250,  # Number of hyperparameter tuning trials\n",
    "    dataset_name = \"fall_data.csv\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains a classical ML model (RandomForest, XGBoost, GradientBoosting, or SVM) with optional hyperparameter tuning\n",
    "    and logs everything to MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: A classical ML model (RandomForest, XGBoost, GradientBoosting, or SVM).\n",
    "        X_train, X_test, y_train, y_test: Pre-split training and testing datasets.\n",
    "        save_name: Name to save the trained model.\n",
    "        experiment_name: Name of the MLflow experiment.\n",
    "        n_trials: Number of hyperparameter tuning trials.\n",
    "\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Start MLflow experiment\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        # Identify model class\n",
    "        model_class = type(model)\n",
    "\n",
    "        if if_optuna:\n",
    "            # âœ… Perform hyperparameter optimization\n",
    "            study = optuna.create_study(direction=\"maximize\")\n",
    "            study.optimize(lambda trial: objective(trial, model_class, X_train, y_train), n_trials=n_trials)\n",
    "        \n",
    "            best_params = study.best_params\n",
    "            print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "            # âœ… Train final model with best params\n",
    "            if model_class == XGBClassifier:\n",
    "                best_model = XGBClassifier(**best_params, objective=\"binary:logistic\", use_label_encoder=False)\n",
    "            elif model_class.__name__ == \"GradientBoostingClassifier\":\n",
    "                best_model = model_class(**best_params, random_state=42)\n",
    "            elif model_class.__name__ == \"RandomForestClassifier\":\n",
    "                best_model = model_class(**best_params, random_state=42)\n",
    "            elif model_class == SVC:\n",
    "                best_model = SVC(**best_params, probability=True, random_state=42)  # âœ… Enable probability for ROC AUC\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported model class: {model_class.__name__}\")\n",
    "        else:\n",
    "            best_model = model\n",
    "\n",
    "        best_model.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "        # SVM needs probability predictions for AUC\n",
    "        if hasattr(best_model, \"predict_proba\"):\n",
    "            roc_auc = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "        # âœ… Log model parameters\n",
    "        mlflow.log_param(\"model_type\", best_model.__class__.__name__)\n",
    "        if if_optuna:\n",
    "            for param, value in best_params.items():\n",
    "                mlflow.log_param(param, value)\n",
    "        mlflow.log_param(\"num_features\", X_train.shape[1])\n",
    "\n",
    "        # Log features used for training as list\n",
    "        if feature_columns is not None:\n",
    "            mlflow.log_param(\"features\", feature_columns)\n",
    "        \n",
    "        # Log target column\n",
    "        mlflow.log_param(\"target_column\", target_column)\n",
    "        \n",
    "        mlflow.log_param(\"dataset\", dataset_name)\n",
    "            \n",
    "        # âœ… Log metrics\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "        # âœ… Save best model\n",
    "        models_folder = \"models\"\n",
    "        if not os.path.exists(models_folder):\n",
    "            os.makedirs(models_folder)\n",
    "        save_path = os.path.join(models_folder, f\"{save_name}.pkl\")\n",
    "        joblib.dump(best_model, save_path)\n",
    "        mlflow.log_artifact(save_path)\n",
    "\n",
    "        # Generate and save confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        conf_matrix = np.array([\n",
    "            [conf_matrix[0, 0], conf_matrix[1, 0]],  # True Positives, False Positives\n",
    "            [conf_matrix[0, 1], conf_matrix[1, 1]]   # False Negatives, True Negatives\n",
    "        ])\n",
    "\n",
    "        # Flip the order of labels for visualization\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(\n",
    "            conf_matrix[::-1, ::-1],  # Reverse rows and keep columns the same\n",
    "            annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Actual Fall\", \"Actual No Fall\"], \n",
    "            yticklabels=[\"Predicted Fall\", \"Predicted No Fall\"],\n",
    "        )\n",
    "        plt.xlabel(\" \")\n",
    "        plt.ylabel(\" \")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        conf_matrix_path = \"confusion_matrix.png\"\n",
    "        plt.savefig(conf_matrix_path)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(conf_matrix_path)\n",
    "\n",
    "        print(f\"Model trained with accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "        # âœ… After training and evaluation, call the per-activity evaluation\n",
    "        evaluate_per_activity(best_model, X_test_full, y_test, feature_columns)\n",
    "\n",
    "        # âœ… After training and evaluation, call the per-distance evaluation\n",
    "        evaluate_per_distance(best_model, X_test_full, y_test, feature_columns)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipe(\n",
    "    model, \n",
    "    dataset_name, \n",
    "    save_name=\"fall_model\", \n",
    "    feature_columns=None, \n",
    "    target_column=\"fall_binary\", \n",
    "    experiment_name=\"default_experiment\",\n",
    "    use_early_stopping=True,\n",
    "    if_optuna=True,\n",
    "    n_trials=250\n",
    "):\n",
    "    \"\"\"\n",
    "    General training pipeline for both classical models (XGBoost, RF, SVM) and deep learning models.\n",
    "\n",
    "    Args:\n",
    "        model: The initialized model (LSTM, RNN, RF, XGB, etc.).\n",
    "        dataset_name: The dataset CSV file.\n",
    "        save_name: Name to save the trained model.\n",
    "        feature_columns: List of feature column names.\n",
    "        target_column: The name of the target column.\n",
    "        experiment_name: MLflow experiment name.\n",
    "        use_early_stopping: Whether to use early stopping (for neural networks).\n",
    "        if_optuna: Whether to perform hyperparameter tuning (for tree-based models).\n",
    "\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    # âœ… Prevent overwriting existing models unless explicitly handled\n",
    "    if os.path.exists(f\"models/{save_name}.pkl\") or os.path.exists(f\"models/{save_name}.keras\"):\n",
    "        raise ValueError(f\"Model name '{save_name}' already exists. Choose a new name or delete the existing model.\")\n",
    "\n",
    "    # âœ… Load dataset\n",
    "    df = load_data(dataset_name)\n",
    "\n",
    "    # âœ… Auto-detect feature columns if not explicitly provided\n",
    "    value_columns = [col for col in df.columns if col.startswith(\"value\")]\n",
    "    if value_columns:\n",
    "        feature_columns = value_columns  \n",
    "    elif feature_columns is None:\n",
    "        raise ValueError(\"Feature columns must be specified.\")\n",
    "\n",
    "    # âœ… Ensure target column exists\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' not found in dataset.\")\n",
    "\n",
    "    data_train, data_test = stratified_activity_split(df, target_column=target_column, test_size=0.2, random_state=42)\n",
    "    print(f\"Train shape: {data_train.shape}, Test shape: {data_test.shape}\")\n",
    "\n",
    "    # âœ… Keep full test data (including metadata like 'activity' or 'distance_m')\n",
    "    X_test_full = data_test.copy()  \n",
    "\n",
    "    # âœ… Keep `X_train`, `X_test` as DataFrames & `y_train`, `y_test` as Series\n",
    "    X_train = data_train[feature_columns]  \n",
    "    X_test = data_test[feature_columns]    \n",
    "    y_train = data_train[target_column]  \n",
    "    y_test = data_test[target_column]    \n",
    "\n",
    "    # âœ… Check model type\n",
    "    is_tree = isinstance(model, (XGBClassifier, RandomForestClassifier, GradientBoostingClassifier))\n",
    "    is_svm = isinstance(model, SVC)\n",
    "\n",
    "    # âœ… Train tree-based models with optional Optuna hyperparameter tuning\n",
    "    if is_tree or is_svm:\n",
    "        model = train_and_log_classical_model(\n",
    "            model, X_train, X_test, y_train, y_test, X_test_full,\n",
    "            save_name=save_name,\n",
    "            experiment_name=experiment_name,\n",
    "            target_column=target_column,\n",
    "            feature_columns=feature_columns,\n",
    "            if_optuna=if_optuna,\n",
    "            n_trials=n_trials,\n",
    "            dataset_name=dataset_name\n",
    "        )\n",
    "    \n",
    "    # Delete the files activity_results.csv and distance_results.csv\n",
    "    os.remove(\"activity_results.csv\")\n",
    "    os.remove(\"distance_results.csv\")\n",
    "    os.remove(\"confusion_matrices_distance.png\")\n",
    "    os.remove(\"confusion_matrix.png\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mlflow.tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "def train_model(\n",
    "    model, \n",
    "    dataset_name, \n",
    "    save_name=\"lstm_fall_model\", \n",
    "    feature_columns=None, \n",
    "    target_column=\"fall_binary\", \n",
    "    experiment_name=\"default_experiment\",\n",
    "    use_early_stopping=True  # âœ… Option to enable/disable early stopping\n",
    "):\n",
    "    \"\"\"\n",
    "    Loads the dataset, reshapes it for RNN, trains the model, and logs everything to MLflow.\n",
    "\n",
    "    Args:\n",
    "        model: The RNN model (already defined).\n",
    "        dataset_name: The name of the dataset CSV file.\n",
    "        save_name: Name to save the trained model.\n",
    "        feature_columns: List of feature column names (overwritten if 'value' columns exist).\n",
    "        target_column: The name of the target column.\n",
    "        experiment_name: Name of the MLflow experiment.\n",
    "        use_early_stopping: Whether to enable early stopping based on validation loss.\n",
    "\n",
    "    Returns:\n",
    "        The trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load dataset\n",
    "    df = load_data(dataset_name)\n",
    "\n",
    "    # Auto-detect feature columns if they start with \"value\"\n",
    "    value_columns = [col for col in df.columns if col.startswith(\"value\")]\n",
    "    if value_columns:\n",
    "        feature_columns = value_columns  # Override feature selection\n",
    "    elif feature_columns is None:\n",
    "        raise ValueError(\"Feature columns must be specified if no 'value' columns exist.\")\n",
    "\n",
    "    # Ensure target column exists\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' not found in dataset.\")\n",
    "\n",
    "    # Train-test split but keep the full dataset for evaluation\n",
    "    data_train, data_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    print(f\"Train shape: {data_train.shape}, Test shape: {data_test.shape}\")\n",
    "\n",
    "    X_train = data_train[feature_columns].values\n",
    "    X_test = data_test[feature_columns].values\n",
    "\n",
    "    y_train = data_train[target_column].values\n",
    "    y_test = data_test[target_column].values\n",
    "    \n",
    "    X_test_full = X_test.copy()  # Keep a copy of the test data for evaluation\n",
    "    y_test_full = y_test.copy()\n",
    "\n",
    "    X_train = X_train[feature_columns].values\n",
    "    X_test = X_test[feature_columns].values\n",
    "\n",
    "    # Reshape X: (num_samples, timesteps=500, num_features)\n",
    "    if value_columns:\n",
    "        num_features = len(feature_columns) // 500  # Calculate how many features per timestep\n",
    "        X_test = X_test.reshape(-1, 500, num_features)\n",
    "        X_train = X_train.reshape(-1, 500, num_features)\n",
    "    else:\n",
    "        num_features = len(feature_columns)\n",
    "\n",
    "    # Print shapes\n",
    "    print(f\"X_test_full shape: {X_test_full.shape}\")\n",
    "    print(f\"y_test_full shape: {y_test_full.shape}\")\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "    is_lstm = isinstance(model, tf.keras.Model)\n",
    "\n",
    "    if is_lstm:\n",
    "        # âœ… Set up Early Stopping (if enabled)\n",
    "        callbacks = []\n",
    "        if use_early_stopping:\n",
    "            early_stopping = EarlyStopping(\n",
    "                monitor=\"val_loss\", patience=3, restore_best_weights=True, verbose=1\n",
    "            )\n",
    "            callbacks.append(early_stopping)\n",
    "\n",
    "    # Start MLflow experiment\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        print(f\"X_train shape: {X_train.shape}\")  # Should be (num_samples, timesteps, num_features)\n",
    "        print(f\"y_train shape: {y_train.shape}\")  # Should be (num_samples,)\n",
    "\n",
    "        # âœ… Log dataset name\n",
    "        mlflow.log_param(\"dataset_name\", dataset_name)  \n",
    "\n",
    "        if is_lstm:\n",
    "            # Train the model and log history\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                validation_data=(X_test, y_test),\n",
    "                callbacks=callbacks  # âœ… Apply Early Stopping if enabled\n",
    "            )\n",
    "        else:\n",
    "            model.fit(X_train, y_train)  # No need for epochs, batch size, or callbacks\n",
    "            \n",
    "        if is_lstm:\n",
    "            # Evaluate model\n",
    "            loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        else:\n",
    "            y_pred = model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # âœ… After training and evaluation, call the per-activity evaluation\n",
    "        results_df = evaluate_per_activity(model, X_test_full, y_test_full, target_column, feature_columns)\n",
    "        \n",
    "        # âœ… After training and evaluation, call the per-distance evaluation\n",
    "        evaluate_per_distance(model, X_test_full, y_test_full, target_column, feature_columns)\n",
    "\n",
    "        # âœ… Log per-activity accuracy in MLflow\n",
    "        mlflow.log_artifact(\"activity_results.csv\")\n",
    "\n",
    "        # âœ… Log model parameters\n",
    "        mlflow.log_param(\"num_features_used\", len(feature_columns))\n",
    "        mlflow.log_param(\"model_type\", model.__class__.__name__)\n",
    "\n",
    "        if is_lstm:\n",
    "            mlflow.log_param(\"epochs\", EPOCHS)\n",
    "            mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "            mlflow.log_param(\"optimizer\", model.optimizer.__class__.__name__)\n",
    "            mlflow.log_param(\"loss_function\", model.loss)\n",
    "            mlflow.log_param(\"early_stopping\", use_early_stopping)  # âœ… Log whether early stopping was used\n",
    "            mlflow.log_metric(\"final_loss\", loss)\n",
    "\n",
    "        # âœ… Log metrics\n",
    "        mlflow.log_metric(\"final_accuracy\", accuracy)\n",
    "\n",
    "        if is_lstm:\n",
    "            # âœ… Log accuracy and loss per epoch\n",
    "            for epoch, (train_acc, val_acc, train_loss, val_loss) in enumerate(zip(history.history['accuracy'], history.history['val_accuracy'], history.history['loss'], history.history['val_loss'])):\n",
    "                mlflow.log_metric(\"train_accuracy_epoch\", train_acc, step=epoch)\n",
    "                mlflow.log_metric(\"val_accuracy_epoch\", val_acc, step=epoch)\n",
    "                mlflow.log_metric(\"train_loss_epoch\", train_loss, step=epoch)\n",
    "                mlflow.log_metric(\"val_loss_epoch\", val_loss, step=epoch)\n",
    "\n",
    "        # âœ… Ensure models folder exists\n",
    "        models_folder = \"models\"\n",
    "        if not os.path.exists(models_folder):\n",
    "            os.makedirs(models_folder)\n",
    "\n",
    "        save_path = os.path.join(models_folder, save_name)\n",
    "\n",
    "        if is_lstm:\n",
    "            model.save(save_path + \".keras\")  # âœ… Save Keras model\n",
    "            mlflow.log_artifact(save_path + \".keras\")\n",
    "        else:\n",
    "            import joblib\n",
    "            joblib.dump(model, save_path + \".pkl\")  # âœ… Save tree-based model\n",
    "            mlflow.log_artifact(save_path + \".pkl\")\n",
    "\n",
    "        # âœ… Log the saved model file as an artifact in MLflow\n",
    "        mlflow.log_artifact(save_path + \".pkl\")\n",
    "\n",
    "        # âœ… Save confusion matrix\n",
    "        y_pred = model.predict(X_test).round()\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # Compute additional metrics\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "\n",
    "        # Log additional metrics\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "        # âœ… Save and log confusion matrix\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"No Fall\", \"Fall\"], yticklabels=[\"No Fall\", \"Fall\"])\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        conf_matrix_path = \"confusion_matrix.png\"\n",
    "        plt.savefig(conf_matrix_path)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(conf_matrix_path)\n",
    "\n",
    "        print(f\"Model trained with accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "        # Delete the files activity_results.csv and distance_results.csv\n",
    "        os.remove(\"activity_results.csv\")\n",
    "        os.remove(\"distance_results.csv\")\n",
    "        os.remove(\"confusion_matrices_distance.png\")\n",
    "        os.remove(\"confusion_matrix.png\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Collection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# XGBoost Model\n",
    "# ==========================\n",
    "\n",
    "def build_xgboost_model():\n",
    "    \"\"\"\n",
    "    Builds an XGBoost model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A compiled XGBoost model.\n",
    "    \"\"\"\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.11,\n",
    "        objective=\"binary:logistic\",\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ==========================\n",
    "# Random Forest Model\n",
    "# ==========================\n",
    "\n",
    "def build_random_forest_model():\n",
    "    \"\"\"\n",
    "    Builds a Random Forest model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Random Forest model.\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ==========================\n",
    "# GBM Model\n",
    "# ==========================\n",
    "def build_gradient_boosting_model():\n",
    "    \"\"\"\n",
    "    Builds a Gradient Boosting (GBM) model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Gradient Boosting model.\n",
    "    \"\"\"\n",
    "    return GradientBoostingClassifier(\n",
    "        n_estimators=200,  # Number of boosting stages\n",
    "        learning_rate=0.1,  # Step size shrinkage to prevent overfitting\n",
    "        max_depth=5,  # Maximum depth of the trees\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "# ==========================\n",
    "# SVM Model\n",
    "# ==========================\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def build_svm_model():\n",
    "    \"\"\"\n",
    "    Builds an SVM model for binary classification.\n",
    "\n",
    "    Returns:\n",
    "        A configured SVM model.\n",
    "    \"\"\"\n",
    "    model = SVC(\n",
    "        kernel=\"rbf\",  # Radial Basis Function (RBF) kernel (default)\n",
    "        C=1.0,         # Regularization parameter\n",
    "        gamma=\"scale\",  # Kernel coefficient\n",
    "        probability=True,  # Enable probability estimates (needed for ROC AUC)\n",
    "        random_state=42\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# RNN Model\n",
    "# ==========================\n",
    "def build_rnn_model():\n",
    "    \"\"\"\n",
    "    Builds a simple RNN model using Keras.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        SimpleRNN(RNN_UNITS, input_shape=INPUT_SHAPE, return_sequences=True),\n",
    "        SimpleRNN(RNN_UNITS),\n",
    "        Dense(DENSE_UNITS, activation=\"relu\"),\n",
    "        Dropout(DROPOUT_RATE),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNCTION, metrics=METRICS)\n",
    "    return model\n",
    "\n",
    "# ==========================\n",
    "# LSTM Model\n",
    "# ==========================\n",
    "def build_lstm_model(l2_lambda=0.001, dropout_rate=0.2, clipnorm=1.0):\n",
    "    \"\"\"\n",
    "    Builds an LSTM-based model with L2 regularization, dropout, and gradient clipping.\n",
    "\n",
    "    Args:\n",
    "        l2_lambda: Strength of L2 regularization (default: 0.001).\n",
    "        dropout_rate: Dropout rate to reduce overfitting (default: 0.2).\n",
    "        clipnorm: Gradient clipping norm (default: 1.0).\n",
    "\n",
    "    Returns:\n",
    "        A compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(RNN_UNITS, input_shape=INPUT_SHAPE, return_sequences=True, \n",
    "             kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),  # Dropout after first LSTM layer\n",
    "        LSTM(RNN_UNITS, kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),  # Dropout after second LSTM layer\n",
    "        Dense(DENSE_UNITS, activation=\"relu\", kernel_regularizer=l2(l2_lambda)),\n",
    "        Dropout(dropout_rate),  # Dropout before final layer\n",
    "        Dense(1, activation=\"sigmoid\")  # Output layer for binary classification\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(clipnorm=clipnorm)\n",
    "    model.compile(optimizer=optimizer, loss=LOSS_FUNCTION, metrics=METRICS)\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Bidirectional LSTM Model (Optional)\n",
    "# ==========================\n",
    "def build_bidirectional_lstm():\n",
    "    \"\"\"\n",
    "    Builds a Bidirectional LSTM model for improved sequence learning.\n",
    "\n",
    "    Returns:\n",
    "        A compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(RNN_UNITS, return_sequences=True), input_shape=INPUT_SHAPE),\n",
    "        Bidirectional(LSTM(RNN_UNITS)),\n",
    "        Dense(DENSE_UNITS, activation=\"relu\"),\n",
    "        Dropout(DROPOUT_RATE),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNCTION, metrics=METRICS)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# CONFIGURABLE VARIABLES\n",
    "# ==========================\n",
    "RNN_UNITS = 128           # Number of RNN/LSTM units\n",
    "DENSE_UNITS = 64         # Number of neurons in the dense layer\n",
    "DROPOUT_RATE = 0.1      # Dropout rate for regularization\n",
    "OPTIMIZER = \"adam\"       # Optimizer: \"adam\", \"sgd\", \"rmsprop\", etc.\n",
    "LOSS_FUNCTION = \"binary_crossentropy\"  # \"binary_crossentropy\" for classification\n",
    "METRICS = [\"accuracy\"]   # Metrics to monitor\n",
    "EPOCHS = 10              # Number of training epochs\n",
    "BATCH_SIZE = 16          # Batch size for training\n",
    "INPUT_SHAPE = (500, 1)   # (Time steps, Features) - Adjust based on your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(probability=True, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Initialize the Model\n",
    "# ==========================\n",
    "model = build_svm_model()  # Change this to your desired model\n",
    "# print(model.summary())  # Print model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-14 00:52:41,281] A new study created in memory with name: no-name-99a59949-a596-4836-ac96-348a9b5c72a9\n",
      "[I 2025-03-14 00:52:41,407] Trial 0 finished with value: 0.5837689211373422 and parameters: {'C': 0.460508503069889, 'kernel': 'linear', 'gamma': 4.1395819821342705}. Best is trial 0 with value: 0.5837689211373422.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1048, 18), Test shape: (262, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-14 00:52:41,563] Trial 1 finished with value: 0.554831404869508 and parameters: {'C': 5.524059487676751, 'kernel': 'rbf', 'gamma': 0.004081508419830653}. Best is trial 0 with value: 0.5837689211373422.\n",
      "[I 2025-03-14 00:52:41,789] Trial 2 finished with value: 0.6039859916148576 and parameters: {'C': 3.9672604996240537, 'kernel': 'linear', 'gamma': 3.2100090321062846}. Best is trial 2 with value: 0.6039859916148576.\n",
      "[I 2025-03-14 00:52:42,089] Trial 3 finished with value: 0.5991609831201242 and parameters: {'C': 7.606375719022123, 'kernel': 'linear', 'gamma': 0.006459276885807884}. Best is trial 2 with value: 0.6039859916148576.\n",
      "[I 2025-03-14 00:52:42,974] Trial 4 finished with value: 0.600494856825132 and parameters: {'C': 35.11904953291173, 'kernel': 'linear', 'gamma': 0.010998454027620137}. Best is trial 2 with value: 0.6039859916148576.\n",
      "[I 2025-03-14 00:52:43,241] Trial 5 finished with value: 0.7228058639249371 and parameters: {'C': 69.87978929601263, 'kernel': 'rbf', 'gamma': 7.637527599024294}. Best is trial 5 with value: 0.7228058639249371.\n",
      "[I 2025-03-14 00:52:43,494] Trial 6 finished with value: 0.6039859916148576 and parameters: {'C': 5.337140715529684, 'kernel': 'linear', 'gamma': 0.004052550320439853}. Best is trial 5 with value: 0.7228058639249371.\n",
      "[I 2025-03-14 00:52:43,681] Trial 7 finished with value: 0.7185702026884971 and parameters: {'C': 5.219976671969255, 'kernel': 'rbf', 'gamma': 3.191755750106683}. Best is trial 5 with value: 0.7228058639249371.\n",
      "[I 2025-03-14 00:52:45,461] Trial 8 finished with value: 0.600494856825132 and parameters: {'C': 76.6692903398809, 'kernel': 'linear', 'gamma': 0.7544420968795092}. Best is trial 5 with value: 0.7228058639249371.\n",
      "[I 2025-03-14 00:52:45,652] Trial 9 finished with value: 0.5977207368042947 and parameters: {'C': 2.481772849347871, 'kernel': 'linear', 'gamma': 0.006260774742959825}. Best is trial 5 with value: 0.7228058639249371.\n",
      "[I 2025-03-14 00:52:45,814] Trial 10 finished with value: 0.6798724073421678 and parameters: {'C': 0.11104877453955009, 'kernel': 'rbf', 'gamma': 0.27433898815915564}. Best is trial 5 with value: 0.7228058639249371.\n",
      "[I 2025-03-14 00:52:46,106] Trial 11 finished with value: 0.7243730085049803 and parameters: {'C': 25.199342787389874, 'kernel': 'rbf', 'gamma': 9.518317979189343}. Best is trial 11 with value: 0.7243730085049803.\n",
      "[I 2025-03-14 00:52:46,371] Trial 12 finished with value: 0.725098605098605 and parameters: {'C': 31.5954082991597, 'kernel': 'rbf', 'gamma': 8.9857275356788}. Best is trial 12 with value: 0.725098605098605.\n",
      "[I 2025-03-14 00:52:46,534] Trial 13 finished with value: 0.6983169284658858 and parameters: {'C': 20.155920608802344, 'kernel': 'rbf', 'gamma': 0.05452125266709653}. Best is trial 12 with value: 0.725098605098605.\n",
      "[I 2025-03-14 00:52:46,757] Trial 14 finished with value: 0.7268885777411146 and parameters: {'C': 23.470820747519316, 'kernel': 'rbf', 'gamma': 0.8940023563613554}. Best is trial 14 with value: 0.7268885777411146.\n",
      "[I 2025-03-14 00:52:46,941] Trial 15 finished with value: 0.724136490805517 and parameters: {'C': 13.174742179944346, 'kernel': 'rbf', 'gamma': 0.628340390426565}. Best is trial 14 with value: 0.7268885777411146.\n",
      "[I 2025-03-14 00:52:47,148] Trial 16 finished with value: 0.7335519856542206 and parameters: {'C': 1.3964926562382944, 'kernel': 'rbf', 'gamma': 1.1678891588152995}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:47,341] Trial 17 finished with value: 0.6368577020708699 and parameters: {'C': 1.3724652335482812, 'kernel': 'rbf', 'gamma': 0.07073717682251625}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:47,544] Trial 18 finished with value: 0.7315499211212778 and parameters: {'C': 0.7851167491449215, 'kernel': 'rbf', 'gamma': 1.0211477011351278}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:47,725] Trial 19 finished with value: 0.707756929616 and parameters: {'C': 0.6696778008722694, 'kernel': 'rbf', 'gamma': 0.22239429247303488}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:47,965] Trial 20 finished with value: 0.3319098893923499 and parameters: {'C': 0.29948848061412336, 'kernel': 'rbf', 'gamma': 0.0011960624351144847}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:48,162] Trial 21 finished with value: 0.7286095606350992 and parameters: {'C': 1.4071924909425102, 'kernel': 'rbf', 'gamma': 1.283791632889584}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:48,366] Trial 22 finished with value: 0.7245866088370831 and parameters: {'C': 1.2730040827376912, 'kernel': 'rbf', 'gamma': 1.518125232855289}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:48,543] Trial 23 finished with value: 0.7180012343920619 and parameters: {'C': 1.472947278245212, 'kernel': 'rbf', 'gamma': 0.3284874580313722}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:48,723] Trial 24 finished with value: 0.7300280639448529 and parameters: {'C': 0.23752175103802736, 'kernel': 'rbf', 'gamma': 1.525652983215301}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:48,893] Trial 25 finished with value: 0.5379139784946237 and parameters: {'C': 0.17065871603745214, 'kernel': 'rbf', 'gamma': 0.03101777710927917}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:49,071] Trial 26 finished with value: 0.7285302738568868 and parameters: {'C': 0.6630106092033007, 'kernel': 'rbf', 'gamma': 2.2403240358767764}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:49,232] Trial 27 finished with value: 0.6427747733300235 and parameters: {'C': 0.263980631461315, 'kernel': 'rbf', 'gamma': 0.16695175782679156}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:49,429] Trial 28 finished with value: 0.7185361783092319 and parameters: {'C': 0.8077916384289788, 'kernel': 'rbf', 'gamma': 0.4458317916425653}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:49,626] Trial 29 finished with value: 0.7193740987709996 and parameters: {'C': 0.368816155037743, 'kernel': 'rbf', 'gamma': 5.236793684384167}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:49,792] Trial 30 finished with value: 0.592960834562427 and parameters: {'C': 0.10753058868131682, 'kernel': 'rbf', 'gamma': 0.11766327144432687}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:49,974] Trial 31 finished with value: 0.7294161540363591 and parameters: {'C': 2.272630106794029, 'kernel': 'rbf', 'gamma': 1.3868266858085165}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:50,155] Trial 32 finished with value: 0.7253405539301948 and parameters: {'C': 2.5479422706903185, 'kernel': 'rbf', 'gamma': 1.362224491602234}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:50,341] Trial 33 finished with value: 0.7248352578756438 and parameters: {'C': 0.46139884519632973, 'kernel': 'rbf', 'gamma': 2.2756825823079625}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:50,503] Trial 34 finished with value: 0.7285490912119224 and parameters: {'C': 2.2318711989010485, 'kernel': 'rbf', 'gamma': 0.469442939830865}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:50,650] Trial 35 finished with value: 0.5984173935534679 and parameters: {'C': 0.9643534517755501, 'kernel': 'linear', 'gamma': 4.414527007365406}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:50,828] Trial 36 finished with value: 0.7181647812222971 and parameters: {'C': 0.20584239289753692, 'kernel': 'rbf', 'gamma': 0.9293005524974949}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:50,955] Trial 37 finished with value: 0.5898654123654123 and parameters: {'C': 0.4908583218460011, 'kernel': 'linear', 'gamma': 1.9391956734660611}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:51,158] Trial 38 finished with value: 0.7227896973370964 and parameters: {'C': 3.3157918889134534, 'kernel': 'rbf', 'gamma': 3.243503447630479}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:51,464] Trial 39 finished with value: 0.6028307078907664 and parameters: {'C': 7.370617350430101, 'kernel': 'linear', 'gamma': 5.283440320833688}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:51,619] Trial 40 finished with value: 0.7252215675732012 and parameters: {'C': 1.8664363089886453, 'kernel': 'rbf', 'gamma': 0.4280668123915613}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:51,798] Trial 41 finished with value: 0.7251130217376206 and parameters: {'C': 4.079469777318551, 'kernel': 'rbf', 'gamma': 1.2752121111869792}. Best is trial 16 with value: 0.7335519856542206.\n",
      "[I 2025-03-14 00:52:51,961] Trial 42 finished with value: 0.741113352156803 and parameters: {'C': 1.062569425181235, 'kernel': 'rbf', 'gamma': 1.0198818521411719}. Best is trial 42 with value: 0.741113352156803.\n",
      "[I 2025-03-14 00:52:52,120] Trial 43 finished with value: 0.7321572613892295 and parameters: {'C': 0.9836616516139922, 'kernel': 'rbf', 'gamma': 0.7564105721515493}. Best is trial 42 with value: 0.741113352156803.\n",
      "[I 2025-03-14 00:52:52,280] Trial 44 finished with value: 0.7232256383461534 and parameters: {'C': 0.5927314858663321, 'kernel': 'rbf', 'gamma': 0.6779657351800609}. Best is trial 42 with value: 0.741113352156803.\n",
      "[I 2025-03-14 00:52:52,461] Trial 45 finished with value: 0.7310641969908118 and parameters: {'C': 0.8743577650873351, 'kernel': 'rbf', 'gamma': 2.9493562481696016}. Best is trial 42 with value: 0.741113352156803.\n",
      "[I 2025-03-14 00:52:52,599] Trial 46 finished with value: 0.5984173935534679 and parameters: {'C': 0.9737990300957002, 'kernel': 'linear', 'gamma': 3.2972128751787135}. Best is trial 42 with value: 0.741113352156803.\n",
      "[I 2025-03-14 00:52:52,796] Trial 47 finished with value: 0.7198382420463936 and parameters: {'C': 1.0009835388499304, 'kernel': 'rbf', 'gamma': 6.792291451510343}. Best is trial 42 with value: 0.741113352156803.\n",
      "[I 2025-03-14 00:52:52,963] Trial 48 finished with value: 0.7250642405722619 and parameters: {'C': 0.3454952354328211, 'kernel': 'rbf', 'gamma': 0.941996398652136}. Best is trial 42 with value: 0.741113352156803.\n",
      "[I 2025-03-14 00:52:53,111] Trial 49 finished with value: 0.7170122352659524 and parameters: {'C': 1.8076644113059521, 'kernel': 'rbf', 'gamma': 0.16021436267971928}. Best is trial 42 with value: 0.741113352156803.\n",
      "[I 2025-03-14 00:52:53,287] Trial 50 finished with value: 0.7292746051762445 and parameters: {'C': 0.8405205263547347, 'kernel': 'rbf', 'gamma': 2.177799317465172}. Best is trial 42 with value: 0.741113352156803.\n",
      "[I 2025-03-14 00:52:53,451] Trial 51 finished with value: 0.716767413720298 and parameters: {'C': 0.21457018737325337, 'kernel': 'rbf', 'gamma': 0.5931893772603161}. Best is trial 42 with value: 0.741113352156803.\n",
      "[I 2025-03-14 00:52:53,631] Trial 52 finished with value: 0.7303519636018202 and parameters: {'C': 0.5349700105620326, 'kernel': 'rbf', 'gamma': 2.891862419241069}. Best is trial 42 with value: 0.741113352156803.\n",
      "[I 2025-03-14 00:52:53,808] Trial 53 finished with value: 0.7314324098731062 and parameters: {'C': 0.5561801889380078, 'kernel': 'rbf', 'gamma': 2.9274041195845104}. Best is trial 42 with value: 0.741113352156803.\n",
      "[I 2025-03-14 00:52:53,971] Trial 54 finished with value: 0.7414399687459409 and parameters: {'C': 1.1805687419846258, 'kernel': 'rbf', 'gamma': 0.9931615097245017}. Best is trial 54 with value: 0.7414399687459409.\n",
      "[I 2025-03-14 00:52:54,118] Trial 55 finished with value: 0.7126559975246674 and parameters: {'C': 1.2233124276838785, 'kernel': 'rbf', 'gamma': 0.27662894798419446}. Best is trial 54 with value: 0.7414399687459409.\n",
      "[I 2025-03-14 00:52:54,236] Trial 56 finished with value: 0.5822911674791375 and parameters: {'C': 0.3929694196314855, 'kernel': 'linear', 'gamma': 0.9499372891994694}. Best is trial 54 with value: 0.7414399687459409.\n",
      "[I 2025-03-14 00:52:54,383] Trial 57 finished with value: 0.7217719353399199 and parameters: {'C': 1.6677792242732439, 'kernel': 'rbf', 'gamma': 0.3624354686386114}. Best is trial 54 with value: 0.7414399687459409.\n",
      "[I 2025-03-14 00:52:54,559] Trial 58 finished with value: 0.6734477081646892 and parameters: {'C': 53.37753861234567, 'kernel': 'rbf', 'gamma': 0.028774340478236852}. Best is trial 54 with value: 0.7414399687459409.\n",
      "[I 2025-03-14 00:52:54,717] Trial 59 finished with value: 0.7263406346145015 and parameters: {'C': 0.7118405048894701, 'kernel': 'rbf', 'gamma': 0.524792497581879}. Best is trial 54 with value: 0.7414399687459409.\n",
      "[I 2025-03-14 00:52:54,875] Trial 60 finished with value: 0.7176599965988324 and parameters: {'C': 3.310006593883681, 'kernel': 'rbf', 'gamma': 0.21132985706578214}. Best is trial 54 with value: 0.7414399687459409.\n",
      "[I 2025-03-14 00:52:55,062] Trial 61 finished with value: 0.7288679119094932 and parameters: {'C': 1.141693510373964, 'kernel': 'rbf', 'gamma': 1.7456524093346781}. Best is trial 54 with value: 0.7414399687459409.\n",
      "[I 2025-03-14 00:52:55,252] Trial 62 finished with value: 0.7297101591128754 and parameters: {'C': 0.7480843456755496, 'kernel': 'rbf', 'gamma': 2.7081566856865886}. Best is trial 54 with value: 0.7414399687459409.\n",
      "[I 2025-03-14 00:52:55,452] Trial 63 finished with value: 0.7278003051706401 and parameters: {'C': 1.1372284708641938, 'kernel': 'rbf', 'gamma': 3.828491010340225}. Best is trial 54 with value: 0.7414399687459409.\n",
      "[I 2025-03-14 00:52:55,660] Trial 64 finished with value: 0.7202713401697787 and parameters: {'C': 0.5306828518180412, 'kernel': 'rbf', 'gamma': 6.64758684397129}. Best is trial 54 with value: 0.7414399687459409.\n",
      "[I 2025-03-14 00:52:55,846] Trial 65 finished with value: 0.729944433057776 and parameters: {'C': 1.5920684382414365, 'kernel': 'rbf', 'gamma': 1.0498927054850546}. Best is trial 54 with value: 0.7414399687459409.\n",
      "[I 2025-03-14 00:52:56,022] Trial 66 finished with value: 0.7362729768732306 and parameters: {'C': 0.921694625974802, 'kernel': 'rbf', 'gamma': 0.8222982721827888}. Best is trial 54 with value: 0.7414399687459409.\n",
      "[I 2025-03-14 00:52:56,203] Trial 67 finished with value: 0.740719897758962 and parameters: {'C': 2.0208634265356396, 'kernel': 'rbf', 'gamma': 0.7127864114863086}. Best is trial 54 with value: 0.7414399687459409.\n",
      "[I 2025-03-14 00:52:56,397] Trial 68 finished with value: 0.7399874744748322 and parameters: {'C': 2.0310732640354283, 'kernel': 'rbf', 'gamma': 0.7697397944094951}. Best is trial 54 with value: 0.7414399687459409.\n",
      "[I 2025-03-14 00:52:56,587] Trial 69 finished with value: 0.7296206911081577 and parameters: {'C': 4.26411062918973, 'kernel': 'rbf', 'gamma': 0.7205764383826511}. Best is trial 54 with value: 0.7414399687459409.\n",
      "[I 2025-03-14 00:52:56,764] Trial 70 finished with value: 0.7300514070590726 and parameters: {'C': 2.531057753541544, 'kernel': 'rbf', 'gamma': 0.3720998684636234}. Best is trial 54 with value: 0.7414399687459409.\n",
      "[I 2025-03-14 00:52:56,949] Trial 71 finished with value: 0.7423093616632184 and parameters: {'C': 1.8895847202845004, 'kernel': 'rbf', 'gamma': 0.6559168635728992}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:52:57,129] Trial 72 finished with value: 0.740719897758962 and parameters: {'C': 1.9959028457047754, 'kernel': 'rbf', 'gamma': 0.7237973916105312}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:52:57,320] Trial 73 finished with value: 0.7278476813825712 and parameters: {'C': 2.042316011679113, 'kernel': 'rbf', 'gamma': 1.1326866648736258}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:52:57,501] Trial 74 finished with value: 0.7368272679993065 and parameters: {'C': 2.91464409864331, 'kernel': 'rbf', 'gamma': 0.5548970727936924}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:52:57,681] Trial 75 finished with value: 0.73797572738306 and parameters: {'C': 2.8745837634226796, 'kernel': 'rbf', 'gamma': 0.523732754868981}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:52:57,903] Trial 76 finished with value: 0.6039859916148576 and parameters: {'C': 2.9923184940878165, 'kernel': 'linear', 'gamma': 0.2580748113196998}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:52:58,086] Trial 77 finished with value: 0.7299057621620335 and parameters: {'C': 5.270129481451495, 'kernel': 'rbf', 'gamma': 0.5828897768945637}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:52:58,263] Trial 78 finished with value: 0.731748707723861 and parameters: {'C': 2.6837532802949893, 'kernel': 'rbf', 'gamma': 0.4609041246022775}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:52:58,440] Trial 79 finished with value: 0.7313635284622324 and parameters: {'C': 7.030762616677879, 'kernel': 'rbf', 'gamma': 0.29507395058839875}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:52:58,597] Trial 80 finished with value: 0.7004157480186722 and parameters: {'C': 3.9131267618742274, 'kernel': 'rbf', 'gamma': 0.1056030089896499}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:52:58,803] Trial 81 finished with value: 0.7231505900420856 and parameters: {'C': 11.186298813731794, 'kernel': 'rbf', 'gamma': 0.7991959328097439}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:52:58,992] Trial 82 finished with value: 0.7295742757461579 and parameters: {'C': 1.8224832950294036, 'kernel': 'rbf', 'gamma': 1.6864143632838906}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:52:59,159] Trial 83 finished with value: 0.7326197430632266 and parameters: {'C': 1.312827173758939, 'kernel': 'rbf', 'gamma': 0.6468076910742707}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:52:59,322] Trial 84 finished with value: 0.7211305643509032 and parameters: {'C': 2.9817182034267904, 'kernel': 'rbf', 'gamma': 0.18033995141512366}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:52:59,499] Trial 85 finished with value: 0.7367087859502419 and parameters: {'C': 2.161636892125167, 'kernel': 'rbf', 'gamma': 0.8101273713537319}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:52:59,666] Trial 86 finished with value: 0.724115855959015 and parameters: {'C': 2.232327511944226, 'kernel': 'rbf', 'gamma': 0.35917437926779366}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:52:59,844] Trial 87 finished with value: 0.7361553604537848 and parameters: {'C': 3.5467276195887916, 'kernel': 'rbf', 'gamma': 0.5351937334649041}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:00,022] Trial 88 finished with value: 0.5338343805192137 and parameters: {'C': 4.4623918173969175, 'kernel': 'rbf', 'gamma': 0.0012287204299482272}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:00,322] Trial 89 finished with value: 0.6002822879111538 and parameters: {'C': 6.22856390401117, 'kernel': 'linear', 'gamma': 1.1677280769898906}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:00,516] Trial 90 finished with value: 0.73146097196353 and parameters: {'C': 2.021826115498629, 'kernel': 'rbf', 'gamma': 1.5447889816710965}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:00,697] Trial 91 finished with value: 0.7402901124779744 and parameters: {'C': 1.3986706053079625, 'kernel': 'rbf', 'gamma': 0.9151444407565634}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:00,879] Trial 92 finished with value: 0.738366041554388 and parameters: {'C': 1.5128965956791205, 'kernel': 'rbf', 'gamma': 0.8041339905024162}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:01,125] Trial 93 finished with value: 0.7252215675732012 and parameters: {'C': 1.5152461421537902, 'kernel': 'rbf', 'gamma': 0.4861541074247426}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:01,344] Trial 94 finished with value: 0.7278997139028964 and parameters: {'C': 1.54767099369848, 'kernel': 'rbf', 'gamma': 1.2588233933609116}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:01,547] Trial 95 finished with value: 0.7361492522040333 and parameters: {'C': 2.698828399265935, 'kernel': 'rbf', 'gamma': 0.6822098221456956}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:01,723] Trial 96 finished with value: 0.7197460996643438 and parameters: {'C': 1.1793507626453579, 'kernel': 'rbf', 'gamma': 0.39425271461027106}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:01,920] Trial 97 finished with value: 0.7312307427238609 and parameters: {'C': 1.776971795116641, 'kernel': 'rbf', 'gamma': 1.0270510222668976}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:02,131] Trial 98 finished with value: 0.7255808951856919 and parameters: {'C': 4.796119101939973, 'kernel': 'rbf', 'gamma': 1.9528261896677988}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:02,310] Trial 99 finished with value: 0.7306119568979131 and parameters: {'C': 1.3292992578504474, 'kernel': 'rbf', 'gamma': 0.5507807632970494}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:02,501] Trial 100 finished with value: 0.7324648376101096 and parameters: {'C': 1.0677993965198644, 'kernel': 'rbf', 'gamma': 1.4042496616501718}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:02,702] Trial 101 finished with value: 0.7325364085677304 and parameters: {'C': 2.1288497035566767, 'kernel': 'rbf', 'gamma': 0.8735697759378974}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:02,909] Trial 102 finished with value: 0.7325364085677304 and parameters: {'C': 2.3785655227201317, 'kernel': 'rbf', 'gamma': 0.7778033152408802}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:03,099] Trial 103 finished with value: 0.7361492522040333 and parameters: {'C': 2.8662435944024804, 'kernel': 'rbf', 'gamma': 0.636214254392664}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:03,296] Trial 104 finished with value: 0.7228627382124708 and parameters: {'C': 3.521670422245268, 'kernel': 'rbf', 'gamma': 0.9922581985346914}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:03,471] Trial 105 finished with value: 0.7240293172006229 and parameters: {'C': 1.5063206693651903, 'kernel': 'rbf', 'gamma': 0.4760807438797234}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:03,641] Trial 106 finished with value: 0.7181431815034456 and parameters: {'C': 1.92479549267503, 'kernel': 'rbf', 'gamma': 0.31643625047194196}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:03,858] Trial 107 finished with value: 0.5977207368042947 and parameters: {'C': 2.364125917829356, 'kernel': 'linear', 'gamma': 0.07281421270530083}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:04,062] Trial 108 finished with value: 0.7268030743887672 and parameters: {'C': 1.6935100125908769, 'kernel': 'rbf', 'gamma': 2.3449888301480013}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:04,271] Trial 109 finished with value: 0.7212000002185063 and parameters: {'C': 1.3608117895718477, 'kernel': 'rbf', 'gamma': 0.22438776786700676}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:04,522] Trial 110 finished with value: 0.7380094227203273 and parameters: {'C': 2.01472241937521, 'kernel': 'rbf', 'gamma': 0.8199282092232673}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:04,919] Trial 111 finished with value: 0.7367087859502419 and parameters: {'C': 1.9856211088834241, 'kernel': 'rbf', 'gamma': 0.8525943278152206}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:05,277] Trial 112 finished with value: 0.7232979311270535 and parameters: {'C': 3.834278094481912, 'kernel': 'rbf', 'gamma': 1.1681471487827007}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:05,546] Trial 113 finished with value: 0.7358687913695617 and parameters: {'C': 2.48213994002618, 'kernel': 'rbf', 'gamma': 0.7162435407387221}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:05,817] Trial 114 finished with value: 0.7280195047500194 and parameters: {'C': 1.708958149821974, 'kernel': 'rbf', 'gamma': 1.4654751752636326}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:06,112] Trial 115 finished with value: 0.7287579883300916 and parameters: {'C': 2.9822223570309703, 'kernel': 'rbf', 'gamma': 0.4085309708371199}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:06,339] Trial 116 finished with value: 0.7268306607243366 and parameters: {'C': 1.0827323695118467, 'kernel': 'rbf', 'gamma': 0.5601954238524229}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:06,599] Trial 117 finished with value: 0.7334881077454989 and parameters: {'C': 1.320206334858887, 'kernel': 'rbf', 'gamma': 1.810391053012376}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:06,851] Trial 118 finished with value: 0.730787283415968 and parameters: {'C': 0.6553417630317981, 'kernel': 'rbf', 'gamma': 0.9008835181677929}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:07,105] Trial 119 finished with value: 0.7290131372040854 and parameters: {'C': 0.809005109576749, 'kernel': 'rbf', 'gamma': 0.6702884167860292}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:07,366] Trial 120 finished with value: 0.7281236620716364 and parameters: {'C': 2.1881809451753536, 'kernel': 'rbf', 'gamma': 1.0421800294588477}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:07,577] Trial 121 finished with value: 0.7399874744748322 and parameters: {'C': 1.9101315884586976, 'kernel': 'rbf', 'gamma': 0.7958837674117656}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:07,973] Trial 122 finished with value: 0.7215886978541917 and parameters: {'C': 97.6755567638529, 'kernel': 'rbf', 'gamma': 0.7815593677715624}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:08,169] Trial 123 finished with value: 0.7276555267792281 and parameters: {'C': 1.473082783155875, 'kernel': 'rbf', 'gamma': 1.3157893476018927}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:08,349] Trial 124 finished with value: 0.7330493444939463 and parameters: {'C': 3.1843352503800473, 'kernel': 'rbf', 'gamma': 0.43545111719591695}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:08,539] Trial 125 finished with value: 0.7358578278090473 and parameters: {'C': 1.8937558042980354, 'kernel': 'rbf', 'gamma': 0.5711949437780086}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:08,758] Trial 126 finished with value: 0.5977207368042947 and parameters: {'C': 2.5797800117623577, 'kernel': 'linear', 'gamma': 1.1302718279468946}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:08,948] Trial 127 finished with value: 0.7367087859502419 and parameters: {'C': 1.738516324891371, 'kernel': 'rbf', 'gamma': 0.9234595072895296}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:09,135] Trial 128 finished with value: 0.7339362696738709 and parameters: {'C': 1.209562431187988, 'kernel': 'rbf', 'gamma': 0.6453882165965841}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:09,330] Trial 129 finished with value: 0.7290450534897065 and parameters: {'C': 0.8885388953561377, 'kernel': 'rbf', 'gamma': 1.604630677213203}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:09,509] Trial 130 finished with value: 0.7227993293483708 and parameters: {'C': 2.190971601943549, 'kernel': 'rbf', 'gamma': 0.3479718244027936}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:09,701] Trial 131 finished with value: 0.7380094227203273 and parameters: {'C': 1.9748016142371474, 'kernel': 'rbf', 'gamma': 0.8242213162380657}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:09,884] Trial 132 finished with value: 0.7375452945843588 and parameters: {'C': 1.6325804287288512, 'kernel': 'rbf', 'gamma': 0.7837563571960441}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:10,063] Trial 133 finished with value: 0.7238558424610025 and parameters: {'C': 1.5211946509319618, 'kernel': 'rbf', 'gamma': 0.49840027482084076}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:10,248] Trial 134 finished with value: 0.738688151727216 and parameters: {'C': 1.6489490149168762, 'kernel': 'rbf', 'gamma': 0.7520192019273618}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:10,420] Trial 135 finished with value: 0.5566373363142766 and parameters: {'C': 1.225645196965284, 'kernel': 'rbf', 'gamma': 0.016651841175614822}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:10,607] Trial 136 finished with value: 0.7333869417685774 and parameters: {'C': 1.063146540133763, 'kernel': 'rbf', 'gamma': 1.2364464550426475}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:10,794] Trial 137 finished with value: 0.7374030743603133 and parameters: {'C': 1.6343481586425428, 'kernel': 'rbf', 'gamma': 0.7193418278081944}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:10,987] Trial 138 finished with value: 0.7358525231980231 and parameters: {'C': 1.3699843630810737, 'kernel': 'rbf', 'gamma': 0.9940892512705531}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:11,188] Trial 139 finished with value: 0.7399874744748322 and parameters: {'C': 1.8976894866678797, 'kernel': 'rbf', 'gamma': 0.8131843104291411}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:11,372] Trial 140 finished with value: 0.7401606013326398 and parameters: {'C': 2.0269546316660163, 'kernel': 'rbf', 'gamma': 0.6353040611299622}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:11,557] Trial 141 finished with value: 0.7367087859502419 and parameters: {'C': 1.9257486847606535, 'kernel': 'rbf', 'gamma': 0.9073065761576478}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:11,743] Trial 142 finished with value: 0.7369587586120806 and parameters: {'C': 2.5114937833262543, 'kernel': 'rbf', 'gamma': 0.6330311827182056}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:11,932] Trial 143 finished with value: 0.7310997139028965 and parameters: {'C': 1.8743840700773542, 'kernel': 'rbf', 'gamma': 1.1047298997888781}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:12,114] Trial 144 finished with value: 0.7341898003421629 and parameters: {'C': 2.2858156793572904, 'kernel': 'rbf', 'gamma': 0.5142197250043293}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:12,291] Trial 145 finished with value: 0.7395088986972451 and parameters: {'C': 1.5337399709433872, 'kernel': 'rbf', 'gamma': 0.7283547167683043}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:12,474] Trial 146 finished with value: 0.738366041554388 and parameters: {'C': 1.4387892502489952, 'kernel': 'rbf', 'gamma': 0.747349305738219}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:12,671] Trial 147 finished with value: 0.7221732340383448 and parameters: {'C': 1.4111958704048615, 'kernel': 'rbf', 'gamma': 1.3979285228985476}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:12,834] Trial 148 finished with value: 0.5957800309161053 and parameters: {'C': 0.9705503173206644, 'kernel': 'linear', 'gamma': 0.6770929034847916}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:13,026] Trial 149 finished with value: 0.7401754526169086 and parameters: {'C': 1.180321319390978, 'kernel': 'rbf', 'gamma': 1.0348882132741233}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:13,238] Trial 150 finished with value: 0.7322537917606067 and parameters: {'C': 1.1935437466979826, 'kernel': 'rbf', 'gamma': 2.026918733715488}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:13,433] Trial 151 finished with value: 0.7374678652386368 and parameters: {'C': 1.5379111333569824, 'kernel': 'rbf', 'gamma': 0.9866934691147848}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:13,626] Trial 152 finished with value: 0.7322384823848239 and parameters: {'C': 1.0211013323122962, 'kernel': 'rbf', 'gamma': 1.2209689913631918}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:13,807] Trial 153 finished with value: 0.7254062947768716 and parameters: {'C': 1.3390651544332186, 'kernel': 'rbf', 'gamma': 0.4285767695459798}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:13,997] Trial 154 finished with value: 0.738688151727216 and parameters: {'C': 1.6881753802916497, 'kernel': 'rbf', 'gamma': 0.7584994640681497}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:14,195] Trial 155 finished with value: 0.7359530763965599 and parameters: {'C': 1.1943274530069634, 'kernel': 'rbf', 'gamma': 0.6194424333202022}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:14,414] Trial 156 finished with value: 0.7292363669838307 and parameters: {'C': 1.6932013636187528, 'kernel': 'rbf', 'gamma': 1.5471803575752177}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:14,602] Trial 157 finished with value: 0.7311980111536653 and parameters: {'C': 0.8292810064033692, 'kernel': 'rbf', 'gamma': 0.7057057967962385}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:14,819] Trial 158 finished with value: 0.7341593090908338 and parameters: {'C': 1.473425178518439, 'kernel': 'rbf', 'gamma': 1.027935176714964}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:15,018] Trial 159 finished with value: 0.7403461222540892 and parameters: {'C': 1.0854109142684762, 'kernel': 'rbf', 'gamma': 0.8661767672822747}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:15,227] Trial 160 finished with value: 0.7322384823848239 and parameters: {'C': 0.9262966504271712, 'kernel': 'rbf', 'gamma': 1.2683769798152031}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:15,509] Trial 161 finished with value: 0.7403461222540892 and parameters: {'C': 1.0804634113828289, 'kernel': 'rbf', 'gamma': 0.8780558122990245}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:16,016] Trial 162 finished with value: 0.732703868144619 and parameters: {'C': 0.72981438515197, 'kernel': 'rbf', 'gamma': 0.9892248332095365}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:16,235] Trial 163 finished with value: 0.731304394589895 and parameters: {'C': 1.0794480421831927, 'kernel': 'rbf', 'gamma': 0.5852060341749779}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:16,434] Trial 164 finished with value: 0.7392032651112321 and parameters: {'C': 1.1992869133731607, 'kernel': 'rbf', 'gamma': 0.9126575597925529}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:16,634] Trial 165 finished with value: 0.7403461222540892 and parameters: {'C': 1.1791234866358447, 'kernel': 'rbf', 'gamma': 0.9334781183324145}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:16,865] Trial 166 finished with value: 0.7267129231310013 and parameters: {'C': 0.642481983841884, 'kernel': 'rbf', 'gamma': 1.7054168705391413}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:17,079] Trial 167 finished with value: 0.7334461434847164 and parameters: {'C': 1.0870332088709267, 'kernel': 'rbf', 'gamma': 1.1623218421160013}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:17,281] Trial 168 finished with value: 0.7338433069709969 and parameters: {'C': 0.9100165438686683, 'kernel': 'rbf', 'gamma': 0.9104353025845943}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:17,491] Trial 169 finished with value: 0.7295546944319768 and parameters: {'C': 1.2241733387863274, 'kernel': 'rbf', 'gamma': 1.4239723285210226}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:17,676] Trial 170 finished with value: 0.7274231014995607 and parameters: {'C': 0.7754012382676791, 'kernel': 'rbf', 'gamma': 0.4897407549600957}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:17,878] Trial 171 finished with value: 0.7399874744748322 and parameters: {'C': 1.7793133131971128, 'kernel': 'rbf', 'gamma': 0.8436333829638858}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:18,091] Trial 172 finished with value: 0.7402901124779744 and parameters: {'C': 1.270024085494414, 'kernel': 'rbf', 'gamma': 0.9621088569333367}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:18,325] Trial 173 finished with value: 0.7403711899082696 and parameters: {'C': 1.2604295504156284, 'kernel': 'rbf', 'gamma': 0.9129690885221443}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:18,551] Trial 174 finished with value: 0.741113352156803 and parameters: {'C': 1.0039576446228773, 'kernel': 'rbf', 'gamma': 1.0843732056002018}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:18,766] Trial 175 finished with value: 0.7322384823848239 and parameters: {'C': 0.9929812669192718, 'kernel': 'rbf', 'gamma': 1.198533492901511}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:18,986] Trial 176 finished with value: 0.7378576715519046 and parameters: {'C': 1.3302797441745013, 'kernel': 'rbf', 'gamma': 1.0081278856874112}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:19,226] Trial 177 finished with value: 0.7336504910771018 and parameters: {'C': 0.9027425309030375, 'kernel': 'rbf', 'gamma': 2.482005206810796}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:19,414] Trial 178 finished with value: 0.6005687681590646 and parameters: {'C': 1.0926096860409378, 'kernel': 'linear', 'gamma': 0.0034899724982984525}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:19,632] Trial 179 finished with value: 0.7290450534897065 and parameters: {'C': 0.8217811369161797, 'kernel': 'rbf', 'gamma': 1.4945101929064697}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:19,858] Trial 180 finished with value: 0.7367087859502419 and parameters: {'C': 1.8521978205333813, 'kernel': 'rbf', 'gamma': 0.8843656615284303}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:20,055] Trial 181 finished with value: 0.7339362696738709 and parameters: {'C': 1.3239382346853525, 'kernel': 'rbf', 'gamma': 0.627892650816023}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:20,323] Trial 182 finished with value: 0.7268501219009277 and parameters: {'C': 2.1591307760484955, 'kernel': 'rbf', 'gamma': 1.0778088586502228}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:20,558] Trial 183 finished with value: 0.7360597004136199 and parameters: {'C': 1.12659211675518, 'kernel': 'rbf', 'gamma': 0.8185177019910254}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:20,765] Trial 184 finished with value: 0.7314468788755684 and parameters: {'C': 1.4706949845097963, 'kernel': 'rbf', 'gamma': 0.6466447665121615}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:21,117] Trial 185 finished with value: 0.7255345785761599 and parameters: {'C': 1.77999083798071, 'kernel': 'rbf', 'gamma': 1.286147099703237}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:21,381] Trial 186 finished with value: 0.7366132271074602 and parameters: {'C': 1.2553437119497906, 'kernel': 'rbf', 'gamma': 1.046512526252909}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:21,591] Trial 187 finished with value: 0.734124216542652 and parameters: {'C': 0.9747065998750082, 'kernel': 'rbf', 'gamma': 0.8095804941676064}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:21,816] Trial 188 finished with value: 0.7156679429036388 and parameters: {'C': 0.13558187497065907, 'kernel': 'rbf', 'gamma': 0.5964820327425193}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:22,055] Trial 189 finished with value: 0.7271411418735517 and parameters: {'C': 2.0844363528329093, 'kernel': 'rbf', 'gamma': 1.8957575867756893}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:22,265] Trial 190 finished with value: 0.7395088986972451 and parameters: {'C': 1.6007075447719796, 'kernel': 'rbf', 'gamma': 0.7183880238079817}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:22,476] Trial 191 finished with value: 0.738688151727216 and parameters: {'C': 1.6737643965718165, 'kernel': 'rbf', 'gamma': 0.7354349237075691}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:22,704] Trial 192 finished with value: 0.733697698890311 and parameters: {'C': 2.4344488047713333, 'kernel': 'rbf', 'gamma': 0.8472266729015036}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:22,912] Trial 193 finished with value: 0.731751395724291 and parameters: {'C': 1.4294017254895341, 'kernel': 'rbf', 'gamma': 0.5516591048838227}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:23,129] Trial 194 finished with value: 0.738366041554388 and parameters: {'C': 1.2908157269450184, 'kernel': 'rbf', 'gamma': 0.9090674226136686}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:23,348] Trial 195 finished with value: 0.7323792021076146 and parameters: {'C': 1.9674030635446782, 'kernel': 'rbf', 'gamma': 1.0844884680275169}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:23,566] Trial 196 finished with value: 0.7374030743603133 and parameters: {'C': 1.5535220379732737, 'kernel': 'rbf', 'gamma': 0.7004806424152612}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:23,762] Trial 197 finished with value: 0.7254062947768716 and parameters: {'C': 1.0328412628001737, 'kernel': 'rbf', 'gamma': 0.4611845721309469}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:23,991] Trial 198 finished with value: 0.7255345785761599 and parameters: {'C': 1.7686410923363438, 'kernel': 'rbf', 'gamma': 1.3152801732467085}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:24,199] Trial 199 finished with value: 0.7402901124779744 and parameters: {'C': 1.262474769702836, 'kernel': 'rbf', 'gamma': 0.9333724600208816}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:24,414] Trial 200 finished with value: 0.7356224520246613 and parameters: {'C': 1.1533606981123226, 'kernel': 'rbf', 'gamma': 1.1020581481140348}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:24,634] Trial 201 finished with value: 0.7402901124779744 and parameters: {'C': 1.3666366531886252, 'kernel': 'rbf', 'gamma': 0.9484689446345449}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:24,853] Trial 202 finished with value: 0.738366041554388 and parameters: {'C': 1.2808013073464473, 'kernel': 'rbf', 'gamma': 0.9143091413331393}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:25,053] Trial 203 finished with value: 0.7326893599476557 and parameters: {'C': 0.9008091533805578, 'kernel': 'rbf', 'gamma': 0.9350842761235753}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:25,268] Trial 204 finished with value: 0.7334461434847164 and parameters: {'C': 1.0979996199069313, 'kernel': 'rbf', 'gamma': 1.1528742521894675}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:25,482] Trial 205 finished with value: 0.738366041554388 and parameters: {'C': 1.4983510443953298, 'kernel': 'rbf', 'gamma': 0.7939620504959766}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:25,709] Trial 206 finished with value: 0.7275495460780953 and parameters: {'C': 1.3053023678090598, 'kernel': 'rbf', 'gamma': 1.4044026317302356}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:25,921] Trial 207 finished with value: 0.7401606013326398 and parameters: {'C': 2.3057736383924743, 'kernel': 'rbf', 'gamma': 0.5915637625884429}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:26,374] Trial 208 finished with value: 0.73797572738306 and parameters: {'C': 2.368447535945486, 'kernel': 'rbf', 'gamma': 0.5711107216739997}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:26,649] Trial 209 finished with value: 0.5977207368042947 and parameters: {'C': 2.542957649712182, 'kernel': 'linear', 'gamma': 0.9758340635912652}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:26,912] Trial 210 finished with value: 0.7401606013326398 and parameters: {'C': 2.0199763747139947, 'kernel': 'rbf', 'gamma': 0.6472990933137893}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:27,137] Trial 211 finished with value: 0.7411442078900169 and parameters: {'C': 2.0793307361473663, 'kernel': 'rbf', 'gamma': 0.6843309209928023}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:27,365] Trial 212 finished with value: 0.7349524420641856 and parameters: {'C': 2.204066795854836, 'kernel': 'rbf', 'gamma': 0.5375419801970011}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:27,601] Trial 213 finished with value: 0.7401606013326398 and parameters: {'C': 2.096447598544092, 'kernel': 'rbf', 'gamma': 0.6269009040834639}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:27,827] Trial 214 finished with value: 0.7339183381087124 and parameters: {'C': 2.953483632288404, 'kernel': 'rbf', 'gamma': 0.6402812788021298}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:28,024] Trial 215 finished with value: 0.6194034787962481 and parameters: {'C': 2.102296535832951, 'kernel': 'rbf', 'gamma': 0.04256316630436665}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:28,244] Trial 216 finished with value: 0.7389974682895 and parameters: {'C': 2.4274055123810987, 'kernel': 'rbf', 'gamma': 0.6563851704957304}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:28,449] Trial 217 finished with value: 0.7264336887853224 and parameters: {'C': 1.9614679800728718, 'kernel': 'rbf', 'gamma': 0.4109605039016543}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:28,647] Trial 218 finished with value: 0.7349524420641856 and parameters: {'C': 2.6923519849347324, 'kernel': 'rbf', 'gamma': 0.510826103233875}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:28,844] Trial 219 finished with value: 0.732318459332937 and parameters: {'C': 0.9530890976686167, 'kernel': 'rbf', 'gamma': 0.6763333716348072}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:29,056] Trial 220 finished with value: 0.7377630833754267 and parameters: {'C': 1.1643958260525464, 'kernel': 'rbf', 'gamma': 1.0882388839244217}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:29,264] Trial 221 finished with value: 0.7380094227203273 and parameters: {'C': 1.9580351242462024, 'kernel': 'rbf', 'gamma': 0.8016799130336076}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:29,473] Trial 222 finished with value: 0.7367087859502419 and parameters: {'C': 1.7808324548808616, 'kernel': 'rbf', 'gamma': 0.8945794275516945}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:29,685] Trial 223 finished with value: 0.738366041554388 and parameters: {'C': 1.411118099503056, 'kernel': 'rbf', 'gamma': 0.7743856302018967}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:29,987] Trial 224 finished with value: 0.7237164751250026 and parameters: {'C': 43.860529563867786, 'kernel': 'rbf', 'gamma': 0.5978850511811399}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:30,206] Trial 225 finished with value: 0.7323792021076146 and parameters: {'C': 2.1560257286935776, 'kernel': 'rbf', 'gamma': 1.0071645165076657}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:30,426] Trial 226 finished with value: 0.7209571524106156 and parameters: {'C': 2.6682065619681112, 'kernel': 'rbf', 'gamma': 1.2568020995799702}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:30,630] Trial 227 finished with value: 0.732318459332937 and parameters: {'C': 1.0238959961935312, 'kernel': 'rbf', 'gamma': 0.6976949273570842}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:30,836] Trial 228 finished with value: 0.7367087859502419 and parameters: {'C': 1.726197967004613, 'kernel': 'rbf', 'gamma': 0.888858247259458}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:31,034] Trial 229 finished with value: 0.7274434732846384 and parameters: {'C': 1.370223288759262, 'kernel': 'rbf', 'gamma': 0.48198086935228623}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:31,255] Trial 230 finished with value: 0.7255972897004745 and parameters: {'C': 2.26475568571994, 'kernel': 'rbf', 'gamma': 1.1164737637075126}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:31,465] Trial 231 finished with value: 0.7399874744748322 and parameters: {'C': 1.892559170161461, 'kernel': 'rbf', 'gamma': 0.7962989497378394}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:31,680] Trial 232 finished with value: 0.7387473534433548 and parameters: {'C': 1.6349167297570502, 'kernel': 'rbf', 'gamma': 0.8988347287770846}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:31,889] Trial 233 finished with value: 0.7359530763965599 and parameters: {'C': 1.1934452836713587, 'kernel': 'rbf', 'gamma': 0.6216708209103768}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:32,210] Trial 234 finished with value: 0.740719897758962 and parameters: {'C': 1.9072670881467169, 'kernel': 'rbf', 'gamma': 0.7657002111073454}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:32,495] Trial 235 finished with value: 0.7411442078900169 and parameters: {'C': 2.017026700612153, 'kernel': 'rbf', 'gamma': 0.6709727325346236}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:32,830] Trial 236 finished with value: 0.7399874744748322 and parameters: {'C': 2.218144521542366, 'kernel': 'rbf', 'gamma': 0.7027130364589347}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:33,224] Trial 237 finished with value: 0.7263406346145015 and parameters: {'C': 0.8128402964116953, 'kernel': 'rbf', 'gamma': 0.5212573261851675}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:33,666] Trial 238 finished with value: 0.7353272338878714 and parameters: {'C': 1.525355915561622, 'kernel': 'rbf', 'gamma': 0.9991432520041138}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:34,077] Trial 239 finished with value: 0.7318796284312932 and parameters: {'C': 3.1340886077781183, 'kernel': 'rbf', 'gamma': 0.6396522776610554}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:34,341] Trial 240 finished with value: 0.7258626675142981 and parameters: {'C': 2.010321548564659, 'kernel': 'rbf', 'gamma': 1.261170513992981}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:34,569] Trial 241 finished with value: 0.740719897758962 and parameters: {'C': 1.877250094544787, 'kernel': 'rbf', 'gamma': 0.779254611422068}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:34,792] Trial 242 finished with value: 0.7358687913695617 and parameters: {'C': 2.3630912716213475, 'kernel': 'rbf', 'gamma': 0.7492519422921761}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:35,016] Trial 243 finished with value: 0.7380094227203273 and parameters: {'C': 1.7398556669943706, 'kernel': 'rbf', 'gamma': 0.8751415836304977}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:35,223] Trial 244 finished with value: 0.731751395724291 and parameters: {'C': 1.3545534627412983, 'kernel': 'rbf', 'gamma': 0.5729125886851086}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:35,435] Trial 245 finished with value: 0.7390075278198711 and parameters: {'C': 1.0911163244076758, 'kernel': 'rbf', 'gamma': 1.0479662028689}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:35,650] Trial 246 finished with value: 0.740719897758962 and parameters: {'C': 2.0272822541773636, 'kernel': 'rbf', 'gamma': 0.72575827502177}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:35,862] Trial 247 finished with value: 0.7338370453378158 and parameters: {'C': 2.7402837666072273, 'kernel': 'rbf', 'gamma': 0.7149104616593909}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:36,064] Trial 248 finished with value: 0.7337722689721321 and parameters: {'C': 2.2075606533853995, 'kernel': 'rbf', 'gamma': 0.571839210904622}. Best is trial 71 with value: 0.7423093616632184.\n",
      "[I 2025-03-14 00:53:36,262] Trial 249 finished with value: 0.59719816862674 and parameters: {'C': 1.5688190765942316, 'kernel': 'linear', 'gamma': 0.43275604009866614}. Best is trial 71 with value: 0.7423093616632184.\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1.8895847202845004, 'kernel': 'rbf', 'gamma': 0.6559168635728992}\n",
      "Model trained with accuracy: 0.8550\n",
      "Precision: 0.8833, Recall: 0.6310, F1-score: 0.7361, ROC-AUC: 0.8997\n",
      "Confusion Matrix:\n",
      "[[171  31]\n",
      " [  7  53]]\n",
      "Activity: CD, X shape: (4, 5), y shape: (4,)\n",
      "Activity CD: 4 correct, 0 incorrect\n",
      "Activity: FCF, X shape: (12, 5), y shape: (12,)\n",
      "Activity FCF: 7 correct, 5 incorrect\n",
      "Activity: FCS, X shape: (12, 5), y shape: (12,)\n",
      "Activity FCS: 2 correct, 10 incorrect\n",
      "Activity: FOB, X shape: (12, 5), y shape: (12,)\n",
      "Activity FOB: 10 correct, 2 incorrect\n",
      "Activity: FOL, X shape: (12, 5), y shape: (12,)\n",
      "Activity FOL: 9 correct, 3 incorrect\n",
      "Activity: FR, X shape: (12, 5), y shape: (12,)\n",
      "Activity FR: 12 correct, 0 incorrect\n",
      "Activity: K, X shape: (24, 5), y shape: (24,)\n",
      "Activity K: 24 correct, 0 incorrect\n",
      "Activity: KD, X shape: (2, 5), y shape: (2,)\n",
      "Activity KD: 2 correct, 0 incorrect\n",
      "Activity: KID, X shape: (4, 5), y shape: (4,)\n",
      "Activity KID: 4 correct, 0 incorrect\n",
      "Activity: LAF, X shape: (12, 5), y shape: (12,)\n",
      "Activity LAF: 10 correct, 2 incorrect\n",
      "Activity: LC, X shape: (12, 5), y shape: (12,)\n",
      "Activity LC: 11 correct, 1 incorrect\n",
      "Activity: LSF, X shape: (12, 5), y shape: (12,)\n",
      "Activity LSF: 11 correct, 1 incorrect\n",
      "Activity: MA, X shape: (9, 5), y shape: (9,)\n",
      "Activity MA: 9 correct, 0 incorrect\n",
      "Activity: PUF, X shape: (12, 5), y shape: (12,)\n",
      "Activity PUF: 11 correct, 1 incorrect\n",
      "Activity: RBS, X shape: (24, 5), y shape: (24,)\n",
      "Activity RBS: 24 correct, 0 incorrect\n",
      "Activity: S, X shape: (9, 5), y shape: (9,)\n",
      "Activity S: 9 correct, 0 incorrect\n",
      "Activity: SC, X shape: (12, 5), y shape: (12,)\n",
      "Activity SC: 12 correct, 0 incorrect\n",
      "Activity: SFB, X shape: (12, 5), y shape: (12,)\n",
      "Activity SFB: 4 correct, 8 incorrect\n",
      "Activity: SLB, X shape: (12, 5), y shape: (12,)\n",
      "Activity SLB: 7 correct, 5 incorrect\n",
      "Activity: STC, X shape: (12, 5), y shape: (12,)\n",
      "Activity STC: 12 correct, 0 incorrect\n",
      "Activity: TF, X shape: (12, 5), y shape: (12,)\n",
      "Activity TF: 12 correct, 0 incorrect\n",
      "Activity: WBS, X shape: (18, 5), y shape: (18,)\n",
      "Activity WBS: 18 correct, 0 incorrect\n",
      "\n",
      "ðŸ“Š Per-Activity Results:\n",
      "                               activity Actual Fall  correct  incorrect  \\\n",
      "0                            Close Door     No Fall        4          0   \n",
      "1                 Chair - Fall to Front        Fall        7          5   \n",
      "2                  Chair - Fall to side        Fall        2         10   \n",
      "3             Fall of object (Backpack)     No Fall       10          2   \n",
      "4         Fall of object (FaszienRolle)     No Fall        9          3   \n",
      "5                         Fall Recovery     No Fall       12          0   \n",
      "6        Kneeling down then standing up     No Fall       24          0   \n",
      "7                            Knock Door     No Fall        2          0   \n",
      "8                          Kids Running     No Fall        4          0   \n",
      "9                    Lying - Awake Fall        Fall       10          2   \n",
      "10                 Laying down on couch     No Fall       11          1   \n",
      "11                  Lying - Asleep Fall        Fall       11          1   \n",
      "12  Minor Ambience (Sitting and Eating)     No Fall        9          0   \n",
      "13      Picking something up from floor     No Fall       11          1   \n",
      "14                       Rush by Sensor     No Fall       24          0   \n",
      "15                                Still     No Fall        9          0   \n",
      "16                Sitting down on chair     No Fall       12          0   \n",
      "17            Slip and Fall - Backwards        Fall        4          8   \n",
      "18                Standing Lost Balance        Fall        7          5   \n",
      "19                  Stand up from Chair     No Fall       12          0   \n",
      "20             Trip and Fall - Forwards        Fall       12          0   \n",
      "21                       Walk by Sensor     No Fall       18          0   \n",
      "\n",
      "    total  accuracy  \n",
      "0       4  1.000000  \n",
      "1      12  0.583333  \n",
      "2      12  0.166667  \n",
      "3      12  0.833333  \n",
      "4      12  0.750000  \n",
      "5      12  1.000000  \n",
      "6      24  1.000000  \n",
      "7       2  1.000000  \n",
      "8       4  1.000000  \n",
      "9      12  0.833333  \n",
      "10     12  0.916667  \n",
      "11     12  0.916667  \n",
      "12      9  1.000000  \n",
      "13     12  0.916667  \n",
      "14     24  1.000000  \n",
      "15      9  1.000000  \n",
      "16     12  1.000000  \n",
      "17     12  0.333333  \n",
      "18     12  0.583333  \n",
      "19     12  1.000000  \n",
      "20     12  1.000000  \n",
      "21     18  1.000000  \n",
      "Distance: 0, X shape: (13, 5), y shape: (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance 0: 13 correct, 0 incorrect\n",
      "Distance: 1, X shape: (68, 5), y shape: (68,)\n",
      "Distance 1: 57 correct, 11 incorrect\n",
      "Distance: 2, X shape: (97, 5), y shape: (97,)\n",
      "Distance 2: 85 correct, 12 incorrect\n",
      "Distance: 3, X shape: (84, 5), y shape: (84,)\n",
      "Distance 3: 69 correct, 15 incorrect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidhark/Desktop/Master These/master/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Per-Distance Results:\n",
      "   distance  correct  incorrect  total  accuracy\n",
      "0         0       13          0     13  1.000000\n",
      "1         1       57         11     68  0.838235\n",
      "2         2       85         12     97  0.876289\n",
      "3         3       69         15     84  0.821429\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trained_model = train_pipe(\n",
    "    model=model,\n",
    "    dataset_name=\"geophone_features_normalized.csv\",\n",
    "    save_name=\"GF_Normalized_SVM_KFoldOptuna\",\n",
    "    feature_columns=[\"median\", \"max\", \"peak\", \"mean\", \"p2p\"],\n",
    "    target_column=\"fall_binary\",\n",
    "    experiment_name=\"Classic Variants Geophone\",\n",
    "    use_early_stopping=False,\n",
    "    if_optuna=True,\n",
    "    n_trials=250\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>median</td>\n",
       "      <td>0.565158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>peak</td>\n",
       "      <td>0.097246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.073363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max</td>\n",
       "      <td>0.065185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>p2p</td>\n",
       "      <td>0.041108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>min</td>\n",
       "      <td>0.029528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>std</td>\n",
       "      <td>0.028338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>crest</td>\n",
       "      <td>0.026930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rms</td>\n",
       "      <td>0.025336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>shape</td>\n",
       "      <td>0.024586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>impulse</td>\n",
       "      <td>0.023221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>energy</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>margin</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature  Importance\n",
       "4    median    0.565158\n",
       "5      peak    0.097246\n",
       "2      mean    0.073363\n",
       "0       max    0.065185\n",
       "6       p2p    0.041108\n",
       "1       min    0.029528\n",
       "3       std    0.028338\n",
       "9     crest    0.026930\n",
       "8       rms    0.025336\n",
       "10    shape    0.024586\n",
       "11  impulse    0.023221\n",
       "7    energy    0.000000\n",
       "12   margin    0.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_feature_importance(model, feature_columns):\n",
    "    \"\"\"\n",
    "    Plots feature importance for tree-based models.\n",
    "\n",
    "    Args:\n",
    "        model: Trained XGBoost, RandomForest, or GradientBoosting model.\n",
    "        feature_columns: List of feature names.\n",
    "\n",
    "    Returns:\n",
    "        None (Displays feature importance plot)\n",
    "    \"\"\"\n",
    "    if hasattr(model, \"feature_importances_\"):  # Ensure model supports feature importance\n",
    "        importances = model.feature_importances_\n",
    "        feature_importance_df = pd.DataFrame({\"Feature\": feature_columns, \"Importance\": importances})\n",
    "        feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.barplot(x=\"Importance\", y=\"Feature\", data=feature_importance_df[:15])  # Top 15 features\n",
    "        plt.title(\"Feature Importance\")\n",
    "        plt.show()\n",
    "\n",
    "        return feature_importance_df\n",
    "    else:\n",
    "        raise ValueError(\"This model does not support feature importance.\")\n",
    "\n",
    "# Usage (after training a model)\n",
    "plot_feature_importance(trained_model, [\"max\", \"min\", \"mean\", \"std\", \"median\", \"peak\", \"p2p\", \"energy\", \"rms\", \"crest\", \"shape\", \"impulse\", \"margin\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def ensemble_predict(models_with_features, dataset_name, target_column):\n",
    "    \"\"\"\n",
    "    Loads a dataset, splits it, loads an ensemble of models (with different feature sets),\n",
    "    and predicts on the test set.\n",
    "\n",
    "    Args:\n",
    "        models_with_features: A list of tuples (model_path, feature_columns) specifying each model's file path\n",
    "                              and the corresponding feature columns used for training.\n",
    "        dataset_name: The name of the dataset CSV file.\n",
    "        target_column: The name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    # âœ… Load dataset\n",
    "    df = load_data(dataset_name)\n",
    "\n",
    "    # âœ… Ensure target column exists\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' not found in dataset.\")\n",
    "\n",
    "    # âœ… Train-test split\n",
    "    data_train, data_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    y_test = data_test[target_column].values  # Target remains the same for all models\n",
    "\n",
    "    # âœ… Load models and their feature columns\n",
    "    models = []\n",
    "    y_preds = []\n",
    "\n",
    "    for model_path, feature_columns in models_with_features:\n",
    "        model = joblib.load(model_path)  # Load model\n",
    "        models.append(model)\n",
    "\n",
    "        # âœ… Extract the correct feature set for this model\n",
    "        X_test = data_test[feature_columns].values  # Select only the features it was trained on\n",
    "\n",
    "        # âœ… Predict (check if the model has `predict_proba` for probability averaging)\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]  # Get probability of the positive class\n",
    "        else:\n",
    "            y_pred_proba = model.predict(X_test)  # Some models might not have `predict_proba`\n",
    "\n",
    "        y_preds.append(y_pred_proba)\n",
    "\n",
    "    # âœ… Ensemble predictions (Average probabilities and threshold at 0.5)\n",
    "    y_pred = np.mean(y_preds, axis=0) > 0.5\n",
    "\n",
    "    # âœ… Compute metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    # âœ… Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # âœ… Print metrics\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    # âœ… Plot confusion matrix\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=[\"No Fall\", \"Fall\"], yticklabels=[\"No Fall\", \"Fall\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9764\n",
      "Precision: 0.9615\n",
      "Recall: 0.9615\n",
      "F1 Score: 0.9615\n",
      "ROC AUC: 0.9722\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ensemble_predict(\n",
    "    models_with_features=[\n",
    "        (\"models/MF_XGB_Optuna.pkl\", [\"max\", \"min\", \"mean\", \"std\", \"median\", \"peak\", \"p2p\", \"energy\", \"rms\", \"crest\", \"shape\", \"impulse\", \"margin\"]),  \n",
    "        (\"models/MF_XGB_RD40_Optuna.pkl\", [\"median\", \"max\", \"peak\", \"mean\", \"p2p\"]),\n",
    "        (\"models/MF_XGB_RD41_Optuna.pkl\", [\"median\", \"max\", \"peak\", \"mean\", \"p2p\"])    \n",
    "    ],\n",
    "    dataset_name=\"MPU_features_pca.csv\",\n",
    "    target_column=\"fall_binary\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
